<!-- HTML header for doxygen 1.9.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Maxwell PerfWorks Profiling Guide | NintendoSDK API Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="openclose.js"></script>
<script type="text/javascript" src="searchapi.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NintendoSDK API Reference
   &#160;<span id="projectnumber">14.1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="_page_graphics_for_n_x.html">Graphics Environment for NX</a></li>  </ul>
</div>
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Maxwell PerfWorks Profiling Guide </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_1">1. Scope</a></li>
<li class="level1"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_2">2. PerfWorks Metrics</a><ul><li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_2_1">2.1. Cycle Metrics</a></li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_2_2">2.2. Time Metrics</a></li>
</ul>
</li>
<li class="level1"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_3">3. Graphics Workflow</a><ul><li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_AlphaBetaPhases">3.1. Alpha/Beta Phases</a></li>
<li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_IntermediateBuffers">3.2. Intermediate Buffers</a></li>
</ul>
</li>
<li class="level1"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4">4. Graphics Bottleneck</a><ul><li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_1">4.1. Bottleneck Regime</a></li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_2">4.2. Bottleneck Unit</a></li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_3">4.3. Throughput Metrics</a></li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_4">4.4. Active Cycles Metrics</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_4_1">4.4.1. Major Processing Units</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_4_2">4.4.2. GPC</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_WorldSpace">4.4.2.1. World-Space</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_ScreenSpace">4.4.2.2. Screen-Space</a></li>
</ul>
</li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_4_4_3">4.4.3. FBP</a></li>
</ul>
</li>
</ul>
</li>
<li class="level1"><a href="#gpuOverview_MaxwellProfiling_guide_GraphicsOptimization">5. Graphics Optimization</a><ul><li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_GraphicsGeneralRecs">5.1. General Recommendations</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_1_1">5.1.1. Useful Metrics</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_ISBEallocations">5.1.1.1. ISBE Allocations</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_TRAMallocations">5.1.1.2. TRAM Allocations</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull">5.1.1.3. Primitive Clipping and Culling</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_ZCULL">5.1.1.4. ZCULL Performance</a></li>
</ul>
</li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2">5.2. VAF (Vertex Attribute Fetch)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_1">5.2.1. Relevant Metrics</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_2">5.2.2. Latency Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_AttributePacking">5.2.2.1. Pack Attributes</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_2_2">5.2.2.2. Reduce ISBE Allocation Stalls</a></li>
</ul>
</li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_3">5.2.3. Workload Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_3_1">5.2.3.1. Optimize Index Buffer</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_CBF">5.2.3.2. Enable Cull-Before-Fetch (CBF)</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_3_3">5.2.3.3. Reduce Clipped and Culled Primitive Overhead</a></li>
</ul>
</li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3">5.3. VPC (Viewport Clip Cull)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_1">5.3.1. Relevant Metrics</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_2">5.3.2. Latency Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_2_1">5.3.2.1. Reduce ISBE Allocation Stalls</a></li>
</ul>
</li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3">5.3.3. Workload Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3_1">5.3.3.1. Enable Vertex Warp Culling</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3_2">5.3.3.2. Enable Cull-Before-Fetch (CBF)</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3_3">5.3.3.3. Reduce Clipped and Culled Primitive Overhead</a></li>
</ul>
</li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4">5.4. ZROP (Z Raster Operation)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_1">5.4.1. Relevant Metrics</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_2">5.4.2. Latency Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_2_1">5.4.2.1. Enable FastZStencil.</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_2_2">5.4.2.2. Enable FastClear Operations</a></li>
</ul>
</li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_3">5.4.3. Workload Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_3_1">5.4.3.1. Improve ZCULL Performance</a></li>
</ul>
</li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_5">5.5. CROP (Color Raster Operation)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_1">5.5.1. Relevant Metrics</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2">5.5.2. Latency Reduction</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2_1">5.5.2.1. Enable Framebuffer Compression</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2_2">5.5.2.2. Enable FastClear Operations</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2_3">5.5.2.3. Experiment with Tiled Caching</a></li>
</ul>
</li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_6">5.6. LTC (Level Two Cache)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_6_1">5.6.1. Relevant Metrics</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_6_2">5.6.2. Client Units</a></li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_TEX">5.7. TEX (Texture)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_7_1">5.7.1. Relevant Metrics</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_7_2">5.7.2. Latency Reduction</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_7_3">5.7.3. Workload Reduction</a></li>
</ul>
</li>
<li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_GraphicsSM">5.8. SM (Streaming Multiprocessor)</a><ul><li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_1">5.8.1. Instruction Issue Utilization Percentage</a></li>
<li class="level3"><a href="#gpuOverview_MaxwellProfiling_guide_WarpOccupancy">5.8.2. Warp Occupancy</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_2_1">5.8.2.1. Latency Hiding</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_ActiveWarps">5.8.2.2. Active Warps</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_WarpResources">5.8.2.3. Warp Resource Requirements</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_FragmentWarpPixelDrain">5.8.2.4. Fragment Warp Pixel Drain</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfiling_guide_FragmentWorkloadStarvation">5.8.2.5. Fragment Workload Starvation</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_2_6">5.8.2.6. Optimizing Warp Occupancy</a></li>
</ul>
</li>
<li class="level3"><a href="#gpuOverview_MaxwellProfiling_guide_ThreadOccupancy">5.8.3. Thread Occupancy</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_3_1">5.8.3.1. Optimizing Thread Occupancy</a></li>
</ul>
</li>
<li class="level3"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_4">5.8.4. Warp Latency</a><ul><li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_4_1">5.8.4.1. Optimizing Warp Latency</a></li>
<li class="level4"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_4_2">5.8.4.2. Warp Stall Types</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="level1"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_6">6. Glossary of Terms</a></li>
<li class="level1"><a href="#gpuOverview_MaxwellProfilingGuide_guide_sec_7">7. Appendix</a><ul><li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_WorldSpaceAlphaOnlyDiagram">7.1. World-Space Data and Command Paths (Alpha Phase Only)</a></li>
<li class="level2"><a href="#gpuOverview_MaxwellProfiling_guide_ScreenSpaceLateZModeDiagram">7.2. Screen-Space Data and Command Paths (LateZ Mode)</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p><a class="anchor" id="md_gpuOverview_MaxwellProfilingGuide"></a></p>
<h1><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_1"></a>
1. Scope</h1>
<p>This document contains recommendations on how to use PerfWorks metrics to profile and optimize graphics and compute performance for applications running on NX SoC. The intended audience is game developers.</p>
<p>This document does not cover how to integrate PerfWorks into an application to retrieve metric values.</p>
<h1><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_2"></a>
2. PerfWorks Metrics</h1>
<p>Note: For more detailed description of PerfWorks metric naming convention please refer to the section "Metrics Naming Conventions" in the "NVIDIA PerfWorks User Guide" document. The following is an excerpt.</p>
<p>Counters and metrics generally obey the naming scheme:</p>
<p><b>&lt;unit&gt;__&lt;subunit&gt;_&lt;pipestage&gt;<em>quantity</em>&lt;qualifiers&gt;</b></p>
<p>where:</p><ul>
<li>unit: A logical or physical unit of the GPU.</li>
<li>subunit: The subunit within the unit where the counter was measured. Sometimes this is a pipeline mode instead.</li>
<li>pipestage: The pipeline stage within the subunit where the counter was measured.</li>
<li>quantity: What is being measured. Generally matches the "dimensional
Units".</li>
<li>qualifiers: Any additional predicates or filters applied to the counter. Often an unqualified counter can be broken down into several qualified sub-components.</li>
</ul>
<p>For example, the metric "vpc__input_prims_point" consists of the following:</p><ul>
<li>The metric is measured from the VPC unit.</li>
<li>The pipeline stage within the unit is the input stage of VPC.</li>
<li>The quantity being measured is the count of primitives.</li>
<li>The qualifier "point" defines the type of primitives.</li>
</ul>
<p>This metric indicates the number of point type primitives which arrive at the VPC unit's input stage within the measured range. All metrics referenced in this document will be written in <em>italics</em>.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_2_1"></a>
2.1. Cycle Metrics</h2>
<p>Metrics using the term cycles in the name report the number of cycles in the unit's clock domain. The different types of metrics are:</p><ul>
<li>&lt;unit&gt;__cycles_elapsed: The number of cycles within a range. Units are in different clock domains.</li>
<li>&lt;unit&gt;__cycles_busy: The number of cycles the unit is not idle.</li>
<li>&lt;unit&gt;__cycles_idle: The number of cycles the unit is idle.</li>
<li>&lt;unit&gt;__cycles_active: The number of cycles the unit is processing data.</li>
</ul>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_2_2"></a>
2.2. Time Metrics</h2>
<ul>
<li>gpu__time_start: gpu timestamp in nanoseconds, relative to the start of the pass, when the range is first submitted to the gpu.</li>
<li>gpu__time_end: gpu timestamp in nanoseconds, relative to the start of the pass, when the last submittal of the range finishes gpu processing.</li>
<li>gpu__time_duration: total gpu time in nanoseconds, in pipelined mode, this is the incremental time duration. See "Isolated vs
Pipelined Passes" above for more info.</li>
<li>gpu__time_active: total gpu time in nanoseconds, in pipelined mode, this is the total range duration. This is equivalent to gpu__time_duration in isolated mode.</li>
</ul>
<h1><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_3"></a>
3. Graphics Workflow</h1>
<p>The following is a high level description of graphics draw call processing. For definitions of the GPU unit names used below, please refer to the "NVIDIA PerfWorks User Guide" document's "Units" section:</p><ul>
<li>NVN driver on the CPU submits state change and draw commands to FIFO used to communicate with the GPU (GPFIFO).</li>
<li>HOST retrieves commands from the GPFIFO for downstream processing and schedules graphics vs. compute workloads.</li>
<li>FE decodes and validates the commands.</li>
<li>Alpha Phase (<a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_AlphaBetaPhases">3.1. Alpha/Beta Phases</a>):<ul>
<li>PDA fetches indices, assembles primitives into batches, and distributes them to GPMPD.</li>
<li>GPMPD distributes vertex shader tasks in round-robin fashion between TPCs for processing.</li>
<li>MPC allocates ISBEs (<a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_IntermediateBuffers">3.2. Intermediate Buffers</a>) in the SM MIOS shared memory data RAM.</li>
<li>PEL instructs VAF to fetch vertex attributes from vertex buffers and store them in ISBEs.</li>
<li>MPC allocates SM resources and launches vertex shader warps.</li>
<li>SM executes vertex shader warps and outputs are written to ISBEs.</li>
<li>If tessellation control shader is enabled:<ul>
<li>MPC allocates SM resources and launches tessellation control shader warps, on the same SM that the preceding vertex warp ran on.</li>
<li>SM executes tessellation control shader warps and outputs are written to ISBEs.</li>
</ul>
</li>
<li>VSC allocates CBEs in the alpha circular buffer via CBMGR for the last alpha phase world-space shader (<a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_IntermediateBuffers">3.2. Intermediate Buffers</a>).</li>
<li>PEL reads the ISBEs of the last alpha phase world-space shader, and frees the ISBEs' MIOS shared memory storage. It then sends the ISBEs to VSC.</li>
<li>VSC writes the ISBEs of the last alpha phase world-space shader into the alpha circular buffer.</li>
</ul>
</li>
<li>Beta Phase (skip if neither tessellation evaluation shader nor geometry shader are active. See <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_AlphaBetaPhases">3.1. Alpha/Beta Phases</a>):<ul>
<li>PDB fetches beta phase tasks from the alpha circular buffer and distributes them to GPMPD.</li>
<li>GPMPD distributes tasks for the first beta phase shader in round-robin fashion between TPCs for processing.</li>
<li>MPC allocates ISBEs (<a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_IntermediateBuffers">3.2. Intermediate Buffers</a>) in the SM MIOS shared memory data RAM.</li>
<li>PEL instructs VAF to fetch output of last alpha phase shader from alpha circular buffer and stores them in ISBEs.</li>
<li>If tessellation evaluation shader is enabled:<ul>
<li>MPC allocates SM resources and launches tessellation evaluation shader warps.</li>
<li>SM executes tessellation evaluation shader warps and outputs are written to ISBEs.</li>
</ul>
</li>
<li>If geometry shader is enabled:<ul>
<li>MPC allocates SM resources and launches geometry shader warps. If a tessellation evaluation shader is also enabled, the warps will run on the same SM that the preceding tessellation evaluation shader warps ran on.</li>
<li>SM executes geometry shader warps and outputs are written to ISBEs.</li>
</ul>
</li>
<li>Optionally STREAM sends transform feedback results from applicable shader stages to LTC to be eventually written to output buffers in DRAM.</li>
<li>PES fetches last world-space shader stage output for fixed-function processing.</li>
<li>VPC clips and culls primitives.</li>
<li>VSC allocates CBEs in the beta circular buffer via CBMGR for the last beta phase world-space shader (<a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_IntermediateBuffers">3.2. Intermediate Buffers</a>).</li>
<li>PEL reads the ISBEs of the last beta phase world-space shader, and frees the ISBEs' MIOS shared memory storage. It then sends the ISBEs to VSC.</li>
<li>VSC writes the ISBEs of the last beta phase world-space shader into CBEs.</li>
</ul>
</li>
<li>WWDX routes the processed primitive for screen space processing.</li>
<li>SWDX sends the primitives to SETUP for rasterization.</li>
<li>Rasterization:<ul>
<li>SETUP fetches all necessary data for screen space processing, computes edge and plane equations for primitives.</li>
<li>CRSTR calculates coarse 16x16 tiles containing coverage information for each primitive.</li>
<li>ZCULL performs conservative depth tests and discards occluded tiles.</li>
<li>FRSTR generates fragments with coverage and Z data.</li>
</ul>
</li>
<li>FRSTR/TC begins subtile transaction.<ul>
<li>If earlyZ mode enabled:<ul>
<li>PROP routes the samples to ZROP via RDM for depth and stencil testing, modifying fragment coverage as necessary.</li>
</ul>
</li>
<li>PROP routes samples to GPMSD for screen-space processing.</li>
<li>GMPSD distributes the samples to TPCs for fragment shader processing in the form of pixel quad shading transactions.</li>
<li>Fragment Shading:<ul>
<li>MPC allocates TRAM entries for the current subtile in MIOS shared memory storage.</li>
<li>STRI calculates plane equations of primitive attributes and writes them to TRAM. These will be used for varying interpolations.</li>
<li>MPC allocates necessary resources and launches fragment shader warps.</li>
<li>SM executes fragment shaders, and returns shaded fragment (color, depth if shaderZ) to GPMSD via the sm2gpmsd half of the PIXOUT interface, to complete the pixel-quad shading transactions.</li>
<li>The last completed pixel quad in ths subtile frees the MIOS TRAM.</li>
</ul>
</li>
<li>PIXOUT routes shaded fragments to PROP's CDP subunit.</li>
<li>CDP executes alpha testing and alpha-to-coverage operations.</li>
<li>If lateZ mode enabled:<ul>
<li>PROP routes the shader fragments to ZROP via RDM for depth and stencil testing.</li>
</ul>
</li>
</ul>
</li>
<li>FRSTR/TC ends subtile transaction.</li>
<li>CSB reorders the fragments and sends them to CROP via RDM.</li>
<li>CROP executes any necessary raster operations and sends the final processed pixels to LTC to be eventually written out to framebuffer in DRAM.</li>
</ul>
<p>Please refer to <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WorldSpaceAlphaOnlyDiagram">7.1. World-Space Data and Command Paths (Alpha Phase Only)</a> and <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ScreenSpaceLateZModeDiagram">7.2. Screen-Space Data and Command Paths (LateZ Mode)</a> for diagrams illustrating graphics workflow above.</p>
<p>For a more in-depth description of graphics processing please see <a class="el" href="gpu_overview__maxwell_technical_overview_index.html">Maxwell Technical Overview</a>.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_AlphaBetaPhases"></a>
3.1. Alpha/Beta Phases</h2>
<p>If tessellation and/or geometry shader stages are active, the world-space processing is split into alpha and beta phases:</p><ul>
<li>Vertex and tessellation control shaders are executed in the alpha phase.</li>
<li>Tessellation evaluation and geometry shaders are executed in the beta phase.</li>
</ul>
<p>The output of the last shader stage in the alpha phase is stored in the alpha circular buffer in LTC to be consumed by the beta phase shaders. The TPCs are time sliced between the alpha and beta phase until all world-space tasks are completed. The scheduling of alpha and beta phase workloads is done by PDA and PDB respectively.</p>
<p>For further details please refer to <a class="el" href="gpu_overview__maxwell_technical_overview_index.html#gpuOverview_MaxwellTechnicalOverview_guide_performance_AlphaBetaPhases">8.5.7.1. Alpha/Beta Phases</a>.</p>
<p>Note that one exception to the above is that executing fast geometry shaders does <b>not</b> necessitate alpha-beta time slicing. This is part of the reason for its higher performance compared to regular geometry shaders. For more details about fast geometry shader please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_fastGS">2.6. Fast Geometry Shader</a>.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_IntermediateBuffers"></a>
3.2. Intermediate Buffers</h2>
<p>In the above operations all memory reads and writes by all GPU units must go through the LTC before reading and writing by DRAM to memory as necessary.</p>
<p>The following is a list of buffers used during graphics processing:</p><ul>
<li>ISBEs (Inter-stage Buffer Elements) are buffers within SM used to transfer data between world space shader stages (vertex, tessellations, geometry), and also between SM and the primitive engine at the end of world space shader processing. In NX, there are 48 KBs of ISBE per-SM. ISBEs are allocated by the MPC unit.</li>
<li>Alpha CB (Circular Buffer) is a region in memory used to store and pass data between alpha and beta phases (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_AlphaBetaPhases">3.1. Alpha/Beta Phases</a>). Alpha CB is managed by the CBMGR unit.</li>
<li>Beta CB (Circular Buffer) is a region in memory used to store and pass data between world and screen-space processing. Beta CB is also managed by the CBMGR unit.</li>
<li>TRAMs (Triangle RAM) are buffers within SM used to store the plane equations which are used to interpolate varyings. In NX, there are 16 KBs of TRAM per SM. TRAMs are allocated by the MPC unit.</li>
</ul>
<h1><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4"></a>
4. Graphics Bottleneck</h1>
<p>This section contains recommended procedure to identify the frame region and GPU unit within that region most likely to be the performance bottleneck. Where applicable, the recommendations will be accompanied with metric values sampled from the frame of an actual game running on NX.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_1"></a>
4.1. Bottleneck Regime</h2>
<p>In order to improve the overall frame rendering time, it is most effective to start with examining the frame regime that is consuming the most cycles. Frame regime here is defined by a set of draw calls that share the same rendering state and shader program. Usually this corresponds to a particular draw pass such as "depth pre-pass", "shadow pass", etc. It is recommended to focus on draw calls with the same state to ensure that they all share the same performance characteristics and bottleneck. It is also easier and more reliable to extract shader optimization hints from a set of metric values which are all measured from draw calls sharing the same shader program.</p>
<p>The recommended method to find the bottleneck regime is to mark regimes within a frame as separate ranges and measuring the <em>gpu__cycles_active.avg</em> for each in isolated mode. Regimes which consumes the most cycles should be examined first. This method works well for regimes with heavy workloads because even in isolated mode there should be enough work for the GPU such that the measured metric values would still reflect real life performance despite the addition of GPU-wait commands by PerfWorks. For details on GPU-wait command insertion by PerfWorks, please refer to the "Isolated vs Pipelined
Passes" section of the "NVIDIA PerfWorks User Guide" document.</p>
<p>For regimes with lighter workloads however, the addition of GPU-wait commands between the regimes may alter the overall workload enough such that it no longer reflects real life performance. In these cases it becomes necessary to measure the metrics over multiple regimes even if they don't share the same states. If all regimes being measured are very low in active cycles (less than 1% of frame time each), it may be necessary to measure multiple regimes together to get accurate performance hints.</p>
<p>Even if there is already an obvious bottleneck regime, it may be beneficial to profile merged regimes anyway to get some additional insight. Once a particular regime has been targeted for examination, the next step would be to find the bottleneck GPU unit for that regime as described in the next section.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_2"></a>
4.2. Bottleneck Unit</h2>
<p>The graphics workflow section above shows how graphics processing involves commands and data streaming down a pipeline of units within the GPU. For a particular unit, the previous unit from which it receives input is called the upstream unit. Conversely, the unit which receives its output is called the downstream unit. For example, in the screen-space pipeline the ZCULL's upstream unit is CRSTR while its downstream unit is FRSTR.</p>
<p>A unit becomes a bottleneck under one or both of the following conditions:</p><ul>
<li>It is stalling its upstream unit(s). This means that upstream unit(s) are frequently idle as it waits for the bottleneck unit to finish its work.</li>
<li>It is starving its downstream unit(s). This means that downstream unit(s) are frequently idle as it waits for the bottleneck unit to generate output for processing.</li>
</ul>
<p>There are 2 methods that could be used to find the unit most likely to be the bottleneck:</p><ul>
<li>Analyze throughput metrics to find the unit which is performing closest to its peak theoretical performance. This unit is the likeliest to be stalling/starving its upstream/downstream units.</li>
<li>Analyze active cycles metrics to find the unit which is active for the longest time within regime and thus is likely to be the performance limiter.</li>
</ul>
<p>The sections below will explain both methods in further details. Please note that both throughput and active cycles analysis can be used to complement each other in finding the top candidate units for optimization, so both methods should be used.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_3"></a>
4.3. Throughput Metrics</h2>
<p>Throughput metrics measure how close a particular unit is to its peak theoretical performance. The recommended variant of throughput metrics for inspection is <em>&lt;unit&gt;__&lt;subunit&gt;_throughput.avg.pct_of_peak_sustained_elapsed</em> where <em>&lt;unit&gt;</em> is the name of the unit and optionally <em>&lt;subunit&gt;</em> is the name of the subunit whose throughput is being measured. These variants of the throughput metrics return percentage values that can range between 0 and 100 percent, measuring how close that particular unit/subunit is to its peak theoretical performance.</p>
<p>Units with the highest throughput percentages are the most likely candidates to be the bottleneck unit for that regime. Usually it is enough to inspect the top 5 units with the highest throughput. Once candidate bottleneck units have been isolated, use the active cycles metrics below to further confirm if the unit is the bottleneck before proceeding to try various optimizations.</p>
<p>Please refer to the PerfWorks documentation for the list of throughput metrics available.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_4"></a>
4.4. Active Cycles Metrics</h2>
<p>This section contains suggestions on how to analyze active cycles metrics starting from top to bottom level units to narrow down as much as possible the sub-unit within the GPU that is causing the bottleneck. Where possible, names for GPU units and subunits are taken from the "NVIDIA PerfWorks User Guide" document. For the rest please refer to <a class="el" href="gpu_overview__maxwell_technical_overview_index.html">Maxwell Technical Overview</a>.</p>
<p>The section is intended to cover only the most common cases for bottleneck regimes so it is possible that there are regimes with their bottleneck units not covered in the steps below. If throughput metrics analysis shows that a different unit is the bottleneck, please investigate both units and experiment with optimizations on both for best results.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_4_1"></a>
4.4.1. Major Processing Units</h3>
<p>The GPU consists of 3 major processing units:</p><ul>
<li>HUB unit which fetches draw/dispatch commands, fetches indices, and assemble primitives for downstream work.</li>
<li>GPC unit which contains most of the graphics/compute processing engine, both fixed function and programmable.</li>
<li>FBP unit which contains the L2 cache and the ROP unit, which is further divided into ZROP and CROP.</li>
</ul>
<p>The NX contains 1 HUB unit, 1 GPC unit, and 2 FBP partitions. As a first step to isolate the bottleneck unit for a particular regime, it is often useful to find out the percentage of total cycles during which each major processing unit is active when processing that regime. This can be done by querying the following metrics.</p>
<p>For the overall GPU active cycles:</p><ul>
<li><em>gr__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>For the GPC unit:</p><ul>
<li><em>mpc__cycles_active_alpha.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>mpc__cycles_active_beta.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>prop__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>sm__cycles_active_ps.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>For the FBP unit:</p><ul>
<li><em>lts__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>crop__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>zrop__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>The HUB unit is ignored because it is very unlikely that it will ever become a bottleneck.</p>
<p>The major processing unit which has the highest active cycle percentage is likely the one containing the bottleneck sub-unit. In particular if the highest percentage value is close to that of gr__cycles_active percentage, then it is a good indication that workload for the regime is dominated by that unit.</p>
<p>For example, in the following table of metric values sampled from the bottleneck regime of an actual game:</p>
<p>Please note that for brevity the modifier "avg.pct_of_peak_sustained_elapsed" is not included in the metric names for all tables below.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Metric   </th><th class="markdownTableHeadNone">Value (%)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>GPU</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>gr__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 100.00 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>GPC</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_alpha</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 99.94 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_beta</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 0.00 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>prop__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 7.74 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>sm__cycles_active_ps</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 39.79 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>FBP</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>lts__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 25.16 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>crop__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 6.14 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>zrop__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 1.85 </div>   </td></tr>
</table>
<p>The GPC has the highest maximum active cycle percentage which very closely approaches the gr__cycles_active percentage. This indicates that the regime's processing time is dominated by the GPC.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_4_2"></a>
4.4.2. GPC</h3>
<p>Once GPC has been established as the major bottleneck unit, the next step is to determine if the majority of active cycles are consumed within world-space or screen-space processing by examining the following metrics.</p>
<p>For world-space processing:</p><ul>
<li><em>mpc__cycles_active_alpha.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>mpc__cycles_active_beta.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>Each metric measures percentage of processing cycles spent within the world-space alpha and beta pipeline respectively. If the beta pipeline is inactive (no tessellation or geometry shaders), its active cycle percentage will be zero as in the example below.</p>
<p>For screen-space processing:</p><ul>
<li><em>prop__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>sm__cycles_active_ps.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>These metrics measure PROP and SM screen-space fragment shader activity respectively. Typically in regimes dominated by screen-space processing the <em>sm__cycles_active_ps</em> would be the higher value.</p>
<p>If the highest active cycle percentage is either of the MPC unit metrics, especially if the value approaches the gr__active_cycles percentage, then it is recommended to concentrate further on world-space processing pipeline, including both fixed function and programmable units.</p>
<p>If either the SM or PROP active cycles percentages are the highest, please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ScreenSpace">4.4.2.2. Screen-Space</a>.</p>
<p>Going back to the above example, the applicable metrics for this section is the following:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Metric   </th><th class="markdownTableHeadNone">Value (%)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>GPU</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>gr__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 100.00 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>World-Space</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_alpha</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 99.94 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_beta</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 0.00 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Screen-Space</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>prop__cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 7.74 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>sm__cycles_active_ps</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 39.79 </div>   </td></tr>
</table>
<p>The highest active cycle percentage, <em>mpc__cycles_active_alpha</em>, is more than twice the cycles spent in the highest screen-space metric <em>sm__cycles_active_ps</em>. This clearly indicates that the regime is world-space bound.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_WorldSpace"></a>
4.4.2.1. World-Space</h4>
<p>The first step in breaking down world-space processing is to differentiate between fixed-function and SM (programmable) workload by comparing the following metrics:</p><ul>
<li><em>mpc__cycles_active_alpha.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>mpc__cycles_active_beta.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>sm__cycles_active_3d_vtg.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p><em>sm__cycles_active_3d_vtg</em> measures the maximum active cycles percentage of all world-space shader executions. If this value is less than the percentage value of <em>mpc__cycles_active_[alpha|beta]</em> metrics then world-space processing is likely bottlenecked by fixed-function workload or vice versa.</p>
<p>From our example regime:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Metric   </th><th class="markdownTableHeadNone">Value (%)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Fixed-Function</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_alpha</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 99.94 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_beta</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 0.00 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Programmable (SM)</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>sm__cycles_active_3d_vtg</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 75.60 </div>   </td></tr>
</table>
<p>The SM cycles required for executing VTG (vertex-tessellation-geometry) shaders only accounts for approximately 76% of world-space cycles. This indicates that likely ~24% of the time the SM has been stalled/starved by one or more fixed-function units.</p>
<p>For optimizing SM bound cases, please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_GraphicsGeneralRecs">5.1. General Recommendations</a> and <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_GraphicsSM">5.8. SM (Streaming Multiprocessor)</a>.</p>
<p>For fixed-function bound cases it is recommended to concentrate on the following units:</p><ul>
<li>VAF unit, which fetches vertex and tessellation evaluation shader inputs from vertex or alpha circular buffers respectively, and stores them in ISBEs.</li>
<li>VPC unit, which clips and culls primitive output of the last world-space shader stage.</li>
</ul>
<p>Relevant VAF metrics are:</p><ul>
<li><em>vaf__alpha_cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>vaf__beta_cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>Relevant VPC metrics are:</p><ul>
<li><em>vpc__alpha_cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>vpc__beta_cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>These measure the active cycle percentages during alpha and beta primitive pipelines for their respective units. If one or both of a unit's cycle count approaches the total world-space active cycles then that unit is a candidate for bottleneck unit. It is possible that both units have high active cycles value in which case they should both be examined.</p>
<p>From our example regime:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Metric   </th><th class="markdownTableHeadNone">Value(%)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>World-Space</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>mpc__cycles_active_alpha</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 99.94 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>VAF</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>vaf__alpha_cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 99.67 </div>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>vaf__beta_cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 0.00 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>VPC</b>   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><em>vpc__alpha_cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 96.78 </div>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><em>vpc__beta_cycles_active</em>   </td><td class="markdownTableBodyNone"><div style="text-align: right;"> 0.00 </div>   </td></tr>
</table>
<p>VAF active cycle percentages are higher than that of the VPC, roughly 99% of the overall world-space active cycles. This would indicate that VAF is the bottleneck unit that needs to be further examined and optimized although in this case the VPC cycle count is high enough that it would be interesting to examine as well.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_ScreenSpace"></a>
4.4.2.2. Screen-Space</h4>
<p>Screen-space bottlenecks usually center around the SM's fragment shader processing performance so optimization is best done by first examining SM's performance metrics. Please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_GraphicsGeneralRecs">5.1. General Recommendations</a> and <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_GraphicsSM">5.8. SM (Streaming Multiprocessor)</a>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_4_4_3"></a>
4.4.3. FBP</h3>
<p>The FBP contains 3 main components:</p><ul>
<li>L2 cache (LTC) which services all GPU units for external memory accesses.</li>
<li>ZROP unit responsible for depth/stencil tests as well as updates and clears of depth/stencil surfaces.</li>
<li>CROP unit responsible for blending color value outputs of the fragment shader and clear operations of color surfaces.</li>
</ul>
<p>The metrics which measure active cycle percentages for the respective sub-units are:</p><ul>
<li><em>lts__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>zrop__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
<li><em>crop__cycles_active.avg.pct_of_peak_sustained_elapsed</em></li>
</ul>
<p>If FBP is the bottleneck major processing unit, the sub-unit with the highest active cycle percentage is likely the bottleneck, especially if the value approaches the total GPU active cycles.</p>
<p>For ZROP and CROP optimization suggestions please refer to their respective optimization sub-sections below.</p>
<p>It is in general not possible to optimize LTC directly because this unit's performance depends on the memory access patterns of various client units within the GPU (TEX, GCC, ZROP, CROP, VAF, VPC, etc). Instead, it may be possible to improve overall performance by altering those client units' memory access behavior. Please refer to the LTC optimization sub-section below for more.</p>
<h1><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_GraphicsOptimization"></a>
5. Graphics Optimization</h1>
<p>Please refer to <a class="el" href="gpu_overview__maxwell_best_practices_index.html">Maxwell Best Practices</a> for a collection of optimization suggestions. The sections below summarize which PerfWorks metrics can be used as hints on which optimizations are likely to improve performance, and for verification of optimization results. For details of each relevant recommendations, references to the best practices document will be made as appropriate.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_GraphicsGeneralRecs"></a>
5.1. General Recommendations</h2>
<p>Once a candidate bottleneck unit is found, its throughput percentage can be used as a hint for the best optimization approach:</p><ul>
<li>High throughput percentages, generally greater than 75%, imply that the unit is already operating at close to peak efficiency. In this case it is recommended to reduce the workload processed by this unit.</li>
<li>Low throughput percentages, generally lower than 75%, imply that the unit is also limited by either some internal operation latency or starved/stalled by its upstream/downstream units. Although reducing the workload for the unit would improve performance, it is recommended to maximize the unit's efficiency first, if possible, by finding and reducing these latencies.</li>
</ul>
<p>For suggestions on specific units please refer to their individual sections below.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_1_1"></a>
5.1.1. Useful Metrics</h3>
<p>This section contains metrics which can give useful optimization information. These will be referred to by various specific unit sub-sections below.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_ISBEallocations"></a>
5.1.1.1. ISBE Allocations</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ISBE">2.10. ISBE</a>.</p>
<p>The metrics showing the number of cycles MPC is forced to stall during ISBE allocation:</p><ul>
<li><em>mpc__isbe_allocation_stalled.avg</em></li>
<li><em>mpc__isbe_allocation_stalled_alpha.avg</em></li>
<li><em>mpc__isbe_allocation_stalled_beta.avg</em></li>
</ul>
<p>The alpha/beta variants are measurements applicable to the alpha/beta phases respectively. ISBE allocation stalls' impact on performance are further detailed below in specific GPU unit sections.</p>
<p>Optimizations that reduce duration of ISBE allocations:</p><ul>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ISBEworldSpace">2.10.1.1. Optimize World-Space Shaders</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ISBEscreenSpace">2.10.1.2. Optimize Screen-Space Processing</a></li>
</ul>
<p>Optimizations that reduce count of ISBE entries allocated:</p><ul>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_CBF">2.8.2.1. Enable Cull-Before-Fetch (CBF)</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_VertexWarpCulling">2.8.2.2. Enable Vertex Warp Culling</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ISBEreduceCull">2.10.2.1. Reduce Culled Primitive Overhead</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ISBEreduceUsage">2.10.2.2. Reduce Count of World-Space Shader Inputs and Outputs</a></li>
</ul>
<p>The following metrics measure the total number of ISBE entries allocated during the measured range. Their differences before and after optimizations indicate effectiveness of allocation reductions:</p><ul>
<li><em>mpc__isbe_allocations.sum</em></li>
<li><em>mpc__isbe_allocations_alpha.sum</em></li>
<li><em>mpc__isbe_allocations_beta.sum</em></li>
</ul>
<p>In addition, the allocation reductions specifically due to CBF can be measured by comparing the sum of the following metrics with and without CBF enabled:</p><ul>
<li><em>vaf__alpha_fetched_attr_scalar_pre_cbf.sum</em></li>
<li><em>vaf__alpha_fetched_attr_scalar_post_cbf.sum</em></li>
</ul>
<p>Note that with CBF disabled, <em>vaf__alpha_fetched_attr_scalar_pre_cbf.sum</em> should always be zero.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_TRAMallocations"></a>
5.1.1.2. TRAM Allocations</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TRAM">2.11. TRAM</a>.</p>
<p>The metrics showing the number of cycles MPC is forced to stall during TRAM allocation is <em>mpc__tram_allocation_stalled.avg</em>.</p>
<p>For optimization suggestions please refer to the following:</p><ul>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TRAMreduceVaryings">2.11.1.1. Reduce Count of Varyings</a></li>
</ul>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull"></a>
5.1.1.3. Primitive Clipping and Culling</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_PrimClipCull">2.9.1.1. Reduce Clipped and Culled Primitive Overhead</a>.</p>
<p>The metrics showing the counts of various primitive types arriving at VPC for clipping and culling:</p><ul>
<li><em>vpc__input_prims.sum</em> (Total count of all primitive types)</li>
<li><em>vpc__input_prims_point.sum</em></li>
<li><em>vpc__input_prims_line.sum</em></li>
<li><em>vpc__input_prims_triangle.sum</em></li>
<li><em>vpc__input_prims_patch.sum</em></li>
</ul>
<p>The metrics showing the counts of various primitive types leaving VPC after clipping and culling:</p><ul>
<li><em>vpc__output_prims.sum</em> (Total count of all primitive types)</li>
<li><em>vpc__output_prims_point.sum</em></li>
<li><em>vpc__output_prims_line.sum</em></li>
<li><em>vpc__output_prims_stippled_line.sum</em></li>
<li><em>vpc__output_prims_triangle.sum</em></li>
</ul>
<p>The metrics showing the count of various primitive types clipped by VPC:</p><ul>
<li><em>vpc__clip_input_prims_clipped.sum</em></li>
<li><em>vpc__clip_input_prims_clipped_single_plane.sum</em></li>
<li><em>vpc__clip_input_prims_clipped_multi_plane.sum</em></li>
</ul>
<p>The metrics showing the count of various primitive types culled by VPC:</p><ul>
<li><em>vpc__cull_culled_prims.sum</em> (Total count of all primitive types)</li>
<li><em>vpc__cull_culled_prims_point.sum</em></li>
<li><em>vpc__cull_culled_prims_line.sum</em></li>
<li><em>vpc__cull_culled_prims_triangle.sum</em></li>
</ul>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_ZCULL"></a>
5.1.1.4. ZCULL Performance</h4>
<p>The ZCULL unit by itself can never become a bottleneck unit but the efficiency of its culling performance may impact other downstream units.</p>
<p>The count of samples arriving at ZCULL input is measured by <em>raster__zcull_input_samples.sum</em>.</p>
<p>The count of samples culled can be queried with <em>raster__zcull_culled_samples.sum</em>.</p>
<p>ZCULL should always be active. Its effectiveness can be improved by rendering primitives in depth order matching that of the current depth compare function. If the culling percentage seems low or zero please refer to <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_zcull">2.2. ZCull</a> for suggestions on how to improve ZCULL performance.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2"></a>
5.2. VAF (Vertex Attribute Fetch)</h2>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_1"></a>
5.2.1. Relevant Metrics</h3>
<p>Throughput percentage can be measured using <em>vaf__throughput.avg.pct_of_peak_sustained_elapsed</em>.</p>
<p>VAF fetches vertex attributes in units of vec4 and writes them into ISBE entries.</p>
<p>The sum of the following metrics indicate the total count of vec4 fetches executed:</p><ul>
<li><em>vaf__alpha_fetched_attr_vector_pre_cbf.sum</em></li>
<li><em>vaf__alpha_fetched_attr_vector_post_cbf.sum</em></li>
</ul>
<p>The sum of the following metrics indicate the total count of ISBE entries needed to store the fetched attributes:</p><ul>
<li><em>vaf__alpha_fetched_attr_scalar_pre_cbf.sum</em></li>
<li><em>vaf__alpha_fetched_attr_scalar_post_cbf.sum</em></li>
</ul>
<p>For explanation of the "cbf" field please refer to <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_CBF">5.2.3.2. Enable Cull-Before-Fetch (CBF)</a>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_2"></a>
5.2.2. Latency Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_AttributePacking"></a>
5.2.2.1. Pack Attributes</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_PackVertexAttribs">2.8.1.1. Pack Attributes</a>.</p>
<p>The efficiency of attribute packing optimization is indicated by</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img16.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 1: Attribute Packing Efficiency Percentage</b> </div><p> <br  />
</p>
<p>which approaches 100% when all attributes are perfectly packed into vec4s.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_2_2"></a>
5.2.2.2. Reduce ISBE Allocation Stalls</h4>
<p>Each attribute that is fetched by VAF is written to an ISBE entry allocated by MPC. Any stalls in the allocation process would add to shader launch latency.</p>
<p>The total cycle count VAF is stalled waiting for ISBE allocations can be measured using:</p><ul>
<li><em>vaf__alpha_cycles_stalled_on_mpc.sum</em></li>
<li><em>vaf__beta_cycles_stalled_on_mpc.sum</em></li>
</ul>
<p>Ideally the allocation stalls should be zero but in some cases stalls are unavoidable. The larger the stalled cycle count, the larger its contribution to reducing VAF efficiency.</p>
<p>For more on GPU-wide ISBE allocation stalls for the entire regime and suggestions on how to reduce them please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ISBEallocations">5.1.1.1. ISBE Allocations</a>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_3"></a>
5.2.3. Workload Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_3_1"></a>
5.2.3.1. Optimize Index Buffer</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_OptimizeIndex">2.8.1.2. Optimize Index Buffer</a>.</p>
<p>The number of primitives which arrive at VAF for processing can be queried using <em>vaf__alpha_input_prims.sum</em>.</p>
<p>The number of batches created is indicated by:</p><ul>
<li><em>vaf__alpha_input_batches_pre_cbf.sum</em></li>
<li><em>vaf__alpha_input_batches_post_cbf.sum</em></li>
</ul>
<p>Please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_CBF">5.2.3.2. Enable Cull-Before-Fetch (CBF)</a> for explanation on "cbf" fields.</p>
<p>The average number of primitives per-batch can be calculated as follows: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img01.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 2: Average Primitives In a Batch</b> </div><p> <br  />
</p>
<p>Effective optimization of index buffer should lead to a higher avg_primitive_per_batch value.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_CBF"></a>
5.2.3.2. Enable Cull-Before-Fetch (CBF)</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_CBF">2.8.2.1. Enable Cull-Before-Fetch (CBF)</a>.</p>
<p>Some VAF metric names describe in this document contain <em>pre_cbf</em> and <em>post_cbf</em> qualifier fields which indicates that the metric applies to VSa and VSb executions respectively as described in best practices document section above.</p>
<p>The number of primitives for a regime that is frustum culled can be queried using VPC culling metrics as described in <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull">5.1.1.3. Primitive Clipping and Culling</a>. This can be used to identify candidate regimes for enabling CBF. Regimes with higher frustum culled primitive count should see more benefit.</p>
<p>The effectiveness of CBF in reducing the number of fetch requests can be measured by comparing the sum of the following metrics with and without CBF enabled:</p><ul>
<li><em>vaf__alpha_fetched_attr_vector_pre_cbf.sum</em></li>
<li><em>vaf__alpha_fetched_attr_vector_post_cbf.sum</em></li>
</ul>
<p>Note that when CBF is disabled, <em>vaf__alpha_fetched_attr_vector_pre_cbf.sum</em> should always be zero.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_2_3_3"></a>
5.2.3.3. Reduce Clipped and Culled Primitive Overhead</h4>
<p>The fetching of clipped or culled primitives' attributes is wasted work done by VAF. For details on primitive clipping and culling, their overhead, and suggestions for improvements please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull">5.1.1.3. Primitive Clipping and Culling</a>.</p>
<p>Effective reduction of culled primitive overhead should reduce both the count of vec4 and scalars fetched as described in the relevant metrics section above.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3"></a>
5.3. VPC (Viewport Clip Cull)</h2>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_1"></a>
5.3.1. Relevant Metrics</h3>
<p>Throughput percentage can be measured using <em>vpc__throughput.avg.pct_of_peak_sustained_elapsed</em>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_2"></a>
5.3.2. Latency Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_2_1"></a>
5.3.2.1. Reduce ISBE Allocation Stalls</h4>
<p>VPC receives inputs in the form of ISBE entries. Any stalling in the allocation for these entries can idle the unit and reduce its efficiency. The metric to measure the amount of cycles stalled is the following:</p><ul>
<li><em>mpc__isbe_allocation_stalled_alpha_on_vsc.avg</em></li>
<li><em>mpc__isbe_allocation_stalled_beta_on_vsc.avg</em></li>
</ul>
<p>Ideally the allocation stalls should be zero but in some cases stalls are unavoidable. The larger the stalled cycle count, the larger its contribution to reducing VPC efficiency.</p>
<p>For more on GPU-wide ISBE allocation stalls for the entire regime and suggestions on how to reduce them please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ISBEallocations">5.1.1.1. ISBE Allocations</a>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3"></a>
5.3.3. Workload Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3_1"></a>
5.3.3.1. Enable Vertex Warp Culling</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_VertexWarpCulling">2.8.2.2. Enable Vertex Warp Culling</a>.</p>
<p>To help estimate and verify vertex warp culling effectiveness, please refer to the metrics in <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull">5.1.1.3. Primitive Clipping and Culling</a> which measure the number of primtives that were frustum culled. Regimes with a high count of frustum culled primitives are good candidates for vertex warp culling. If effective, vertex warp culling should reduce this count.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3_2"></a>
5.3.3.2. Enable Cull-Before-Fetch (CBF)</h4>
<p>Please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_CBF">5.2.3.2. Enable Cull-Before-Fetch (CBF)</a> for details on CBF optimization. CBF reduces VPC workload by dropping frustum culled primitives at the vertex shader stage.</p>
<p>To help estimate and verify CBF effectiveness, please refer to the metrics in <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull">5.1.1.3. Primitive Clipping and Culling</a> to measure how many of a regime's primitives are frustum culled. Regimes with high count of frustum culled primitives are good candidates for CBF. If effective, CBF should reduce this count.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_3_3_3"></a>
5.3.3.3. Reduce Clipped and Culled Primitive Overhead</h4>
<p>VPC workload is directly proportional to the number of primitives processed. Clipped and culled primitives represent wasted cycles. For details on primitive clipping and culling, their overhead, and suggestions for improvements please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_PrimitiveClipCull">5.1.1.3. Primitive Clipping and Culling</a>.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4"></a>
5.4. ZROP (Z Raster Operation)</h2>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_1"></a>
5.4.1. Relevant Metrics</h3>
<p>Throughput percentage can be measured using <em>zrop__throughput.avg.pct_of_peak_sustained_elapsed</em>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_2"></a>
5.4.2. Latency Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_2_1"></a>
5.4.2.1. Enable FastZStencil.</h4>
<p>Enabling FastZStencil mode can significantly increase ZROP throughput. Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_fastZ">2.3. FastZStencil</a> for further details.</p>
<p>If it is not possible to enable FastZStencil for a certain pass, consider separating the depth tests to a separate pre-pass which can support FastZStencil mode.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_2_2"></a>
5.4.2.2. Enable FastClear Operations</h4>
<p>Enabling FastClear will reduce memory operation latencies and increase ZROP processing efficiency. Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_fastClear">2.5. Fast Clear (Zero Bandwidth Clear)</a> for more details.</p>
<p>The following metrics can be used to indicate if a depth clear operation is executed as a FastClear:</p><ul>
<li><em>lts__cbc_requests_hit_clear_zbc_zrop.sum</em></li>
<li><em>lts__cbc_requests_miss_clear_zbc_zrop.sum</em></li>
</ul>
<p>Non-zero values in one or both of the metrics above indicate that FastClear operation has been executed.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_3"></a>
5.4.3. Workload Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_4_3_1"></a>
5.4.3.1. Improve ZCULL Performance</h4>
<p>More efficient ZCULL unit performance will reduce the number of depth/stencil samples that ZROP need to handle. Please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ZCULL">5.1.1.4. ZCULL Performance</a>.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_5"></a>
5.5. CROP (Color Raster Operation)</h2>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_1"></a>
5.5.1. Relevant Metrics</h3>
<p>Throughput percentage can be measured using <em>crop__throughput.avg.pct_of_peak_sustained_elapsed</em>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2"></a>
5.5.2. Latency Reduction</h3>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2_1"></a>
5.5.2.1. Enable Framebuffer Compression</h4>
<p>Enabling framebuffer-compression has the following advantages:</p><ul>
<li>CROP can work directly and more efficiently with framebuffer-compressed surfaces.</li>
<li>Memory operation latencies can be significantly reduced for such surfaces.</li>
</ul>
<p>Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_FBcompression">2.4. Framebuffer Compression</a> for further details and refer to the NVN programming guide for details on how to create framebuffer-compressible textures.</p>
<p>The following metrics can be used to indicate if framebuffer-compressed writes occur:</p><ul>
<li><em>crop__write_requests_compressed_1to1.sum</em></li>
<li><em>crop__write_requests_compressed_2to1.sum</em></li>
<li><em>crop__write_requests_compressed_4to1.sum</em></li>
<li><em>crop__write_requests_compressed_8to1_or_fastclear.sum</em></li>
</ul>
<p>If all metrics above except <em>crop__write_requests_compressed_1to1</em> are zeroes then no compressed writes occurred. The relative values of above metrics can also give an estimate of the effectiveness of framebuffer-compression.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2_2"></a>
5.5.2.2. Enable FastClear Operations</h4>
<p>Enabling FastClear will reduce memory operation latencies and increase CROP processing efficiency. Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_fastClear">2.5. Fast Clear (Zero Bandwidth Clear)</a> for more details.</p>
<p>The following metric can be used to indicate if a color clear operation is executed as a FastClear:</p><ul>
<li><em>lts__cbc_requests_hit_clear_zbc_crop.sum</em></li>
<li><em>lts__cbc_requests_miss_clear_zbc_crop.sum</em></li>
</ul>
<p>Non-zero values in one or both of the metrics above indicate that FastClear operation has been executed.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_5_2_3"></a>
5.5.2.3. Experiment with Tiled Caching</h4>
<p>Blending operations under certain conditions could lead to reduced performance for framebuffer-compressed surfaces. Enabling tiled caching in these cases may help to improve performance. For details please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_RMWblend">2.4.2.1. Enable Tiled Caching for Blending</a>.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_6"></a>
5.6. LTC (Level Two Cache)</h2>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_6_1"></a>
5.6.1. Relevant Metrics</h3>
<p>Throughput percentage can be measured using <em>lts__throughput.avg.pct_of_peak_sustained_elapsed</em>.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_6_2"></a>
5.6.2. Client Units</h3>
<p>The LTC unit services all internal GPU clients for external memory accesses in addition to handling atomic operations and decompressing framebuffer-compressed surfaces as necessary.</p>
<p>When LTC is the bottleneck unit, it is recommended to investigate further which of its client is dominating its workload and shift investigation to that client unit.</p>
<p>LTC client request counts can be queried using the metrics with the names <em>lts__t_requests_&lt;unit&gt;.sum</em> where &lt;unit&gt; is the name of the various client units such as "pe", "raster", "crop", etc. Please refer to the LOP documentations for the full list.</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_TEX"></a>
5.7. TEX (Texture)</h2>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_7_1"></a>
5.7.1. Relevant Metrics</h3>
<p>Throughput percentage can be measured using <em>l1tex__throughput.avg.pct_of_peak_sustained_elapsed</em>.</p>
<p>Another useful value to check is the hit-rate within the L1 texture cache: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img02.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 3: TEX L1 Cache Hitrate Percentage</b> </div><p> <br  />
</p>
<p>Hitrates which are lower than 90% could potentially have an impact on overall performance. Latency reduction and workload reduction suggestions below may help to improve the L1 hitrate.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_7_2"></a>
5.7.2. Latency Reduction</h3>
<p>Please refer to the following sections in maxwell best practices documentation:</p><ul>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_BatchTexInsts">2.7.2.2. Batch Texture Instructions</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TextureGathers">2.7.2.3. Use Texture Gathers</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_OverrideSubtile">2.7.2.7. Override Fragment Warp Subtile Size</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TextureFBcompression">2.13.1.1. Enable Framebuffer Compression</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TextureFormats">2.13.1.2. Use Optimal Formats</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TextureFiltering">2.13.1.3. Use Optimal Filtering Mode</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_InitializeCompressed">2.13.2.1. Initialize with Framebuffer-Compressed Values</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_TexTiledCaching">2.13.2.2. Experiment with Tiled Caching</a></li>
</ul>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_7_3"></a>
5.7.3. Workload Reduction</h3>
<p>Please refer to the following sections in maxwell best practices documentation:</p><ul>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ShaderReduceRegSpill">2.7.2.1. Reduce Register Spills</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_SSBOtoUBO">2.7.1.6. Replace SSBOs with UBOs</a></li>
<li><a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_Texture3Dto2D">2.13.1.4. Use 2D Array instead of 3D Textures</a></li>
</ul>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_GraphicsSM"></a>
5.8. SM (Streaming Multiprocessor)</h2>
<p>In NX, shaders are executed within SM in batches of up to 32 threads called warps. Warps are further grouped into subtiles which are distributed into one of the SM partitions. All warps in a subtile are assigned to and execute within one of the sub-partition. For further details please refer to <a class="el" href="gpu_overview__maxwell_technical_overview_index.html">Maxwell Technical Overview</a>.</p>
<p>Warp execution performance can be affected by the following factors:</p><ul>
<li>Instruction issue utilization percentage, which indicate how close the instruction issue rate for a regime is to the peak instruction-per-cycle capability of the SM.</li>
<li>Warp occupancy, which is defined as a measure of how many warps are available as candidates for execution at any particular SM active cycle.</li>
<li>Thread occupancy, which is defined as a measure of how many threads are active per warp.</li>
<li>Warp latency, which is the total sum of cycles necessary to execute all of the warp's threads to completion.</li>
</ul>
<p>It is recommended to optimize in the following order:</p><ul>
<li>If the issue utilization percentage is approaching peak instruction-per-cycle rate, the SM is already at close to peak processing capacity and the number of instructions to be executed must be reduced to increase performance.</li>
<li>If the warp occupancy for the regime is low, in general it is more productive to try to improve this next. This is because high warp occupancy can maximize performance gains by amplifying the benefits of warp latency reduction optimizations. Conversely, low warp occupancy can diminish those same benefits.</li>
<li>Similar to poor warp occupancy, low thread occupancy causes each warp to do less than optimal amount of work, reducing the benefits of warp latency reduction optimizations.</li>
<li>After it has been verified that instruction issue utilization is not the bottleneck and both warp and thread occupancies have been optimized as much as possible, profiling can then proceed to investigate the regime's warp latencies and how to reduce them.</li>
</ul>
<p>Warp occupancy, thread occupancy, and warp latency optimizations are discussed in further details within their own sub-sections below.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_1"></a>
5.8.1. Instruction Issue Utilization Percentage</h3>
<p>The instruction issue utilization percentage of a regime is defined as a ratio of the number of cycles within the regime when instructions are being issued and the total elapsed cycles for the regime's processing within the SM:</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img19.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 4: Issue Utilization Percentage</b> </div><p> <br  />
</p>
<p>Peak issue performance occur if a new instruction is issued for every elapsed cycle.</p>
<p>Utilization percentages of greater than 90% generally indicates that the SM is bottlenecked by the number of instructions it can execute. In these cases, the best way to optimize performance is to reduce the number of instructions that needs to be processed.</p>
<p>One real world example would be a pass that blends a surface texture containing user interface elements with the framebuffer. If the UI elements only cover a very small percentage of the screen, adding a conditional to skip the color space conversions and blending operations for UI surface texels with zero alpha value can be used to reduce the total number of instructions that needs to be executed , leading to increased overall performance.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_WarpOccupancy"></a>
5.8.2. Warp Occupancy</h3>
<p>Warp occupancy is measured in units of <b>active-warps-per-active-cycle</b>. For brevity this document will use the term <b>warps-per-cycle</b> instead. Higher warps-per-cycle value indicates higher warp occupancy and vice versa. The exact definition of <b>active warp</b> will be explained in detail below. First however, the next section will explain why high warp occupancy is desirable.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_2_1"></a>
5.8.2.1. Latency Hiding</h4>
<p>Higher warp occupancy increases the SM's capability to hide the latencies of long running operations by substituting a different warp for execution.</p>
<p>In the following figures, each row represents the scheduling timeline of a candidate warp within an SM sub-partition. Colored segments represent the range of cycles when the corresponding warp is executing math operations. White segments represent the range of cycles when the corresponding warp is being blocked waiting for a texture fetch to finish. Please note that these figures are simplified to illustrate the benefit of latency hiding. In reality, it is possible that there are more than two warps simulatenously running within a sub-partition, each executing on a different sub-unit which may be local to the sub-partition or shared with another. Furthermore, NX contains 2 SM units with a total of 8 sub-partitions, each executing more or less independently of each other. For further details please refer to <a class="el" href="gpu_overview__maxwell_technical_overview_index.html">Maxwell Technical Overview</a>.</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img03.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 5: Latency Hiding</b> </div><p> <br  />
</p>
<p>In figure 5, while warp 1's texture fetch operation is being processed in the texture pipeline, warp 2's math operations are scheduled to execute. Effectively the long latency of the texture fetch is being hidden by substituting warp 2 to utilize the SM math units, which would have been idle otherwise. Ideally, the SM can be kept busy 100% of the time by having its various sub-units executing operations from multiple warps simultaneously.</p>
<p>The effectiveness of latency hiding is affected by the number of candidate warps available for substitution. The larger the number of candidates, the higher the probability that one of the candidates is available for substitution.</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img04.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 6: Insufficient Candidate Warps</b> </div><p> <br  />
</p>
<p>In figure 6, with only 2 candidate warps available, the SM is forced to become idle when both warps must each block for their respective texture fetch operations to complete.</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img05.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 7: Sufficient Candidate Warps</b> </div><p> <br  />
</p>
<p>In figure 7, with N candidate warps available, there is a higher chance that at least one of those warps are not blocked and can be executed.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_ActiveWarps"></a>
5.8.2.2. Active Warps</h4>
<p>The set of warps that can be considered as candidates for execution is called the set of active warps. Warps are considered active if all the necessary resources required for their execution have been succesfully allocated by the MPC, see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WarpResources">5.8.2.3. Warp Resource Requirements</a>.</p>
<p>For NX, the peak theoretical warp occupancy is 128 warps-per-cycle per-SM for fragment shaders and 64 warps-per-cycle-per-SM for all other types of shaders. However it is almost impossible for a regime to reach these maximum values as an average. Practically, 100 warps-per-cycle for fragment shaders and 50 warps-per-cycle for all other shader types can be considered as optimal occupancies. As a rule of thumb, occupancy between 20 and 40 warps-per-cycle can be considered good although this value may differ depending on shader complexity. The maximum count of warps-per-cycle achievable for a particular draw regime ultimately depends on properties of the shader and the draw call itself as explained below.</p>
<p>The average warps-per-cycle of a particular regime can be calculated as follows: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img06.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 8: Average Active Warps Per Cycle</b> </div><p> <br  />
</p>
<p>The average warps-per-cycle of a particular warp type for a regime can be calculated as follows: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img07.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 9: Average Active X Warps Per Cycle</b> </div><p> <br  />
 where <b>X</b> can be one of the following:</p><ul>
<li><em>vsa</em> or <em>vsb</em> for vertex shaders.</li>
<li><em>tcs</em> for tessellation control shaders.</li>
<li><em>tes</em> for tessellation evaluation shaders.</li>
<li><em>gs</em> for geometry shaders.</li>
<li><em>ps</em> for fragment shaders.</li>
<li><em>cs</em> for compute shaders.</li>
</ul>
<p><em>vsa</em> and <em>vsb</em> refer to the 2 phases of the vertex shaders if CBF is enabled (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_CBF">5.2.3.2. Enable Cull-Before-Fetch (CBF)</a>). If CBF is not enabled, <em>vsb</em> alone should be sufficient.</p>
<p>Low occupancy can be due to the following 2 causes:</p><ul>
<li>Lack of SM resources which limits the maximum number of warps that can be active at any given cycle.</li>
<li>Upstream and/or downstream unit(s) are starving/stalling the SM. For example, world-space processing requires too much cycles, starving the SM by reducing the rate of fragment work arrival. Another example would be CROP stalling the SM by taking too long to execute complex blend operations, reducing the rate that active warps which have completed is drained from the SM (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_FragmentWarpPixelDrain">5.8.2.4. Fragment Warp Pixel Drain</a>).</li>
</ul>
<p>Both of these causes and the methods to detect them are discussed in their respective sections below.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_WarpResources"></a>
5.8.2.3. Warp Resource Requirements</h4>
<p>The following lists all types of SM resources that must be shared by all active warps. No additional active warp can be created once any single required resources of a particular type is not sufficient.</p>
<p><b>Register</b></p>
<p>One common type of resource necessary for warps of all shader types are registers. Each SM sub-partition contains 512 warp-wide registers, each warp-wide register can store up to 32 different values, one for each warp thread. This means that the register requirement for a particular shader translates directly to the register requirement of its corresponding warp. The maximum active warp count for a shader given its register usage can be calculated from the "occupancy" statistic of GLSLC compilation's performance statistics output using the following formula: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img08.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 10: Active Warp Count</b> </div><p> <br  />
 Please refer to the GLSLC documentation's "Compiler Performance
Statistics" section for further details.</p>
<p><b>Shader Scratch Memory</b></p>
<p>Some shader requires additional scratch memory storage for execution as determined by GLSLC. Insufficient allocation of shader scratch memory by the application can lead to less than optimal warp occupancy. The scratch memory size requirement for a single warp of a particular shader is returned by GLSLC as <b><a class="el" href="struct_g_l_s_l_cgpu_code_header.html#a804117e2ce22cbcc85316d5d2e8b1c84" title="The amount of local memory (in bytes per warp) required for this program.">GLSLCgpuCodeHeader::scratchMemBytesPerWarp</a></b> field of GLSLC compilation output. The amount of scratch memory sufficient to achieve the maximum possible warps-per-cycle is returned as the <b><a class="el" href="struct_g_l_s_l_cgpu_code_header.html#ac8b1eef84fa9f0debec1874f8b570e62" title="The total amount of local memory recommended for this program on a NX device.">GLSLCgpuCodeHeader::scratchMemBytesRecommended</a></b> field. Please see section "3. Scratch Memory" of the GLSLC programming guide for further details. Please also see section "10. Register Spill Control" for more options on controlling shader scratch memory requirement.</p>
<p><b>ISBE Entries</b></p>
<p>World-space shaders' warp occupancies can be limited by insufficient ISBE entries. Please see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_ISBE">2.10. ISBE</a>. The total number of ISBE entries needed for a world-space shader's input and output can be calculated from the sum of all scalar inputs and outputs for that shader. For example, a vec4 input/output attribute translates into 4 ISBE entries. Note that each ISBE entry is an fp32 precision value so lower precision inputs/outputs such as half floats will still require a single entry each. Please see <a class="el" href="gpu_overview__maxwell_technical_overview_index.html#gpuOverview_MaxwellTechnicalOverview_guide_performance_ISBE">8.5.4. Inter-Stage Buffer Entries (ISBEs)</a> for the formula to calculate the maximum possible active warp count given the input and output of a vertex shader.</p>
<p><b>TRAM Entries</b></p>
<p>A fragment shader's warp occupancy can be limited by insufficient TRAM entries. The total number of TRAM entries needed by a fragment shader warp can be calculated using the following formula: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img09.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 11: Warp TRAM Entry Count</b> </div><p> <br  />
 The total number of primitives that are processed by the fragment shader can be queried using the metric <em>raster__setup_input_prims.sum</em>. If we assume that every fragment warps references the same number of primitives, then the average TRAM entry needed per-warp would be: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img10.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 12: Average TRAM Entries Per Warp</b> </div><p> <br  />
 <b>fragment_shader_input_#</b> above is the sum of the following:</p><ul>
<li>The count of the fragment shader's scalar varyings (i.e a vec4 varying consists of 4 varying scalars).</li>
<li>The count of hidden scalar varyings for reads of built-in fragment shader variables such as gl_FragCoord, gl_PointCoord, etc. Please refer to the GLSL specification for the full list of fragment shader built-in variables.</li>
<li>If any of the fragment shader's varying input is interpolated in a perspective correct manner and gl_FragCoord.w is not accessed by the fragment shader, an additional varying representing the perspective division value 'w' will also be added as a fragment shader input to be used for perspective division operations. This extra input can be eliminated by explicitly specifying 'noperspective' or 'flat' for all of the fragment shader's varying inputs.</li>
</ul>
<p>The size of each TRAM entry is 12 bytes. Each SM contains 16 KBytes of TRAM memory which must be shared by all active warps. The formula for maximum possible active warp given the assumption that each warp refers to the same number of primitives and there is no reuse of TRAM entries between consecutive warps is as follows: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img11.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 13: Maximum Active Warp (TRAM Usage)</b> </div><p> <br  />
</p>
<p>Note however, that the active warp count calculated above may not be accurate due to the following reasons:</p><ul>
<li>It assumes that each warp contains fragments from the same number of primitives. Practically, the number of primitives referenced by each warp can be influenced by the location of the warp's fragments within the primitive (fragments from the middle of a primitive tend to reference only 1 primitive, while those near the border may reference more), and the grouping of fragments into warp. In turn this implies that some subset of fragment warps may have higher TRAM requirements than others and the maximum possible active warp count will fluctuate in real time.</li>
<li>The MPC attempts to reduce TRAM usage by reusing TRAM entry already allocated for the previous warp if both warps reference the same primitive. The effectiveness of this reuse depends on the processing order and composition of the fragment warps.</li>
</ul>
<p>Because of the potential inaccuracies above, it is recommended that other warp occupancy limiting resources be investigated first, leaving TRAM for last if other explanations for low warp occupancy are not found.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_FragmentWarpPixelDrain"></a>
5.8.2.4. Fragment Warp Pixel Drain</h4>
<p>This section describes how warp occupancy can be reduced due to draining fragment shader warps.</p>
<p>The registers used by fragment shader warps are freed in 2 stages:</p><ul>
<li>The registers not used to store the shader output values are immediately freed once the warp finishes execution of all instructions.</li>
<li>The registers used to store the shader outputs are freed once their values have been drained by PIXOUT.</li>
</ul>
<p>The output of NX fragment warps can be a combination of the following depending on shader content:</p><ul>
<li>Up to 8 pixel color values when multiple render targets are enabled.</li>
<li>Depth value.</li>
<li>Coverage value.</li>
</ul>
<p>The largest possible count of registers needed is 34 registers consisting of the following:</p><ul>
<li>8 pixel color values occupying 4 registers each, for a total of 32 registers.</li>
<li>Depth value occupying 1 register.</li>
<li>Coverage value occupying 1 register.</li>
</ul>
<p>Because registers are allocated and freed in groups of eight, in the worse case a finished warp waiting to be drained can still occupy up to 40 registers. These unfreed registers can reduce warp occupancy by preventing new active warps from being created.</p>
<p>Delays in draining fragment warp outputs are usually caused by the following:</p><ul>
<li>Busy downstream units stalling SM execution.</li>
<li>The fragment shader warp must wait for all other warps in its subtile to finish.</li>
</ul>
<p>For more information about subtiles please refer to <a class="el" href="gpu_overview__maxwell_technical_overview_index.html#gpuOverview_MaxwellTechnicalOverview_guide_performance_SM_Neighbors">8.2.1. SM and Its Neighbors</a>.</p>
<p>The number of registers occupied by draining warps for each active cycle can be estimated using the following formula: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img13.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 14: Average Drain Register Count</b> </div><p> <br  />
 The shader_output_reg_# varies depending on the fragment shader content.</p>
<p>The formula described in the register sub-section of <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WarpResources">5.8.2.3. Warp Resource Requirements</a>, can be used to estimate if avg_drain_reg_# is decreasing warp occupancy by preventing the SM to allocate additional blocks of 8 registers. Possible ways to reduce the impact of fragment warp drains are:</p><ul>
<li>High pixel drain latency can be an indication of downstream units stalling the SM. For example, CROP's blending operations delaying pixels to be drained. It is recommended to check for such downstream units and try to optimize them. Please refer to each downstream unit's individual section elsewhere in this document.</li>
<li>The effect of high pixel drain latency can be reduced by minimizing the fragment shader output. Consider fragment shader and/or rendering pass changes which may be able to accomplish this.</li>
<li>Experimenting with different subtile sizes can potentially reduce the duration of the draining wait. Please refer to <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_OverrideSubtile">2.7.2.7. Override Fragment Warp Subtile Size</a> for further details.</li>
</ul>
<h4><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_FragmentWorkloadStarvation"></a>
5.8.2.5. Fragment Workload Starvation</h4>
<p>Another possible cause for reduced fragment warp occupancy is fragment workload starvation by upstream units. If the screen-space SM does not receive a steady stream of fragment workload, there could be periods when the warp occupancy is less than optimal although warp resources are available.</p>
<p>The relevant metric that can be used as a hint that upstream units are starving screen-space SM is <em>mpc__warp_launch_stalled_ps</em>. This indicate the total cycle count when there exists at least one active warp ready to execute but for various reasons is being stalled, the exact stall root cause is not important here.</p>
<p>Ideally, with upstream units delivering fragment workload at sufficient rate, the stalled cycles should approach the total cycles of MPC graphics processing measured by <em>sm__cycles_active_3d</em>, indicating that screen-space SMs always have fragment workload available to process. Otherwise see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WorldSpace">4.4.2.1. World-Space</a> for suggestions on how to determine which upstream unit's processing is reducing the rate of fragment work arrival.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_2_6"></a>
5.8.2.6. Optimizing Warp Occupancy</h4>
<p>The following optimization flow is suggested for increasing warp occupancy:</p><ul>
<li>Calculate the warp occupancy's warps-per-cycle metric for the shader stage of interest (vertex, fragment, etc). See <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ActiveWarps">5.8.2.2. Active Warps</a>.</li>
<li>Given the corresponding shader's warp resource usage, calculate the maximum possible warp occupancy. This would be the lowest warp occupancy possible given usage of all applicable types of resources. See <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WarpResources">5.8.2.3. Warp Resource Requirements</a>.</li>
<li>If the resource limited warp occupancy value is close to the actual warp occupancy, then it is likely that occupancy is resource limited. Shader modification or draw pass changes to reduce the bottleneck resource usage is recommended.</li>
<li>For fragment warps, if the resource limited warp occupancy is higher than the actual warp occupancy, refer to <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_FragmentWarpPixelDrain">5.8.2.4. Fragment Warp Pixel Drain</a> and <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_FragmentWorkloadStarvation">5.8.2.5. Fragment Workload Starvation</a> to check if SM is being stalled or starved by downstream/upstream units.</li>
<li>For world-space warps, if the resource limited warp occupancy is higher than the actual warp occupancy, please see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WorldSpace">4.4.2.1. World-Space</a> to check if world-space fixed function units are starving/stalling the SM.</li>
</ul>
<h3><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_ThreadOccupancy"></a>
5.8.3. Thread Occupancy</h3>
<p>Thread occupancy describes the number of threads within a warp which can execute instructions. A warp which has the maximum possible 32 active threads can execute at maximum efficiency. Conversely, warps with less than 32 active threads are not fully utilizing the SM's resources. For example, if a warp has only 16 active threads then for every active cycle only half of the SM's ALUs can be put to work while the other half remain idle. Please note that the concept of thread occupancy is orthogonal to warp occupancy described above. Warp occupancy refers to the number of candidate warps that are eligible to execute instructions on the SM per active cycle, while thread occupancy refers to how many threads in an executing warp can do useful work. In general thread occupancy of 30 or higher is considered optimal.</p>
<p>Possible causes for less than optimal thread occupancy are:</p><ul>
<li>Warps are launched with less than the maximum 32 active threads. This is due to the way pixels are covered by the primitives being drawn. Draw calls rendering primitives which are small, far away, partially obscured, or a combination thereof, have higher chances of generating warps with less than 32 active thread count. Conversely, a pass that draws a single fullscreen primitive is guaranteed to have fully occupied warps. Sparse warps have suboptimal efficiency for their entire lifetime. If a particular regime seems to suffer from sparsely launched warps, graphics debuggers such as LLGD and NVNGD can be used to confirm the pixel coverage of its draw calls.</li>
<li>Divergent branching of threads within a warp during execution could cause some threads to become temporarily inactive. For a more detailed explanation of how divergent branching could deactivate threads please refer to <a class="el" href="gpu_overview__maxwell_technical_overview_index.html#gpuOverview_MaxwellTechnicalOverview_guide_performance_SIMTexecutionModel">8.2.2.2. SIMT Execution Model</a>. Branch instructions whose conditions evaluate to the same results for all threads in a warp will not cause divergence and have no negative impact on performance. For example, conditions based on uniforms or constant values, which evaluate to identical values for all threads, will not cause divergence. Conversely, conditions based on SSBO values or thread specific properties have a chance of causing divergence and temporarily deactivating a portion of the warp's threads. The GLSLC performance analysis statistic <em>numDivergentBranches</em> can be used as an estimate of how many branch instructions in the shader can potentially diverge. Note that this statistic may not be able to fully capture runtime behavior so it is recommended to measure runtime thread execution divergence using the method described below. Please refer to the GLSLC documentation's performance statistics section for further details.</li>
</ul>
<p>The average number of threads launched for a warp of a particular type can be calculated by the following:</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img12.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 15: Average Thread # Launched Per X Warp</b> </div><p> <br  />
</p>
<p>where <b>X</b> can be one of the following:</p><ul>
<li><em>vsa</em> or <em>vsb</em> for vertex shaders.</li>
<li><em>tcs</em> for tessellation control shaders.</li>
<li><em>tes</em> for tessellation evaluation shaders.</li>
<li><em>gs</em>, <em>gs_fast_alpha</em>, and <em>gs_fast_beta</em> for geometry shaders.</li>
<li><em>ps</em> for fragment shaders.</li>
<li><em>cs</em> for compute shaders.</li>
</ul>
<p>This value ranges from 0 to 32 and higher is better for performance. To calculate the average count of threads launched per warp for all warp types, divide <em>sm__threads_launched.avg</em> by the sum all of the above <em>sm__warps_launched_X.avg</em> values.</p>
<p>Less than optimal thread occupancy due to divergent branching can be calculated by the following:</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img20.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 16: Average Thread Inst # Executed Per Instruction Executed</b> </div><p> <br  />
</p>
<p>This value ranges from 0 to the number of threads launched for the warp and higher is better for performance. Values less than the number of threads launched indicate that some threads' execution have been temporarily suspended due to divergent branching.</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_3_1"></a>
5.8.3.1. Optimizing Thread Occupancy</h4>
<p>It is recommended to look for, and optimize if possible, warps that are launched with low thread counts before optimizing for branch divergence.</p>
<p>Please refer to <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_Fullscreen">2.7.2.5. Use Fullscreen Rendering Pass to Optimize Thread Occupancy</a> for an optimization option that improves thread occupancy.</p>
<p>Please refer to <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_Shuffle">2.7.2.4. Use Shuffle or Subgroup Intrinsics</a> for an optimization option that may reduce branch divergence.</p>
<h3><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_4"></a>
5.8.4. Warp Latency</h3>
<p>Warp latency is directly dependent on the complexity of the shader. Shaders with large amounts of complex math operations and/or global memory accesses, such as texture/SSBO/Image reads/writes, will naturally take longer to complete than those which do not.</p>
<p>The average warp latency for a draw regime can be calculated as follows:</p>
<p>The total cycles to execute all warps (total_warp_latency) can be calculated by summing the following metrics:</p><ul>
<li><em>smsp__warps_cant_issue_long_scoreboard.avg</em></li>
<li><em>smsp__warps_cant_issue_imc_miss.avg</em></li>
<li><em>smsp__warps_cant_issue_no_instructions.avg</em></li>
<li><em>smsp__warps_cant_issue_short_scoreboard.avg</em></li>
<li><em>smsp__warps_cant_issue_membar.avg</em></li>
<li><em>smsp__warps_cant_issue_wait.avg</em></li>
<li><em>smsp__warps_cant_issue_tex_throttle.avg</em></li>
<li><em>smsp__warps_cant_issue_mio_throttle.avg</em></li>
<li><em>smsp__warps_cant_issue_math_pipe_throttle.avg</em></li>
<li><em>smsp__warps_cant_issue_drain.avg</em></li>
<li><em>smsp__warps_cant_issue_not_selected.avg</em></li>
<li><em>smsp__warps_cant_issue_selected.avg</em></li>
<li><em>smsp__warps_cant_issue_tile_allocation_stall.avg</em></li>
<li><em>smsp__warps_cant_issue_allocation_stall.avg</em></li>
<li><em>smsp__warps_cant_issue_dispatch_stall.avg</em></li>
<li><em>smsp__warps_cant_issue_barrier.avg</em></li>
<li><em>smsp__warps_cant_issue_misc.avg</em></li>
</ul>
<p>The average warp latency can be estimated by dividing the total latency by the total number of warps launched:</p>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img14.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 17: Average Warp Latency</b> </div><p> <br  />
</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_4_1"></a>
5.8.4.1. Optimizing Warp Latency</h4>
<p>Before optimizing warp latency, it is recommended to first try to optimize warp occupancy as much as possible (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WarpOccupancy">5.8.2. Warp Occupancy</a>). Similarly, thread occupancy should also be checked (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_ThreadOccupancy">5.8.3. Thread Occupancy</a>). Once warp and thread occupancy cannot be easily improved any further, the metrics indicating the various warp stall types described below should be measured to find which type of stall is dominating warp execution. Finally, experiments with shader modification can be done to reduce the bottleneck stall(s).</p>
<h4><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_5_8_4_2"></a>
5.8.4.2. Warp Stall Types</h4>
<p>In the course of execution, one or more threads of a warp may be stalled due to a variety of reasons. Once a thread is stalled, it must either wait until the stalling operation is complete, or the entire warp can be substituted with another non-stalled warp which can proceed (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_WarpOccupancy">5.8.2. Warp Occupancy</a>).</p>
<p>The metrics described below measure the cycle count of various stall types. To find the likeliest bottleneck stall type, it is often useful to convert these metrics into percentage values measuring how much each stall type contributes to the average warp latency by using the following formula: </p><div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img15.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 18: Average Percentage Stalled by X</b> </div><p> <br  />
 where <b>X</b> corresponds to the stall types described below.</p>
<p>Optimization attempts should start with the stall root cause that occupies the highest percentage of warp latency. Note that the percentage above applies to warps of all shader types. Unfortunately it is not possible to calculate stall percentage values for a particular type of shader warp (vertex, fragment, etc).</p>
<p>Sub-sections below list common causes for SM stalls, how to measure them using PerfWorks metrics, and where applicable, suggestions on how to optimize them.</p>
<p><b>Texture Pipeline Stall</b></p>
<p>The cycle count during which a warp is stalled waiting for texture pipeline operations to complete can be measured using <em>smsp__warps_cant_issue_long_scoreboard.avg</em>. Shader operations that are processed by the texture pipeline are:</p><ul>
<li>Texture fetches.</li>
<li>SSBO reads and writes.</li>
<li>Image reads and writes.</li>
<li>Atomic operations.</li>
</ul>
<p>All suggestions listed in <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_TEX">5.7. TEX (Texture)</a> can potentially improve texture operation efficiency and reduce texture pipeline stalls.</p>
<p><b>Immediate Constant Cache (IMC) Miss</b></p>
<p>IMC is an on-chip cache within the SM that stores uniform buffer values. Cycles stalled due to IMC misses can be measured using <em>smsp__warps_cant_issue_imc_miss.avg</em>. IMC access is most efficient when all threads within the warp access the same UBO entry. If IMC stalls are excessive and the warp threads access pattern can be very divergent, consider replacing the corresponding UBOs with SSBOs. For a related topic, please also see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_SSBOtoUBO">2.7.1.6. Replace SSBOs with UBOs</a>.</p>
<p><b>No Instruction Stall</b></p>
<p>The cycle count during which a warp is stalled waiting for shader instruction fetch can be measured using <em>smsp__warps_cant_issue_no_instructions.avg</em>. This can be due to:</p><ul>
<li>Instruction fetch speed is not sufficient. This should be rare.</li>
<li>Instruction not yet fetched after a branch.</li>
</ul>
<p>If this stall type's percentage is high, consider experimenting with reducing/altering branches within the shader.</p>
<p><b>Shared Memory Stall</b></p>
<p>The cycle count during which a warp is stalled waiting for shared memory access can be measured using <em>smsp__warps_cant_issue_short_scoreboard.avg</em>. In graphics this translates to ISBE and TRAM accesses for attributes and varyings respectively. Generally the percentage for this stall type should be low.</p>
<p><b>Memory Barrier Stall</b></p>
<p>Warp stall cycles waiting on memory barrier instructions is measured by <em>smsp__warps_cant_issue_membar.avg</em>. Review and tune memory barriers within the shader for possible improvements.</p>
<p><b>Wait Stall</b></p>
<p>The cycle count during which a warp is stalled waiting for math operations to finish can be measured using <em>smsp__warps_cant_issue_wait.avg</em>. Optimizing shader to reduce its instruction count and/or latency may help reduce this stall. See also <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_HalfFloat">2.7.3. Half Float (FP16) Operations</a>.</p>
<p><b>Texture, MIO, and Math Pipe Throttle Stall</b></p>
<p>The set of stalls measured using:</p><ul>
<li><em>smsp__warps_cant_issue_tex_throttle.avg</em></li>
<li><em>smsp__warps_cant_issue_mio_throttle.avg</em></li>
<li><em>smsp__warps_cant_issue_math_pipe_throttle.avg</em></li>
</ul>
<p>Indicates that warps are being stalled due the input interface of texture pipeline, shared memory (ISBE and TRAM) controller, and math units being busy. Note that these stalls are different from the cycles needed to execute these instructions. In theory the percentages for these stalls should be very low. Any high value tend to be due to extremely high amount of the corresponding type of instructions.</p>
<p><b>Drain Stall</b></p>
<p>The cycle count during which a warp is stalled waiting for remaining memory operations to complete after the warp has finished execution can be measured using <em>smsp__warps_cant_issue_drain.avg</em>. Note that this type of stall is different from <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_FragmentWarpPixelDrain">5.8.2.4. Fragment Warp Pixel Drain</a>. The blocking memory operations for this warp drain stall are those that are needed to execute the warp's shader instructions, while the pixel drain described above has nothing to do with the shader content.</p>
<p><b>Not Selected Stall</b></p>
<p>The metric <em>smsp__warps_cant_issue_not_selected.avg</em> shows the cycle count that warps are ready but not selected for execution.</p>
<p><b>Selected Stall</b></p>
<p>The metric <em>smsp__warps_cant_issue_selected.avg</em> measures the cost of issuing a warp instruction. This is usually one cycle per instruction.</p>
<p><b>Tile Allocation Stall</b></p>
<p>Warps are executed in groups called subtiles. The metric <em>smsp__warps_cant_issue_tile_allocation_stall.avg</em> measures the synchronization stalls between warps within a subtile.</p>
<p><b>Allocation Stall</b></p>
<p>Warps can also stall waiting for an execution slot within the SM sub-partition. This is measured by <em>smsp__warps_cant_issue_allocation_stall.avg</em>.</p>
<p><b>Dispatch Stall</b></p>
<p>Warp stall cycles in issuing instruction is measured by <em>smsp__warps_cant_issue_dispatch.avg</em>. This should be very rare.</p>
<p><b>Barrier Stall</b></p>
<p>The metric <em>smsp__warps_cant_issue_barrier.avg</em> is only related to compute workload and can be ignored for graphics optimization.</p>
<p>As an example, the following are values of stall metrics sampled from an NX game's draw pass:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Stall Types   </th><th class="markdownTableHeadNone">Stall Duration (cycles)   </th><th class="markdownTableHeadNone">% of warp latency    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_long_scoreboard   </td><td class="markdownTableBodyNone">16,648,985   </td><td class="markdownTableBodyNone">22.01    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_wait   </td><td class="markdownTableBodyNone">14,614,998   </td><td class="markdownTableBodyNone">19.32    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_selected   </td><td class="markdownTableBodyNone">12,846,059   </td><td class="markdownTableBodyNone">16.98    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_short_scoreboard   </td><td class="markdownTableBodyNone">11,267,427   </td><td class="markdownTableBodyNone">14.89    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_not_selected   </td><td class="markdownTableBodyNone">5,792,233   </td><td class="markdownTableBodyNone">7.66    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_allocation_stall   </td><td class="markdownTableBodyNone">5,587,190   </td><td class="markdownTableBodyNone">7.39    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_no_instructions   </td><td class="markdownTableBodyNone">5,462,913   </td><td class="markdownTableBodyNone">7.22    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_math_pipe_throttle   </td><td class="markdownTableBodyNone">2,252,782   </td><td class="markdownTableBodyNone">2.98    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_drain   </td><td class="markdownTableBodyNone">545,518   </td><td class="markdownTableBodyNone">0.72    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_dispatch_stall   </td><td class="markdownTableBodyNone">315,312   </td><td class="markdownTableBodyNone">0.42    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_imc_miss   </td><td class="markdownTableBodyNone">253,587   </td><td class="markdownTableBodyNone">0.34    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_tex_throttle   </td><td class="markdownTableBodyNone">59,306   </td><td class="markdownTableBodyNone">0.08    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_mio_throttle   </td><td class="markdownTableBodyNone">4,877   </td><td class="markdownTableBodyNone">0.01    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_barrier   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0.00    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">smsp__warps_cant_issue_membar   </td><td class="markdownTableBodyNone">0   </td><td class="markdownTableBodyNone">0.00    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">total_warp_latency   </td><td class="markdownTableBodyNone">75,651,187   </td><td class="markdownTableBodyNone">100.00   </td></tr>
</table>
<p>In the above draw regime, the top 3 stalls are:</p><ul>
<li>Texture operation stalls (long_scoreboard), which may benefit from texture optimizations (see <a class="el" href="gpu_overview__maxwell_profiling_guide_index.html#gpuOverview_MaxwellProfiling_guide_TEX">5.7. TEX (Texture)</a>).</li>
<li>Math operation stalls (wait), which may benefit from general shader optimizations to reduce instruction count and/or latency (see also <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_HalfFloat">2.7.3. Half Float (FP16) Operations</a>).</li>
<li>Instruction issue cost (selected). Because this is more or less a constant cost of 1 cycle-per-instruction, there is usually not much optimization that can be done other than reducing instruction count. In some cases, increasing the number of half-float operations may help if GLSLC is able to increase vectorized instruction count (see <a class="el" href="gpu_overview__maxwell_best_practices_index.html#gpuOverview_MaxwellBestPractices_guide_HalfFloatBenefits">2.7.3.1. Benefits of FP16 Operations</a>).</li>
</ul>
<h1><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_6"></a>
6. Glossary of Terms</h1>
<p>This section lists abbreviations and nvidia-specific terms used in PerfWorks metric names. If the same term applies to different units, each item will be followed by the parent unit's name in parentheses. For example, "fe (host)". Some of the terms below are also described in the "PerfWorks User Guide" and explained in greater details within the <a class="el" href="gpu_overview__maxwell_technical_overview_index.html">Maxwell Technical Overview</a> document. Terms that indicate a GPU hardware unit is written capitalized.</p>
<p><b>ACACHE</b> Attribute Cache. An on-chip cache used by VAF and STRI units. The VAF unit stores fetched attribute to the ACACHE while the STRI unit loads attributes from the ACACHE as input.</p>
<p><b>ADU</b> Address Divergence Unit. A sub-unit of MIOP which handles re-issuing of divergent indexed uniform accesses and divergent branches.</p>
<p><b>BAR</b> Barrier Pipe. A sub-unit of SM which implements barrier operations.</p>
<p><b>BRU</b> Branch Resolution Unit. A sub-unit of SM used for branch resolution.</p>
<p><b>CBC</b> Compression Bit Cache. An on-chip cache used to store metada information for framebuffer compressible surfaces.</p>
<p><b>cbe</b> Circular Buffer Entry. Used to pass data between shader stages, possibly on different SMs.</p>
<p><b>cbf</b> Cull-Before-Fetch. An attribute fetch operation mode where initially only position attributes for a warp is fetched and culled. If all vertices for a warp are frustum culled then the entire warp can be discarded immediately. Please refer to the "GLSLC
Programming Guide" document for further details.</p>
<p><b>CBMGR</b> Circular Buffer Manager. A GPU sub-unit which communicates attributes from Alpha phase to Beta phase, and from Beta phase to raster.</p>
<p><b>CDP</b> Color Data Path. A sub-unit within PROP which performs Alpha Test and Alpha-to-Coverage.</p>
<p><b>channel</b> A stream of command to be processed by the GPU. There can be multiple channel independently processed at any one time.</p>
<p><b>crd</b> CROP Read. A read operation requested by CROP.</p>
<p><b>CRSTR</b> Coarse Raster. A sub-unit of raster which determines primitive coverage over 16x16 tiles.</p>
<p><b>CROP</b> Color ROP. Part of the ROP unit. Performs blending and color write.</p>
<p><b>CSB</b> Color Sync Barrier. A PROP sub-unit which accepts color value inputs from the CDP sub-unit to be reordered as necessary before being passed on to the CROP unit.</p>
<p><b>cta</b> Cooperative Thread Array, also known as a thread block.</p>
<p><b>ctxsw</b> Context Switch. The event of switching between execution of 2 channels which requires saving of the current channel's context and restoring the next channel's context.</p>
<p><b>CWD</b> Compute Work Distributor. A unit which distributes compute thread blocks to SMs.</p>
<p><b>FBP</b> Frame Buffer Partition. A major unit which contains the L2, ROP, and on discrete GPU, the DRAM controller.</p>
<p><b>FE (host)</b> Host Front End. A HOST sub-unit that decodes GPU commands and sends them to engines.</p>
<p><b>FE (SM)</b> SM Front End. A sub-unit of SM which tracks scoreboard dependencies from decoupled instructions, and accelerates shader-based clipping (gl_ClipDistance).</p>
<p><b>FMA64PLUS</b> Fast 64-bit Float Instruction Pipe. A sub-unit of SM which handles fast 64-bit floating point operations. This does not exist for NX hardware.</p>
<p><b>FMA64PLUSPLUS</b> 64-bit Float Instruction Pipe. A sub-unit of SM which handles 64-bit floating point operations.</p>
<p><b>FMAI</b> An ALU pipe within SMSP which handles integer and float ADD, MUL, MAD, MOV, and bitwise operations.</p>
<p><b>FP16</b> 16-bit Float Instruction Pipe. A sub-unit of SM which handles 16-bit floating point operations.</p>
<p><b>FRSTR</b> Fine Raster. A sub-unit of RASTER which determines which samples of a subtile (8x8 or 16x4) are covered by a primitive.</p>
<p><b>FXU</b> An ALU pipe within smsp which has all the functionality of an FMAI pipe and can also handle integer and float comparisons and shift operations.</p>
<p><b>GCC</b> GPC Cache Controller. A unit which contains and manages "level
1.5" instruction and uniform caches as well as the TSL2 cache (see separate description below).</p>
<p><b>GNIC</b> GPC Network Interconnect. A unit which functions as a port to the XBAR.</p>
<p><b>GPC</b> GPU Processing Cluster. A scalable HW block including most fixed function graphics units, and multiple TPCs.</p>
<p><b>gpfifo</b> Circular buffer containing commands, data, pointers to data, and pointers to pushbuffer segments to be processed by the GPU.</p>
<p><b>GPMPD</b> Graphics Pipe Manager Primitive Distributor. A sub-unit of HUB which distributes initial geometry work to MPCs.</p>
<p><b>GPMSD</b> Graphics Pipe Manager Screen-Space Distributor. A unit which distributes fragment work to MPCs.</p>
<p><b>gr</b> Graphics Engine. The GPU's graphics and compute engine.</p>
<p><b>gs</b> Geometry Shader.</p>
<p><b>HOST</b> Work scheduling unit in the GPU. A HOST unit determines the order in which input command streams are executed and dispatches work to the proper engines.</p>
<p><b>ICC</b> Instruction Cache. An on-chip cache used to store shader program instructions.</p>
<p><b>IMC</b> Immediate Constant Cache. An on-chip cache used to store uniform values accessed from a constant address across all threads of a warp.</p>
<p><b>IDC</b> Indexed Constant Cache. An on-chip cache used to store uniform values accessed from an indexed address, which may diverge between threads of a single warp.</p>
<p><b>ISBE</b> Inter-Stage Buffer Entry. A structure that passes data between PE and SM and between shader stages on the same SM (vs to tcs and tes to gs). Can also refer to the region of shared memory used to store these entries.</p>
<p><b>L15</b> L1.5 Texture Unit. A cache within the GCC unit used to store uniform and instruction data.</p>
<p><b>L1TEX</b> L1 Texture Unit. This unit, also referred to as TEX, receives texture coordinates from the SMs, fetches texel data, and performs bilinear/trilinear/aniso filtering. It contains an L1 cache to improve locality. On Maxwell and Pascal GPUs, this unit is also responsible for global, local, and surface loads and stores.</p>
<p><b>LDC</b> Load Constant Pipe. A sub-unit of MIOP which handles the loading of indexed uniforms from the IDC cache. Note that non-indexed uniforms typically do not flow through this pipe, and are instead direct operands of ALU instructions, read via the IMC cache.</p>
<p><b>LSU</b> Load Store Unit. A sub-unit of SM which handles shared memory operations, shuffle, and world space shader attribute loads and stores. It also handles local/global memory address generation, prior to issuing the instruction through the texture unit.</p>
<p><b>LTC</b> L2 Cache Unit. This unit contains LTS and RASTER operation units (CROP, ZROP and RDM).</p>
<p><b>LTCX</b> On mobile GPUs, each LTS connects to the MCCIF via an LTCX. Contains queueing and coalescing logic.</p>
<p><b>LTS</b> L2 Data Cache Slice. The basic building block of the L2 data cache.</p>
<p><b>MCCIF</b> Memory Controller Interface. This unit sends read and write requests from LTCX to MSS.</p>
<p><b>MIO</b> Memory Input Output. This SM sub-unit manages the input and output of instructions and memory traffic between SM partitions and the rest of the SM and GPU. It contains the sub-units MIOC, MIOP, and MIOS.</p>
<p><b>MIOC</b> Memory Input Output Controller. A sub-unit of MIO which arbitrates and send instructions and memory requests to the appropriate destinations.</p>
<p><b>MIOP</b> Memory Input Output Partition. A sub-unit of MIO which handles instruction and memory traffic from a single SM partition. Each SM partition is serviced by a dedicated MIOP sub-unit.</p>
<p><b>MIOS</b> Memory Input Output Shared. A sub-unit of MIO which is shared between 2 SM partitions. It contains and manages the shared memory from which TRAM, ISBE, and compute shared memory are allocated. It also directs memory traffic between the SM partitions and the PE, PIXOUT, and TEX units.</p>
<p><b>MME</b> Macro Method Expander. A sub-unit of the FE which processes macro commands.</p>
<p><b>MPC</b> Modular Pipe Controller. Allocates resources and launches work to a given SM.</p>
<p><b>MSS</b> Memory Subsystem. On NX, the MSS contains the DRAM controller. This unit resides outside of the GPU, and handles CPU traffic as well.</p>
<p><b>PDA</b> Primitive Distributor Alpha. A sub-unit of PD which assembles primitives from memory buffers and sends them to the GPCs.</p>
<p><b>PDB</b> Primitive Distributor Beta. A sub-unit of PD which distributes geometry and/or tessellation shading to GPCs.</p>
<p><b>pde</b> Page Directory Entry. An entry in the GPU memory page table which points to a list of page table entries</p>
<p><b>PE</b> Primitive engine. A collection of fixed function units that work on geometry data. PE is divided into 2 parts: a PEL sub-unit, which contains units allocated per-TPC, and a PES sub-unit that contains units shared by 2 TPCs.</p>
<p><b>PEL</b> Primitive Engine Local. A per-TPC block that contains VAF and STRI sub-units.</p>
<p><b>PES</b> Primitive Engine Shared. A unit shared by TPCs, that performs tessellation and contains the VSC, TGA, and TGB units.</p>
<p><b>PIXOUT</b> Pixel Out. An interface which routes shader fragments from SM to the prop's CDP unit.</p>
<p><b>PROP</b> Pre-Rop. A unit which is responsible for sending pixel work to TPCs and ROPs.</p>
<p><b>ps</b> Pixel Shader, equivalent to fragment shader for GLSL.</p>
<p><b>pte</b> Page Table Entry. An entry in the GPU memory page table which points to a physical page in memory.</p>
<p><b>RASTER</b> A unit which that translates primitives into pixel work. Contains SETUP, CRSTR, ZCULL, FRSTR, and TC sub-units.</p>
<p><b>RDM</b> ROP Data Manager. A sub-unit of LTC which receives CROP and ZROP commands from GPCs, and distributes them to the appropriate destination.</p>
<p><b>SCC</b> State Cache Controller. A unit which handles state and constant versioning for the graphics pipeline.</p>
<p><b>SETUP</b> A unit that takes the primitive's screen-space x, y and z coordinates and generates edge equations for the rasterizer, a plane equation for z, and partial results used by the PE's STRI unit to calculate attribute plane equations.</p>
<p><b>shdz</b> Shader Z. Depth value generated by the fragment shader.</p>
<p><b>SKED</b> This unit maintains the list of outstanding compute tasks, and sends them to the CWD.</p>
<p><b>SM</b> Streaming Multiprocessor. A core processing unit in the GPU, running all shader programs.</p>
<p><b>SMP</b> Streaming Multiprocessor Partition. This is a physical partition of the shared resources in SM.</p>
<p><b>SMSP</b> Streaming Multiprocessor Sub-Partition. This unit contains a warp scheduler, register file, and dedicated execution units.</p>
<p><b>STREAM</b> Stream Output. If enabled, this unit writes primitive data to memory before clip/cull. STREAM is known as "transform feedback" on some APIs.</p>
<p><b>STRI</b> Shader TRI. A sub-unit of PE that calculates plane equations for attributes for the pixel shader. Results are stored in the TRAM area of shared memory.</p>
<p><b>SU</b> Special Unit. A sub-unit of SM which implements instructions for fragment shader attribute interpolation.</p>
<p><b>subch</b> Sub-Channel. A subdivision of the commands within a channel to be executed by a specific GPU pipeline such as graphics, compute, and copy engine.</p>
<p><b>SWDX</b> Screen Work Distributor Crossbar. This unit receives work from the XBAR, and sends primitives to RASTER. SWDX performs the binning and tiling steps for tiled caching.</p>
<p><b>TC</b> Tile Coalescer.</p>
<p><b>tcs</b> Tesselation Control Shader.</p>
<p><b>tes</b> Tesselation Evaluation Shader.</p>
<p><b>TEX</b> See l1tex description above.</p>
<p><b>TGA</b> Task Generator Alpha.</p>
<p><b>TGB</b> Topology Generator Beta.</p>
<p><b>TPC</b> Texture Processing cluster. A unit within the GPC that contains the SM, MPC, PEL and two TEX units.</p>
<p><b>TRAM</b> Triangle RAM. A region of shared memory where per-attribute, per-primitive plane equations are stored for per-pixel evaluation.</p>
<p><b>TSL1</b> Texture Sampler L1 Cache. A cache within TEX used to store texture header and sampler entries.</p>
<p><b>TSL2</b> Texture Sampler L2 Cache. A cache within GCC used to store texture header and sampler entries.</p>
<p><b>VAF</b> Vertex attribute fetch. A sub-unit of PE that fetches and formats input vertex data for use as input by vertex shader programs.</p>
<p><b>VPC</b> Viewport Clip Cull.</p>
<p><b>vs</b> Vertex Shader.</p>
<p><b>vsa</b> Vertex Shader A. The first phase vertex shader when cbf is enabled. Please refer to Cull-Before-Fetch in "GLSLC Programming
Guide" for further details.</p>
<p><b>vsb</b> Vertex Shader B. The second phase vertex shader when cbf is enabled. Please refer to Cull-Before-Fetch in "GLSLC Programming
Guide" for further details.</p>
<p><b>wfi</b> Wait For Idle. A command which causes the GPU to stall until all in-flight commands being processed have been completed.</p>
<p><b>WWDX</b> World Work Distributor Crossbar. This unit sends primitives at the end of the world pipe to the XBAR bus, destined to SWDX and RASTER.</p>
<p><b>XBAR</b> Crossbar. An interconnect which links together all of the GPU's major units.</p>
<p><b>XU</b> Extended Unit. A sub-unit of SM which implements transcendental operations and int to float conversions.</p>
<p><b>ZCULL</b> A sub-unit of RASTER which has a low resolution on-chip Z-buffer to trivially accept or reject tiles based on conservative depth comparison.</p>
<p><b>zrd</b> ZROP Read. A read operation requested by the ZROP.</p>
<p><b>ZROP</b> Z RASTER Operation. A ROP unit that performs depth (Z) and stencil read, compare, and conditional write.</p>
<h1><a class="anchor" id="gpuOverview_MaxwellProfilingGuide_guide_sec_7"></a>
7. Appendix</h1>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_WorldSpaceAlphaOnlyDiagram"></a>
7.1. World-Space Data and Command Paths (Alpha Phase Only)</h2>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img17.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 19: World Space Graphics Workflow (Alpha Phase Only)</b> </div><p> <br  />
</p>
<h2><a class="anchor" id="gpuOverview_MaxwellProfiling_guide_ScreenSpaceLateZModeDiagram"></a>
7.2. Screen-Space Data and Command Paths (LateZ Mode)</h2>
<div class="image">
<img src="MaxwellPerfWorksProfilingGuide_img18.jpg" alt=""/>
</div>
 <div style="text-align: center;" markdown="1"> <b>Figure 20: Screen Space Graphics Workflow (LateZ Mode)</b> </div><p> <br  />
 </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- HTML footer for doxygen 1.9.1-->
<!-- start footer part -->
</body>
</html>
