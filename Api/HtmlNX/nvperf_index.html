<!-- HTML header for doxygen 1.9.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NVIDIA PerfWorks User Guide | NintendoSDK API Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="openclose.js"></script>
<script type="text/javascript" src="searchapi.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NintendoSDK API Reference
   &#160;<span id="projectnumber">14.1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="_page_graphics_for_n_x.html">Graphics Environment for NX</a></li>  </ul>
</div>
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">NVIDIA PerfWorks User Guide </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_PerfWorks_User_Guide"></a></p>
<h1><a class="anchor" id="autotoc_md117"></a>
API Concepts</h1>
<p>Note: "NvPerf" is the abbreviation for "NVIDIA Perfworks".</p>
<p>The PerfWorks API allows you to instrument an application and collect <a href="#Metric">metrics</a>. Metrics consist of low-level GPU <a href="#Counter">counters</a>, and high-level calculations that take those counters as input. Counters are collected per <a href="#User">user</a>-defined-<a href="#Range">range</a> or per individual <a href="#Workload">workload</a>.</p>
<p>PerfWorks currently supports <a href="#Range_Based_Profiling">range-based profiling</a> on a variety of GPUs and APIs.</p>
<p>Realtime is currently supported through range-based profiling.</p>
<h2><a class="anchor" id="autotoc_md118"></a>
Isolated vs Pipelined Metrics</h2>
<p>Isolated metrics capture the <em>total cost</em> of a <a href="#Range">range</a> of work, in isolation. To capture isolated results, PerfWorks inserts commands that cause a GPU-wait at each range boundary. PerfWorks will never issue GPU-wait commands inside an isolated range.</p>
<p>Pipelined metrics capture the <em>incremental cost</em> of a <a href="#Range">range</a> of work. The incremental cost of a range is measured from the moment all preceding work has completed until the end of that range.</p>
<p>Isolated metrics and pipelined metrics are collected on separate passes.</p>
<h2><a class="anchor" id="autotoc_md119"></a>
Multi-Pass Collection</h2>
<p>NVIDIA GPU hardware has a limited number of <a href="#Counter">counter</a> registers, and cannot collect all possible counters concurrently. There are also limitations on which counters can be collected together in a single <a href="#Pass">pass</a>.</p>
<p>PerfWorks resolves these problems by requiring <a href="#You">you</a> to replay the exact same set of GPU workloads multiple times, where each replay is termed a <a href="#Pass">pass</a>. On each <a href="#Pass">pass</a>, PerfWorks collects a different subset of the requested <a href="#Counter">counters</a>. Once all <a href="#Pass">passes</a> have completed, all <a href="#Counter">counter</a> values are made available to read back. This overall process is termed <em>multi-pass collection</em>.</p>
<p>Certain metrics require a large number of counters as inputs; adding a single metric may require a large number of passes to collect. For example, a unit sol metric would require a large number of passes, since it will take inputs from every stage within the unit.</p>
<p>Isolated metrics require one <a href="#Pass">pass</a> per nesting-level of ranges in the program. That is, if your application creates 3-deep nested ranges, each <a href="#Counter">counter</a> must be re-collected <code>3</code> times. If the configuration requires <code>7</code> passes, then a total of <code>3*7 = 21</code> execution passes will be required.</p>
<p><a class="anchor" id="Workflow"></a></p>
<h1><a class="anchor" id="autotoc_md120"></a>
Workflow</h1>
<p>The PerfWorks API is split into 3 conceptual phases: configuration, collection, evaluation. These phases define the normal workflow for a host and target.</p>
<p><img src="data_flow_realtime.png" alt="" class="inline" title="Data Flow Realtime"/> <img src="data_flow_range_profiler.png" alt="" class="inline" title="Data Flow Range Profiler"/></p>
<p>The following sections contain code recipes that show the prescribed set of calls to accomplish a goal, without intervening error checking. Since each NVPA_ function may fail in real-world usage, working code will be more complex than it appears in the recipes.</p>
<p><a class="anchor" id="ConfigurationSection"></a></p>
<h2><a class="anchor" id="autotoc_md121"></a>
Configuration</h2>
<p>Configuration is the process of specifying the metrics that will be collected and how those metrics should be collected. The inputs for this stage are the metric names and metric collection properties. The output for this stage is a <b>ConfigImage</b> and a <b>CounterDataPrefix</b> Image.</p>
<p>There are two metric layers: <b>Raw Metrics</b> and <b>Derived Metrics</b>. The Raw Metrics layer contains the list of raw counters supported by the GPU, and can directly configure them. The Derived Metrics layer provides calculated metrics; each metric can report the set of Raw Metric dependencies needed to perform the calculation.</p>
<h3><a class="anchor" id="autotoc_md122"></a>
Derived Metrics Layer</h3>
<p>From the host PC, you can enumerate metrics with these commands: </p><div class="fragment"><div class="line">nvperf list throughputs --gpu=gm20b</div>
<div class="line">nvperf list metrics --gpu=gm20b</div>
<div class="line">nvperf list metrics --gpu=gm20b --csv</div>
<div class="line">nvperf list metrics --gpu=gm20b --submetrics --csv</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md123"></a>
RawMetrics Layer</h3>
<p>During <b>ConfigImage</b> generation, PerfWorks schedules the specified metrics into passes. See the section on <a href="#Range_Based_Profiling">range-based profiling</a> for details on metric configuration modes and behaviors.</p>
<p>During <b>CounterDataPrefix</b> Image generation, PerfWorks determines the <a href="#Counter">counter</a> dependencies for each metric and writes meta data into the prefix image. On the target before collection, the <b>CounterDataPrefix</b> is used to generate a <b>CounterDataImage</b>; the size of the <b>CounterDataImage</b> is a function of the number of ranges <a href="#You">you</a> wish to collect.</p>
<p>During collection, PerfWorks uses the ConfigImage to program the GPU at the start of each pass, and writes the results to the corresponding location in the <b>CounterData</b> Image.</p>
<p>A <b>ConfigImage</b> and <b>CounterDataImage</b> are allowed to not match. In simple workflows, both the <b>ConfigImage</b> and the <b>CounterData</b> are created together so that every configured <a href="#Counter">counter</a> is stored. Advanced use-cases include "incremental collection", where a <b>CounterData</b> has space for counters {A, B, C, D}, but collection is split into 2 <b>ConfigImages</b> each containing only {A, B}, {C, D}. The counters can be collected over two separate sessions, and accumulated into a single <b>CounterDataImage</b>.</p>
<p>Configuration can occur offline or online. Configuration can also occur on the host or target device. Keep in mind that if configuration occurs on the target, it will incur some CPU and memory overhead.</p>
<p>Boundary conditions:</p>
<ul>
<li>If the <b>ConfigImage</b> contains counters that are missing from the <b>CounterData</b> list, those counters are read from the GPU, but then discarded.</li>
<li>If the <b>CounterDataImage</b> contains counters that are missing from the <b>ConfigImage</b> list, those counters in the <b>CounterDataImage</b> will remain unmodified during any session that uses the <b>ConfigImage</b>.</li>
<li>If a <b>CounterDataImage</b> is sized for fewer ranges than executed on the GPU, the results for the last set of ranges will be discarded.</li>
</ul>
<h3><a class="anchor" id="autotoc_md124"></a>
Offline Generation of the ConfigImage using nvperf</h3>
<p>nvperf accepts Derived Metric names.</p>
<p>Note: Using nvperf to offline generate the configuration image, a single pass-group is always created.</p>
<p>From the Host PC, run the following commandline tool: </p><div class="fragment"><div class="line">nvperf configure --gpu &lt;target gpu&gt; --out &lt;filename&gt; [metrics] ...</div>
</div><!-- fragment --><p>For example, to configure the metrics <em>gpu__shaded_fragments.sum</em> and <em>smsp__pixels_killed_by_shader.sum</em> for <b>gm20b</b>: </p><div class="fragment"><div class="line">nvperf configure --gpu gm20b --out config.image  gpu__shaded_fragments.sum  smsp__pixels_killed_by_shader.sum</div>
</div><!-- fragment --><p>Note the above metrics are the "sum" of a counter value. For more detail on the relationship between metrics and counters, please consult the <a href="#MetricsChapter">Metrics chapter</a>.</p>
<p>When specifying a metric name on the command line, the following characters can be appended to the end of the name to affect its collection:</p>
<ul>
<li>+ - set <code>keepInstances</code> true</li>
<li>$ - set <code>isolated</code> true (Default)</li>
<li>&amp; - set <code>isolated</code> false (aka. pipelined)</li>
</ul>
<p>nvperf also accepts "response files" for commandline arguments, which allows passing long lists of metric names via a file. Response files are specified with an '@' symbol. For example: </p><div class="fragment"><div class="line">cat &gt; metric_names.txt</div>
<div class="line">gpu__shaded_fragments.sum</div>
<div class="line">smsp__pixels_killed_by_shader.sum</div>
<div class="line">^D</div>
<div class="line"> </div>
<div class="line">nvperf configure --gpu gm20b --out config.image @metric_names.txt</div>
</div><!-- fragment --><p> <a class="anchor" id="OnlineConfigImage"></a></p>
<h3><a class="anchor" id="autotoc_md125"></a>
Online Generation of the ConfigImage</h3>
<p>Online generation of the ConfigImage gives you complete control over metric configuration.</p>
<div class="fragment"><div class="line"><span class="comment">// generate list of metric requests</span></div>
<div class="line">NVPA_RawMetricRequest requests[2];</div>
<div class="line">requests[0].pMetricName   = <span class="stringliteral">&quot;gpu__shaded_fragments&quot;</span>;</div>
<div class="line">requests[0].isolated      = <span class="keyword">true</span>;</div>
<div class="line">requests[0].keepInstances = <span class="keyword">false</span>;</div>
<div class="line">requests[1].pMetricName   = <span class="stringliteral">&quot;smsp__pixels_killed_by_shader&quot;</span>;</div>
<div class="line">requests[1].isolated      = <span class="keyword">false</span>;</div>
<div class="line">requests[1].keepInstances = <span class="keyword">false</span>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// set configuration options</span></div>
<div class="line">NVPA_RawMetricsConfigOptions configOptions = { NVPA_RAW_METRICS_CONFIG_OPTIONS_STRUCT_SIZE };</div>
<div class="line">options.activityKind = <a class="code" href="nvperf__common_8h.html#a185c285d78299004540732d0d228fbc6a003151b80ca105b7a3d6bca7b202e56f">NVPA_ACTIVITY_KIND_PROFILER</a>;</div>
<div class="line">options.pChipName = <span class="stringliteral">&quot;gm20b&quot;</span>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// create the config object</span></div>
<div class="line">NVPA_RawMetricsConfig&amp; pConfig;</div>
<div class="line">NVPA_Raw_MetricsConfig_Create(&amp;configOptions, &amp;pConfig);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// add metrics to the config object</span></div>
<div class="line">NVPA_RawMetricsPassGroupOptions passGroupOptions = { NVPA_RAW_METRICS_PASS_GROUP_OPTIONS_STRUCT_SIZE };</div>
<div class="line">NVPA_RawMetricsConfig_BeginPassGroup(pConfig, &amp;passGroupOptions);</div>
<div class="line">NVPA_RawMetricsConfig_AddMetrics(pConfig, requests, 2);</div>
<div class="line">NVPA_RawMetricsConfig_EndPassGroup(pConfig);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// generate config image</span></div>
<div class="line">NVPA_RawMetricsConfig_GenerateConfigImage(pConfig);</div>
<div class="line"><span class="keywordtype">size_t</span> configImageSize = 0;</div>
<div class="line">NVPA_RawMetricsConfig_GetConfigImage(pConfig, 0, <span class="keyword">nullptr</span>, &amp;configImageSize);</div>
<div class="line">std::vector&lt;uint8_t&gt; configImage;</div>
<div class="line">configImage.resize(configImageSize);</div>
<div class="line">NVPA_RawMetricsConfig_GetConfigImage(pConfig, configImage.size(), &amp;configImage[0], <span class="keyword">nullptr</span>);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// can now use configImage directly for BeginSession()</span></div>
<div class="ttc" id="anvperf__common_8h_html_a185c285d78299004540732d0d228fbc6a003151b80ca105b7a3d6bca7b202e56f"><div class="ttname"><a href="nvperf__common_8h.html#a185c285d78299004540732d0d228fbc6a003151b80ca105b7a3d6bca7b202e56f">NVPA_ACTIVITY_KIND_PROFILER</a></div><div class="ttdeci">@ NVPA_ACTIVITY_KIND_PROFILER</div><div class="ttdoc">A workload-centric activity for serialized and pipelined collection.</div><div class="ttdef"><b>Definition:</b> nvperf_common.h:141</div></div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md126"></a>
Offline Generation of the CounterDataPrefix Image using nvperf</h3>
<div class="fragment"><div class="line">nvperf initdata --gpu &lt;target gpu&gt; --out &lt;filename&gt; [metrics]...</div>
</div><!-- fragment --><p>Example: </p><div class="fragment"><div class="line">nvperf initdata --gpu gm20b --out couterdataprefix.image gpu__shaded_fragments smsp__pixels_killed_by_shader</div>
</div><!-- fragment --><p>Note: When configuring for offline evaluation, you must specify <code>keepInstances=true</code> on all metrics by appending a <code>+</code> character.</p>
<h3><a class="anchor" id="autotoc_md127"></a>
Online Generation of the CounterDataPrefix Image</h3>
<div class="fragment"><div class="line"><span class="comment">// generate list of metric requests</span></div>
<div class="line">NVPA_RawMetricRequest requests[2];</div>
<div class="line">requests[0].pMetricName   = <span class="stringliteral">&quot;gpu__shaded_fragments&quot;</span>;</div>
<div class="line">requests[0].isolated      = <span class="keyword">true</span>;</div>
<div class="line">requests[0].keepInstances = <span class="keyword">false</span>;</div>
<div class="line">requests[1].pMetricName   = <span class="stringliteral">&quot;smsp__pixels_killed_by_shader&quot;</span>;</div>
<div class="line">requests[1].isolated      = <span class="keyword">false</span>;</div>
<div class="line">requests[1].keepInstances = <span class="keyword">false</span>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// set builder options</span></div>
<div class="line">NVPA_CounterDataBuilderOptions counterDataBuilderOptions = { NVPA_COUNTER_DATA_BUILDER_OPTIONS_STRUCT_SIZE };</div>
<div class="line">counterDataBuilderOptions.pChipName = <span class="stringliteral">&quot;gm20b&quot;</span>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// create the builder object</span></div>
<div class="line">NVPA_CounterDataBuilder* pCounterDataBuilder;</div>
<div class="line">NVPA_CounterDataBuilder_Create(&amp;counterDataBuilderOptions, &amp;pCounterDataBuilder);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// add metrics to the builder object</span></div>
<div class="line">NVPA_CounterDataBuilder_AddMetrics(pCounterDataBuilder, requests, 2);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// create the CounterDataPrefix image</span></div>
<div class="line"><span class="keywordtype">size_t</span> counterDataPrefixSize = 0;</div>
<div class="line">NVPA_CounterDataBuilder_GetCounterDataPrefix(pCounterDataBuilder, 0, <span class="keyword">nullptr</span>, &amp;counterDataPrefixSize);</div>
<div class="line">std::vector&lt;uint8_t&gt; counterDataImagePrefix;</div>
<div class="line">NVPA_CounterDataBuilder_GetCounterDataPrefix(pCounterDataBuilder, counterDataImagePrefix.size(), &amp;counterDataImagePrefix[0], <span class="keyword">nullptr</span>);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// can now use counterDataPrefix to create a full counterData</span></div>
</div><!-- fragment --><p>Note: When configuring for offline evaluation, you must specify <code>keepInstances=true</code> on all metrics.</p>
<p><a class="anchor" id="CollectionOnTarget"></a></p>
<h2><a class="anchor" id="autotoc_md128"></a>
Collection on Target</h2>
<p>The outline for profiling:</p>
<ul>
<li><b>Allocate</b> buffers for profiling.</li>
<li><b>BeginSession</b> with the pre-allocated buffers and ConfigImage. This step initializes hardware.</li>
<li>For each replay of the frame (until <code>allPassesSubmitted</code>):<ul>
<li><b>BeginPass</b> : submits commands that apply current pass' configuration to hardware, including the perfmon system.</li>
<li><b>Submit</b> GPU work to be profiled, via <code>nvnQueueSubmitCommands</code>.<ul>
<li>Profiled ranges in commandBuffers must be delimited by NVN <code>Push/PopDebugGroup</code> or PerfWorks <code>Push/PopRange</code> calls.</li>
</ul>
</li>
<li><b>EndPass</b> : submits commands that flush the hardware counters and disables the perfmon system.</li>
<li><b>DecodeCounters</b> : populates the CounterData Image. Recommended to be called once per EndPass.</li>
</ul>
</li>
<li>Call <code>nvnQueueFinish()</code> or replay the frame and call <code>DecodeCounters()</code> until <code>allPassesDecoded</code>.</li>
<li>At any time, counter and metric values can be queried from the CounterData Image via Metrics APIs. ** caveat: if all passes have not been collected and decoded, counter and metric values will be incomplete, signified by <code>NaN</code> values</li>
<li><b>EndSession</b> when profiling complete, to free up gpu resources.<ul>
<li>Before calling EndSession, the application must ensure that all previously submitted GPU commands from BeginPass, Push/Pop, or EndPass have completed execution. Calling EndSession before these operations have executed on the GPU will result in undefined behavior. The simplest method is to call <code>nvnQueueFinish()</code> before EndSession, but it's the application's responsibility to ensure that no deadlock would occur by calling it.</li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md129"></a>
Allocating the Full CounterData Image</h3>
<p>A <b>CounterData</b> image allocates space for values for each counter for each range. The <b>CounterDataPrefix</b> only contains some meta data about the metrics that will be stored. A full <b>CounterDataImage</b> with space allocated for the values still needs to be created before a profiling session can begin. Note that a <b>CounterData</b> image only stores counter values for a single <a href="#Iteration">iteration</a> . Following the collection of an <a href="#Iteration">iteration</a> , the <b>CounterDataImage</b> may be used for metric evaluation. In realtime profiling or on target metric evaluation, the <b>CounterDataImage</b> can be reused once the metrics have been evaluated. If multiple <b>CounterData</b>'s are needed, a single <b>CounterDataPrefix</b> can be used to initialize all of them.</p>
<div class="fragment"><div class="line"><span class="comment">// Create a **CounterDataPrefix** image or read one in from a file that was generated offline</span></div>
<div class="line"><span class="comment">//   See above sections on how to generate</span></div>
<div class="line">std::vector&lt;uint8_t&gt; counterDataImagePrefix = ...;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// upper bound on number of ranges - too low and data will be dropped during collection</span></div>
<div class="line">uint32_t maxNumRanges =...;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// for shared configuration between iterations</span></div>
<div class="line">NVPA_NVNC_CounterDataImageOptions counterDataImageOptions = { NVPA_NVNC_COUNTER_DATA_IMAGE_OPTIONS_STRUCT_SIZE };</div>
<div class="line">counterDataImageOptions.pCounterDataPrefix = &amp;counterDataImagePrefix[0];</div>
<div class="line">counterDataImageOptions.counterDataPrefixSize = counterDataImagePrefix.size();</div>
<div class="line">counterDataImageOptions.maxNumRanges = maxNumRanges;</div>
<div class="line">counterDataImageOptions.maxNumRangeTreeNodes = maxNumRanges;</div>
<div class="line">counterDataImageOptions.maxRangeNameLength = 64;</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">size_t</span> counterDataImageSize = 0;</div>
<div class="line">NVPA_NVNC_CalculateCounterDataImageSize(&amp;counterDataImageOptions, &amp;counterDataImageSize);</div>
<div class="line">std::vector&lt;std::vector&lt;uint8_t&gt;&gt; counterDataImages;</div>
<div class="line"><span class="keywordflow">for</span>(uint32_t iterationId = 0; iterationId &lt; num_iterations; ++iterationId)</div>
<div class="line">{</div>
<div class="line">    counterDataImages[iterationId].resize(counterDataImageSize);</div>
<div class="line">    NVPA_NVNC_InitializeCounterDataImage(&amp;counterDataImageOptions, counterDataImageSize, &amp;counterDataImages[iterationId][0]);</div>
<div class="line">}</div>
</div><!-- fragment --><p>Typically, a realtime HUD needs to show fresh values on every frame. In such a case, before reusing a <b>CounterData</b> image over multiple frames, the image should be re-initialized by making a call to <code>NVPA_NVNC_InitializeCounterDataImage</code>. This ensures that the data is cleared for the next <a href="#Iteration">iteration</a> . If the image is reused without clearing the data, the next iteration will accumulate into the previous <a href="#Iteration">iteration</a> . Reuse without re-initialization could be intended usage if you want to average results over many iterations.</p>
<h3><a class="anchor" id="autotoc_md130"></a>
Allocating the CounterData Scratch Buffer</h3>
<p>PerfWorks does not allocate any internal buffers itself; this is left to the application. For some internal operations on the <b>CounterDataImage</b>, PerfWorks requires some temporary storage. This is what the <b>CounterData</b> scratch buffer is for.</p>
<div class="fragment"><div class="line"><span class="comment">// CounterData image previously generated, see above sections</span></div>
<div class="line">uint8_t* pCounterDataImage = ...;</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">size_t</span> counterDataScratchBufferSize = 0;</div>
<div class="line">NVPA_NVNC_CalculateCounterDataScratchBufferSize(pCounterDataImage, &amp;counterDataScratchBufferSize);</div>
<div class="line">std::vector&lt;uint8_t&gt; counterDataScratchBuffer;</div>
<div class="line">counterDataScratchBuffer.resize(counterDataScratchBufferSize);</div>
<div class="line">NVPA_NVNC_InitializeCounterDataScratchBuffer(pCounterDataImage, counterDataScratchBuffer.size(), &amp;counterDataScratchBuffer[0]);</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"><span class="comment">// counterDataScratchBuffer is now ready to be passed to BeginSession</span></div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md131"></a>
BeginSession</h3>
<p>The call to <code>NVPA_NVNC_BeginSession</code> sets the gpu up for collection, though collection won't begin until <code>NVPA_NVNC_BeginPass</code>. To call BeginSession, GPU-mapped buffers must be allocated and passed to BeginSession via <code>NVPA_NVNC_SessionOptions</code>. Perfworks requires the following buffers to be allocated by the client:</p>
<ol type="1">
<li><p class="startli"><b>TraceArena</b> - a set of <b>TraceBuffers</b></p>
<p class="startli">The <b>TraceBuffer</b> is used to store range metadata from the GPU, and can be sized with the following: </p><pre class="fragment">// If using a PushRangeDynamic for your range markers, the range descriptions must be stored after each corresponding record
//   This provides storage for the dynamic strings in the buffer
// If only using PushRangeStatic, this can be set to 0
const size_t avgDynamicStringLength = 64;

// upper bound to the number of ranges in the frame.  Each range, including repeated ranges, will create a record in the buffer
const size_t maxNumRanges = ...;

// NVPA_NVN_TRACE_BUFFER_PAD_SIZE - PerfWorks defined pad size to avoid complicated boundary checks on the gpu
// 2x - each range will write a start and end record
const size_t traceBufferSize = NVPA_NVN_TRACE_BUFFER_PAD_SIZE + maxNumRanges * (2 * NVPA_NVN_TRACE_RECORD_SIZE + avgDynamicStringLength);
</pre><p> For replay-based profiling, if you insert an <code>nvnQueueFinish</code> between every <code>EndPass</code> and <code>DecodeCounters</code>, only one TraceBuffer is required.</p>
<p class="startli">For realtime profiling, like most buffers in graphics applications, the number of required TraceBuffers is a function of the swap-chain size, with additional buffers needed for software-pipelining. On a given frame, buffers typically fulfill the following roles (assuming double-buffering):</p><ul>
<li>[0] : Submitted commands are enqueuing writes into the current TraceBuffer.</li>
<li>[-1] : GPU is executing commands to prepare the display's back-buffer, and is actively writing this TraceBuffer. Unsafe to decode from the CPU.</li>
<li>[-2] : GPU has fully written this TraceBuffer. Corresponds to display's front-buffer. Safe to decode from the CPU.</li>
<li>[-3] : One additional buffer to avoid a race-condition between reading from the CPU and writes from the current frame's GPU commands.</li>
</ul>
<p class="startli">So the recommended number of buffers in realtime = <code>swapChainSize + 2</code>. </p><pre class="fragment">// set to swap chain size + 2; for example with double buffering, set this to 4.
const numTraceBuffers = ...;
const size_t traceArenaSize = numTraceBuffers * traceBufferSize;
</pre><p> The <b>TraceArena</b> is a single <code><a class="el" href="struct_n_v_nmemory_pool.html" title="Block of GPU-accessible memory that can be used for storage of buffer and texture objects.">NVNmemoryPool</a></code> with suggested <code>(NVN_MEMORY_POOL_FLAGS_CPU_UNCACHED_BIT | NVN_MEMORY_POOL_FLAGS_GPU_CACHED_BIT)</code> bits. CPU_CACHED_BIT is acceptable, but PerfWorks will only read from the <b>TraceArena</b>, no writes. The GPU will write to the <b>TraceArena</b> frequently, so GPU_CACHED_BIT is preferred for increased performance. </p><pre class="fragment">// initialize memory pool with the above given constraints
NVNmemoryPool traceArena = ...;

sessionOptions.numTraceBuffers = numTraceBuffers;
sessionOptions.traceBufferSize = traceBufferSize;
// cpu mapped pointer to memory pool
sessionOptions.pTraceArena = (uint8_t*)nvnMemoryPoolMap(traceArena);
// gpu pointer to memory pool
sessionOptions.traceArenaGpuAddress = nvnMemoryPoolGetBufferAddress(traceArena);
// pointer to the memory pool object
sessionOptions.pTraceArenaMemoryPool = &amp;traceArena;
</pre></li>
<li><p class="startli"><b>ComputeArena</b> - a set of <b>ComputeBuffers</b></p>
<p class="startli">The <b>ComputeBuffer</b> is similar to a <b>TraceBuffer</b> but stores metadata about compute traces. It is sized similarly as well: </p><pre class="fragment">// upper bound to the number of dispatches in the frame.
const size_t maxDispatchesPerFrame = ...;
const size_t computeBufferSize = NVPA_NVN_COMPUTE_BUFFER_PAD_SIZE + maxDispatchesPerFrame * NVPA_NVN_COMPUTE_RECORD_SIZE;
</pre><p> The <b>ComputeBuffer</b> is also written by the GPU, so similar to needing multiple <b>TraceBuffers</b>, multiple <b>ComputeBuffers</b> are needed, one per <b>TraceBuffer</b> or the same as the swap chain size. </p><pre class="fragment">const size_t computeArenaSize = numTraceBuffers * computeBufferSize;
</pre><p> The <b>ComputeArena</b> is also stored as a single memory pool with similar constraints as the <b>TraceArena</b> so it is suggested to use <code>(NVN_MEMORY_POOL_FLAGS_CPU_UNCACHED_BIT | NVN_MEMORY_POOL_FLAGS_GPU_CACHED_BIT)</code> bits. </p><pre class="fragment">sessionOptions.computeBufferSize = computeBufferSize;
sessionOptions.pComputeArena = (uint8_t*)nvnMemoryPoolMap(computeArena);
sessionOptions.computeArenaGpuAddress = nvnMemoryPoolGetBufferAddress(computeArena);
sessionOptions.pComputeArenaMemoryPool = &amp;computeArena;
</pre></li>
<li><p class="startli"><b>PerfmonBuffer</b> - a buffer used by the hardware to store intermediate <a href="#Counter">counter</a> results</p>
<p class="startli">This buffer is stored in a gpu internal format and is processed by PerfWorks where the results are returned in the <b>CounterDataImage</b>. A <b>Perfmon</b> is short for performance monitor and is the unit that governs the collection of counters per gpu unit. Each perfmon will return two records per range (start and end). The number of perfmons is gpu-dependent. The minimum size for this buffer is: </p><pre class="fragment">const size_t maxNumRanges = ...

// 100 is a good upper bound for pre-Pascal gpu's
// gm20b is always 5
const size_t numPerfmons = 100;
const size_t perfmonBufferMinSize = maxNumRanges * numPerfmons * (2 * NVPA_NVN_PERFMON_RECORD_SIZE);
// the size must be aligned to NVN_MEMORY_POOL_STORAGE_ALIGNMENT;
const size_t perfmonBufferSize = AlignUp(perfmonBufferMinSize, NVN_MEMORY_POOL_STORAGE_ALIGNMENT);
</pre><p> For Windows implementations, the <b>PerfmonBuffer</b> is allocated and managed by PerfWorks. On NX, the application must allocate a page-aligned CPU buffer. </p><pre class="fragment">    uint8_t* pPerfmonBuffer = nullptr;
#if !defined(_WIN32)
    uint8_t perfmonBuffer[perfmonBufferSize] __attribute__((aligned(NVN_MEMORY_POOL_STORAGE_ALIGNMENT)));
    pPerfmonBuffer = &amp;perfmonBuffer[0];
#endif

    sessionOptions.pPerfmonBuffer = pPerfmonBuffer;
    sessionOptions.perfmonBufferSize = perfmonBufferSize;
</pre><p> For edge cases where the calculated buffer sizes are insufficient, please consult <a href="#TraceBufferDynamicResizing">the section on dynamic resizing</a>.</p>
</li>
</ol>
<p>Other options to set: </p><div class="fragment"><div class="line"><span class="comment">// See above sections for generation options</span></div>
<div class="line">std::vector&lt;uint8_t&gt; configImage = ...;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// must set the configuration so Perfworks knows how to program the gpu for the requested counters</span></div>
<div class="line">sessionOptions.pConfig = &amp;configImage[0];</div>
<div class="line">sessionOptions.configSize = configImage.size();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// set activity kind so PerfWorks can set up gpu into the right mode</span></div>
<div class="line">sessionOptions.activityKind = <a class="code" href="nvperf__common_8h.html#a185c285d78299004540732d0d228fbc6a003151b80ca105b7a3d6bca7b202e56f">NVPA_ACTIVITY_KIND_PROFILER</a>;</div>
<div class="line"> </div>
<div class="line">sessionOptions.finishOnEndPass = <span class="keyword">false</span>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Control which ranges will be profiled.  For example, given a scene with following instrumentation:</span></div>
<div class="line"><span class="comment">//    PushDebugGroup(&quot;1&quot;)</span></div>
<div class="line"><span class="comment">//       DrawA()</span></div>
<div class="line"><span class="comment">//    PushDebugGroup(&quot;2&quot;)</span></div>
<div class="line"><span class="comment">//       DrawB()</span></div>
<div class="line"><span class="comment">//    PushDebugGroup(&quot;3&quot;)</span></div>
<div class="line"><span class="comment">//       DrawC()</span></div>
<div class="line"><span class="comment">//    PopDebugGroup()</span></div>
<div class="line"><span class="comment">//       DrawD()</span></div>
<div class="line"><span class="comment">//    PopDebugGroup()</span></div>
<div class="line"><span class="comment">//       DrawE()</span></div>
<div class="line"><span class="comment">//    PopDebugGroup(()</span></div>
<div class="line"><span class="comment">// To profile all ranges:</span></div>
<div class="line"><span class="comment">//   minNestingLevel  = 1</span></div>
<div class="line"><span class="comment">//   numNestingLevels = 3</span></div>
<div class="line"><span class="comment">//     this returns results for each range separately: Range 1(draws A-E), Range 2(draws B-D), Range 3(draws C)</span></div>
<div class="line"><span class="comment">// To profile only range 1:</span></div>
<div class="line"><span class="comment">//   minNestingLevel  = 1</span></div>
<div class="line"><span class="comment">//   numNestingLevels = 1</span></div>
<div class="line"><span class="comment">//     this returns 1 range result for:  Range 1(draws A-E)</span></div>
<div class="line"><span class="comment">// To profile only range 3:</span></div>
<div class="line"><span class="comment">//   minNestingLevel  = 3</span></div>
<div class="line"><span class="comment">//   numNestingLevels = 1</span></div>
<div class="line"><span class="comment">//     this returns 1 range result for:  Range 3(draw C)</span></div>
<div class="line">sessionOptions.minNestingLevel = ...;</div>
<div class="line">sessionOptions.numNestingLevels = ...;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// given some initialized queue</span></div>
<div class="line"><a class="code" href="struct_n_v_nqueue.html">NVNqueue</a> queue = ...;</div>
<div class="line"> </div>
<div class="line">NVPA_NVNC_BeginSession(queue, &amp;sessionOptions);</div>
<div class="ttc" id="astruct_n_v_nqueue_html"><div class="ttname"><a href="struct_n_v_nqueue.html">NVNqueue</a></div><div class="ttdoc">API class used to send commands to the GPU.</div><div class="ttdef"><b>Definition:</b> nvn.h:231</div></div>
</div><!-- fragment --><h4><a class="anchor" id="autotoc_md132"></a>
Range Profiling Example</h4>
<div class="fragment"><div class="line"><a class="code" href="nvperf__common_8h.html#adec6426ce48517af734ec679c6c3c9ab">NVPA_Bool</a> allPassesSubmitted = <span class="keyword">false</span>;</div>
<div class="line"><span class="keywordflow">while</span> (!allPassesSubmitted)</div>
<div class="line">{</div>
<div class="line">    NVPA_NVNC_BeginPass(queue);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// submit any needed commands</span></div>
<div class="line">    nvnQueueSubmitCommands(queue, ...);</div>
<div class="line"> </div>
<div class="line">    NVPA_NVNC_EndPass(queue, &amp;allPassesSubmitted);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// To simplify profiling, call Finish, then Decode the previous pass immediately.</span></div>
<div class="line">    nvnQueueFinish(queue);</div>
<div class="line">    DecodeCounters();</div>
<div class="line">}</div>
<div class="ttc" id="anvperf__common_8h_html_adec6426ce48517af734ec679c6c3c9ab"><div class="ttname"><a href="nvperf__common_8h.html#adec6426ce48517af734ec679c6c3c9ab">NVPA_Bool</a></div><div class="ttdeci">uint8_t NVPA_Bool</div><div class="ttdoc">The type used for boolean values.</div><div class="ttdef"><b>Definition:</b> nvperf_common.h:156</div></div>
</div><!-- fragment --><h4><a class="anchor" id="autotoc_md133"></a>
Realtime Profiling Example</h4>
<div class="fragment"><div class="line"><span class="comment">// global toggle to enable profiling</span></div>
<div class="line"><span class="keywordtype">bool</span> profiling = ...;</div>
<div class="line">uint32_t frameNum = 0;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// set to swap chain size</span></div>
<div class="line">uint32_t frameDelay = ...;</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">while</span> (profiling)</div>
<div class="line">{</div>
<div class="line">    NVPA_NVNC_BeginPass(queue);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// submit any needed commands</span></div>
<div class="line">    nvnQueueSubmitCommands(queue, ...);</div>
<div class="line"> </div>
<div class="line">    <a class="code" href="nvperf__common_8h.html#adec6426ce48517af734ec679c6c3c9ab">NVPA_Bool</a> allPassesSubmitted = <span class="keyword">false</span>;</div>
<div class="line">    NVPA_NVNC_EndPass(queue, &amp;allPassesSubmitted);</div>
<div class="line"> </div>
<div class="line">    frameNum += 1;</div>
<div class="line">    <a class="code" href="nvperf__common_8h.html#adec6426ce48517af734ec679c6c3c9ab">NVPA_Bool</a> allPassesDecoded = <span class="keyword">false</span>;</div>
<div class="line">    DecodeCounters(&amp;allPassesDecoded);</div>
<div class="line">    <span class="keywordflow">if</span> (allPassesDecoded)</div>
<div class="line">    {</div>
<div class="line">        EvaluateMetrics();          <span class="comment">// UnpackRawMetrics and evaluate through the realtime metrics system.</span></div>
<div class="line">        InitializeCounterData();    <span class="comment">// InitializeCounterDataImage + InitializeCounterDataScratchBuffer</span></div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>Note, that <code>allPassesSubmitted</code> will flip true whenever an <a href="#Iteration">iteration</a> is completely submitted. You would still have to wait swap chain size number of frames before the frames for the <a href="#Iteration">iteration</a> have been rendered and decoded into the <b>CounterData</b> image. DecodeCounters() does not need to be deferred based on the swap chain size. DecodeCounters() can be called safely after every call to EndPass(). The first calls to DecodeCounters() will simply be no-op's until the first frame's data is written into the trace buffer. Use the <code>DecodeCounterStats</code> output parameter of DecodeCounters() to determine if a pass has been decoded and whether all passes have been decoded.</p>
<h4><a class="anchor" id="autotoc_md134"></a>
DebugStats</h4>
<p>The DecodeCounters function reads data from the oldest <b>TraceBuffer</b>, reads counters from <b>PerfmonBuffer</b>, and outputs counter values to the passed-in <b>CounterDataImage</b>.</p>
<p>The <b>PerfmonBuffer</b> is a circular buffer managed by the hardware, and is not inherently segmented per <b>TraceBuffer</b>. The circular buffer state-machine is managed inside the PerfWorks library, which can be queried via <code>NVPA_NVNC_QueueGetDebugStats</code>. After a call to DecodeCounters, some perfmon bytes will be consumed (read by the CPU). However, the hardware circular buffer will not be able to reuse that space until the following BeginPass call.</p>
<p>After a completed pass, the <b>TraceBuffer</b> will be populated by the GPU, and <code>NVPA_NVNC_GetTraceBufferDebugStats</code> can be called to read back which pass was collected, and the perfmon buffer end offset for that pass.</p>
<h2><a class="anchor" id="autotoc_md135"></a>
Metric Evaluation</h2>
<p>Metric Evaluation is the process of forming metrics from the counters stored in the <b>CounterData</b> image. PerfWorks defines several kinds of metrics:</p>
<ul>
<li><b>Raw Metrics</b> - these are simple metrics transformed directly from the <b>CounterData</b> in a canonical format</li>
<li><b>Realtime Metrics</b> - these are <b>Raw Metrics</b> that can be collected in a single pass, suitable for realtime profiling. Only GPU values are exposed.</li>
<li><b>Derived Metrics</b> - these are complex metrics formed from expressions of <b>Raw Metrics</b>. Both GPU and instance values are available.</li>
</ul>
<p><img src="metric_stack.png" alt="" class="inline" title="Metric Stack"/></p>
<p><a class="anchor" id="RealtimeMetricsEvaluation"></a></p>
<h3><a class="anchor" id="autotoc_md136"></a>
Realtime Metrics</h3>
<p>The Realtime Metrics System is designed to run on the NX device, and supports both configuration and evaluation. The sample <code>debuggroup.cpp</code> demonstrates both configuration and evaluation on device.</p>
<p>Major differences compared to the <a href="#DerivedMetricsEvaluation">Derived Metrics Layer</a> include:</p>
<ul>
<li>Realtime metrics only calculates GPU-level values.</li>
<li>Realtime metrics only return <code>sum</code> and <code>avg</code> stats; <code>min</code> and <code>max</code> are not available.</li>
<li>Realtime metrics provide <code>per_cycle_elapsed</code> and <code>pct_of_peak_sustained_elapsed</code>. All other <code>per_cycle</code> and <code>pct_of_peak</code> metrics are not available.</li>
<li>Realtime throughput metrics are only an approximation of the full formulas defined in the Derived Metrics Layer.</li>
</ul>
<p>Despite these limitations, the Realtime Metrics System is still handy for quick performance triage on device, and is well suited for integration into performance HUDs.</p>
<h4><a class="anchor" id="autotoc_md137"></a>
Configuration + Evaluation Workflow</h4>
<p>This is a rough outline of the <code>debuggroup.cpp</code> sample:</p>
<ul>
<li>Define the <code>MetricsStorage</code> object. This contains enough space for every counter in a single range.<ul>
<li><code>nv::metrics::MetricsStorage&lt;nv::metrics::gm20b::AllMetrics, nv::metrics::gm204::AllMetrics&gt; metricsStorage[2];</code></li>
</ul>
</li>
<li><code>InitializeChipDesc()</code> initializes the <code>nv::metrics::ChipDesc</code> for the current GPU.<ul>
<li>This step initializes the two <code>RawMetricsContext</code> objects in the <code>MetricsStorage</code>, one for isolated counters, the other for pipelined.</li>
<li><code>pRawMetricsContext</code> points at either <code>gm20b::AllMetrics</code> or <code>gm204::AllMetrics</code>. The GPU-specific classes contain the GPU-specific evaluation functions for every counter and metric.</li>
</ul>
</li>
<li><code>SelectAllMetrics()</code> selects counters to be measured.<ul>
<li>Enumerate by iterating the array of <code>MetricDesc</code> pointers in <code>(ChipDesc::pMetricDescs, ChipDesc::numMetricDescs)</code>.</li>
<li>Keep a list of selected metrics, by holding the <code>MetricDesc</code> pointers.</li>
<li>Note that <code>debuggroup.cpp</code> collects every possible metric. In your engine, this function is a good place to select the exact list you wish to see.</li>
</ul>
</li>
<li>Configuration<ul>
<li>Call <code>ChipDescResetContexts()</code> to reset the <code>RawMetricsContexts</code> objects. Enable configuration mode with <code>chipDesc.pRawMetricsContexts[isolated]-&gt;configuring = true;</code></li>
<li>For each selected metric, call its evaluation function: <code>pMetricDesc-&gt;metricEvalFn(chipDesc.pRawMetricsContexts[isolated]);</code> . As a side effect, all raw metrics required for configuration will have their corresponding <code>RawMetricsContext::pCounts[rawMetricIdx]</code> set to 1.</li>
<li>Iterate over every RawMetricId; if its <code>RawMetricsContext::pCounts[rawMetricIdx] != 0</code> then convert the 64-bit ID to a string by calling <code>NVPA_RawMetricsConfig_GetMetricNameFromCounterId</code>, then create an <code>NVPA_RawMetricRequest</code> from it.</li>
<li>Create a <b>ConfigImage</b> as described in section <a href="#OnlineConfigImage">"Online Generation of the ConfigImage"</a>.</li>
</ul>
</li>
<li>Collect counter values as described in section <a href="#CollectionOnTarget">"Collection on Target"</a>, resulting in a <b>CounterDataImage</b>.</li>
<li>Evaluate metrics.<ul>
<li>Query number of ranges from <b>CounterDataImage</b></li>
<li>Query the range descriptions from <b>CounterDataImage</b><ul>
<li>Note: range descriptions are returned via <code>const char*</code>, and point directly into the <b>CounterDataImage</b>.</li>
</ul>
</li>
<li>Call <code>ChipDescResetContexts()</code> to reset the <code>RawMetricsContexts</code> objects.</li>
<li>For each range:<ul>
<li>Call <code>NVPA_NVNC_CounterData_UnpackRawMetrics</code> to unpack raw counter values from the <b>CounterDataImage</b> into <code>RawMetricsContext</code>.</li>
<li>For each selected metric:<ul>
<li>Call <code>MetricValue metricValue = pMetricDesc-&gt;metricEvalFn(chipDesc.pRawMetricsContexts[isolated]);</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><a class="anchor" id="autotoc_md138"></a>
struct MetricValue</h4>
<p>Each metric value has the following properties:</p>
<ul>
<li><code>.sum</code> : The sum of counter values across all unit instances.<ul>
<li>Sum is usually best for operation counts like: draws, dispatches, primitives, vertices, attributes, pixels, samples, quads.</li>
</ul>
</li>
<li><code>.avg</code> : The average counter value across all unit instances.<ul>
<li>Avg is usually best for cycle counts like: active, stalled.</li>
</ul>
</li>
<li><code>.peak_sustained</code> : The peak sustained rate of operation for a single instance (i.e. referenced to the <code>avg</code> counter).<ul>
<li>Example: <code>smsp__inst_issued</code> &ndash; each SMSP can issue <code>1.5</code> instructions/gpc_clk sustained, and there are 8 SMSP on a GM20B. The peak_sustained value is <code>1.5</code>.</li>
</ul>
</li>
<li><code>.cycles_elapsed</code> : The avg elapsed cycles on the unit.<ul>
<li>On NX, there is only one global clock. Therefore all counters' <code>cycles_elapsed</code> values should be roughly equal.</li>
</ul>
</li>
<li><code>.sum_per_cycle_elapsed()</code> : <code>sum / cycles_elapsed</code><ul>
<li>Returns per-cycle throughput of the whole GPU.</li>
</ul>
</li>
<li><code>.avg_per_cycle_elapsed()</code> : <code>avg / cycles_elapsed</code><ul>
<li>Returns per-cycle throughput of the average unit instance.</li>
</ul>
</li>
<li><code>.pct_of_peak_sustained_elapsed()</code> : <code>100.0 * avg / (cycles_elapsed * peak_sustained)</code><ul>
<li>Returns the percentage of peak throughput achieved for this counter.</li>
<li>These values are useful for displaying in a performance HUD.</li>
</ul>
</li>
</ul>
<h4><a class="anchor" id="autotoc_md139"></a>
Percentage Metrics</h4>
<p>Some metrics are presented as percentages and have a <code>_pct</code> suffix, for example <code>l1tex__t_sectors_hit_rate_pct</code>.</p>
<ul>
<li>The percentage value appears in the <code>.avg</code> field.</li>
<li><code>cycles_elapsed</code>, <code>sum_per_cycle_elapsed</code>, <code>avg_per_cycle_elapsed</code>, and <code>pct_of_peak_sustained_elapsed</code> are meaningless on percentage metrics, and can be safely ignored.</li>
</ul>
<p><a class="anchor" id="DerivedMetricsEvaluation"></a></p>
<h3><a class="anchor" id="autotoc_md140"></a>
Derived Metric Evaluation</h3>
<p>The general process is:</p>
<p>0. During collection, save the CounterDataImage to a file. (or transfer over network)</p><ol type="1">
<li>Query number of ranges from <b>CounterDataImage</b></li>
<li>Query the range descriptions from <b>CounterDataImage</b> Note: range descriptions are returned via <code>const char*</code>, and point directly into the <b>CounterDataImage</b>.</li>
<li>Create an <code>NVPA_MetricsContext</code> for the GPU that the <b>CounterDataImage</b> was collected from.</li>
<li>For Each Range:<ol type="a">
<li>Call <code>NVPA_MetricsContext_SetCounterData</code> to set the <em>current</em> set of values.</li>
<li>Call <code>NVPA_MetricsContext_EvaluateToGpuValues</code> to calculate and retrieve GPU-level values.</li>
<li>Call <code>NVPA_MetricsContext_EvaluateToInstanceValues</code> to calculate and retrieve unit-level values.</li>
</ol>
</li>
</ol>
<p>NOTE: It is recommended that when using <b>Derived Metric Evaluation</b>, that during the <a href="#ConfigurationSection">configuration</a> phase, <code>keepInstances</code> should be set to <code>true</code>. Many metrics in the derived metrics layer require instances to evaluate properly. Without <code>keepInstances=true</code>, these metrics will evaluate to <code>NaN</code>.</p>
<p>Please consult the "derivedMetrics" sample for a full demonstration of usage.</p>
<p><a class="anchor" id="Range_Based_Profiling"></a></p>
<h1><a class="anchor" id="autotoc_md141"></a>
Range-Based Profiling</h1>
<p>Each profiling <a href="#Session">session</a> runs a series of replay <a href="#Pass">passes</a>, where each <a href="#Pass">pass</a> contains a sequence of <a href="#Range">ranges</a>. Every <a href="#Metric">metric</a> enabled in the <a href="#Session">session's</a> <a href="#ConfigurationSection">configuration</a> is collected separately per unique <a href="#RangeStack">range-stack</a> in the <a href="#Pass">pass</a>.</p>
<div class="fragment"><div class="line">NVPA_NVNC_SessionOptions sessionOptions = NVPA_NVNC_SessionOptions();</div>
<div class="line">sessionOptions.activityKind = <a class="code" href="nvperf__common_8h.html#a185c285d78299004540732d0d228fbc6a003151b80ca105b7a3d6bca7b202e56f">NVPA_ACTIVITY_KIND_PROFILER</a>;</div>
<div class="line"> </div>
<div class="line">NVPA_NVNC_BeginSession(queue, &amp;sessionOptions);</div>
<div class="line">    <span class="keywordflow">do</span> {</div>
<div class="line">        NVPA_NVNC_BeginPass(queue);</div>
<div class="line"> </div>
<div class="line">            <span class="comment">// repeat ...</span></div>
<div class="line">            nvnQueueSubmitCommands(queue, 1, cmdHandle);</div>
<div class="line">            <span class="comment">/* cmdHandle = nvnCommandBufferBeginRecord(cmdBuf) of the following</span></div>
<div class="line"><span class="comment">            {</span></div>
<div class="line"><span class="comment">                gpu_commands_not_measured();</span></div>
<div class="line"><span class="comment">                nvnCommandBufferPushDebugGroupDynamic(cmdBuf, domainId, MyRangeDesc);</span></div>
<div class="line"><span class="comment">                    gpu_commands_measured();</span></div>
<div class="line"><span class="comment">                nvnCommandBufferPopDebugGroupDynamicId(cmdBuf, domainId);</span></div>
<div class="line"><span class="comment">            }</span></div>
<div class="line"><span class="comment">            */</span></div>
<div class="line"> </div>
<div class="line">        NVPA_NVNC_EndPass(queue);</div>
<div class="line">    } <span class="keywordflow">while</span> (!PredictDataReady(queue));</div>
<div class="line"> </div>
<div class="line">    nvnQueueFinish(queue); <span class="comment">// wait for results to finish</span></div>
<div class="line">    ReadResults(queue);</div>
<div class="line">NVPA_NVNC_EndSession(queue);</div>
</div><!-- fragment --><p>During decode counters, any remaining unmatched PushDebugGroup* ranges are automatically popped.</p>
<h2><a class="anchor" id="autotoc_md142"></a>
Detailed Pseudo-code</h2>
<p>In this pseudo-code, each range contains more than one draw call, to emphasize that with application-defined ranges, measurements occur at range boundaries (<b>not</b> per draw call).</p>
<div class="fragment"><div class="line"><a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a> CreateScene()</div>
<div class="line">{</div>
<div class="line">    <a class="code" href="struct_n_v_ncommand_buffer.html">NVNcommandBuffer</a>* cmdBuf = ...;</div>
<div class="line"> </div>
<div class="line">    nvnCommandBufferBeginRecording(cmdBuf, ...);</div>
<div class="line">    Draw_AA_0();                                <span class="comment">// not measured</span></div>
<div class="line">    Draw_AA_1();                                <span class="comment">// not measured</span></div>
<div class="line"> </div>
<div class="line">    nvnCommandBufferPushDebugGroup(cmdBuf, 0, <span class="stringliteral">&quot;100&quot;</span>);</div>
<div class="line">        Draw_BB_0();                            <span class="comment">//     measured</span></div>
<div class="line">        Draw_BB_1();                            <span class="comment">//     measured</span></div>
<div class="line">    nvnCommandBufferPopDebugGroupId(cmdBuf, 0);</div>
<div class="line"> </div>
<div class="line">    Draw_CC_0();                                <span class="comment">// not measured</span></div>
<div class="line">    Draw_CC_1();                                <span class="comment">// not measured</span></div>
<div class="line"> </div>
<div class="line">    nvnCommandBufferPushDebugGroup(cmdBuf, 0, <span class="stringliteral">&quot;200&quot;</span>);</div>
<div class="line">        Draw_DD_0();                            <span class="comment">//     measured</span></div>
<div class="line">        Draw_DD_1();                            <span class="comment">//     measured</span></div>
<div class="line"> </div>
<div class="line">        nvnCommandBufferPushDebugGroup(cmdBuf, 0, <span class="stringliteral">&quot;10&quot;</span>);</div>
<div class="line">            Draw_EE_0();                        <span class="comment">//     measured</span></div>
<div class="line">            Draw_EE_1();                        <span class="comment">//     measured</span></div>
<div class="line">        nvnCommandBufferPopDebugGroupId(cmdBuf, 0);</div>
<div class="line"> </div>
<div class="line">        Draw_FF_0();                            <span class="comment">//     measured</span></div>
<div class="line">        Draw_FF_1();                            <span class="comment">//     measured</span></div>
<div class="line">    nvnCommandBufferPopDebugGroupId(cmdBuf, 0);</div>
<div class="line"> </div>
<div class="line">    Draw_GG_0();                                <span class="comment">// not measured</span></div>
<div class="line">    Draw_GG_1();                                <span class="comment">// not measured</span></div>
<div class="line"> </div>
<div class="line">    <a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a> scene = nvnCommandBufferEndRecording(cmdBuf, ...);</div>
<div class="line">    <span class="keywordflow">return</span> scene;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> <a class="code" href="namespacenns_1_1dbgui.html#a130fd0189fc1b44752570a7d28fbb4d9">Render</a>(<a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a>&amp; scene)</div>
<div class="line">{</div>
<div class="line">    NVPA_NVNC_BeginPass(queue, ...);</div>
<div class="line"> </div>
<div class="line">    nvnQueueSubmitCommands(queue, 1, scene);</div>
<div class="line"> </div>
<div class="line">    NVPA_NVNC_EndPass(queue, ...);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> main()</div>
<div class="line">{</div>
<div class="line">    <a class="code" href="struct_n_v_nqueue.html">NVNqueue</a>* queue = ...;</div>
<div class="line">    <a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a> scene = CreateScene();</div>
<div class="line"> </div>
<div class="line">    NVPA_NVNC_BeginSession(queue, ...);</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">do</span> {</div>
<div class="line">        <a class="code" href="namespacenns_1_1dbgui.html#a130fd0189fc1b44752570a7d28fbb4d9">Render</a>(scene);</div>
<div class="line">    } <span class="keywordflow">while</span> (!PredictDataReady(queue));</div>
<div class="line"> </div>
<div class="line">    nvnQueueFinish(queue); <span class="comment">// wait for GPU commands to complete</span></div>
<div class="line">    NVPA_NVNC_EndSession(queue);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// decode counter and evaluate metrics</span></div>
<div class="line">    ReadResults(queue);</div>
<div class="line">}</div>
<div class="ttc" id="agroup__nvn__c__handle_html_gab7f10945ffe1f6161c87238c75ae411d"><div class="ttname"><a href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a></div><div class="ttdeci">uint64_t NVNcommandHandle</div><div class="ttdoc">GPU handle used to refer to a command buffer object.</div><div class="ttdef"><b>Definition:</b> nvn.h:437</div></div>
<div class="ttc" id="anamespacenns_1_1dbgui_html_a130fd0189fc1b44752570a7d28fbb4d9"><div class="ttname"><a href="namespacenns_1_1dbgui.html#a130fd0189fc1b44752570a7d28fbb4d9">nns::dbgui::Render</a></div><div class="ttdeci">void Render(nn::gfx::CommandBuffer *pCommandBuffer) NN_NOEXCEPT</div><div class="ttdoc">Renders the frame.</div></div>
<div class="ttc" id="astruct_n_v_ncommand_buffer_html"><div class="ttname"><a href="struct_n_v_ncommand_buffer.html">NVNcommandBuffer</a></div><div class="ttdoc">Collection of commands to send to the GPU via queues.</div><div class="ttdef"><b>Definition:</b> nvn.h:236</div></div>
</div><!-- fragment --><ul>
<li>The following are not measured, since they lie outside of any <a href="#Range">range</a>:<ul>
<li><code>Draw_AA_*</code>, <code>Draw_CC_*</code>, <code>Draw_GG_*</code></li>
</ul>
</li>
<li>When collecting isolated metrics, data is produced per <a href="#RangeStack">range-stack</a> as follows:<ul>
<li><code>{100}</code> : isolated cost of <code>Draw_BB_*</code></li>
<li><code>{200}</code> : isolated cost of running these in parallel: <code>Draw_DD_*</code>, <code>Draw_EE_*</code>, <code>Draw_FF_*</code></li>
<li><code>{200, 10}</code> : isolated cost of <code>Draw_EE_*</code></li>
</ul>
</li>
<li>When collecting pipelined metrics, data is produced per <a href="#RangeStack">range-stack</a> as follows:<ul>
<li><code>{100}</code> : incremental cost of <code>Draw_BB_*</code></li>
<li><code>{200}</code> : incremental cost of <code>Draw_DD_*</code> + incremental cost of <code>Draw_FF_*</code></li>
<li><code>{200, 10}</code> : incremental cost of <code>Draw_EE_*</code></li>
</ul>
</li>
</ul>
<p>Notice that the isolated counters in <code>{200}</code> include contributions from <code>Draw_EE_*</code>, whereas pipelined counters in <code>{200}</code> do not. This result arrives from the definition of isolated metrics, which measure <em>total cost in isolation</em>, as opposed to pipelined metrics which measure <em>incremental cost</em> over previous work.</p>
<h2><a class="anchor" id="autotoc_md143"></a>
Isolated vs Pipelined Passes</h2>
<p>The following diagrams illustrate how PerfWorks collects metrics differently in pipelined and isolated passes. Each diagram element is also annotated in the source code, so you can search for <code>P1</code>, <code>RA</code>, <code>D3</code>, etc. By way of example, the diagram elements are:</p>
<ul>
<li><code>P1</code> and <code>/P1</code> : <code>BeginPass</code> and <code>EndPass</code>, for <a href="#Pass">pass</a> <code>1</code></li>
<li><code>Cfg P1</code> : configuration of performance counters for <a href="#Pass">pass</a> <code>1</code></li>
<li><code>RA</code> and <code>/RA</code> :<ul>
<li>CPU: &lsquo;PushRange('A&rsquo;)<code>and the corresponding</code>PopRange`</li>
<li>GPU: <a href="#Trigger">trigger</a> commands</li>
</ul>
</li>
<li><code>D3</code> : Draw Call <code>3</code></li>
<li><code>VA1</code> : the value for <a href="#Range">range</a> <code>A</code> in <a href="#Pass">pass</a> <code>1</code></li>
<li><code>W</code> : GPU-wait command, which blocks the GPU frontend from issuing commands until all preceding work has completed</li>
</ul>
<p><b>In both <a href="#Pass">pass</a> types:</b></p>
<ul>
<li>Assume frame rendering is double-buffered.</li>
<li>The GPU executes asynchronously from the CPU &ndash; the GPU is behind by one frame.</li>
<li>Values are delayed by two frame boundaries from the time of the Draw API call.</li>
</ul>
<p><b>During pipelined <a href="#Pass">passes</a> (diagram below):</b></p>
<ul>
<li>Execution behavior and performance is the same as when PerfWorks is not in use.</li>
<li><code>{D1, D2, D3}</code> all execute in parallel.</li>
<li><code>VB1</code> is <code>RB</code>'s <em>incremental cost</em>.<ul>
<li>Notice that the timespan between <code>VA1</code> and <code>VB1</code> does not contain the entirety of <code>D3</code>.</li>
</ul>
</li>
</ul>
<p><img src="ranges_pipelined_d3.svg" alt="" style="pointer-events: none;" class="inline" title="Pipelined Data production"/></p>
<p><b>During isolated <a href="#Pass">passes</a> (diagram below):</b></p>
<ul>
<li><code>{D1, D2}</code> execute in parallel, since they lie within the same <a href="#Range">range</a>.</li>
<li><code>D3</code> <em>does not</em> execute in parallel with <code>{D1, D2}</code>.</li>
<li><code>VB1</code> is <code>RB</code>'s <em>isolated</em> cost.<ul>
<li>Notice that the timespan for VB1 only contains draws within <code>RB</code>.</li>
</ul>
</li>
</ul>
<p><img src="ranges_isolated_d3.svg" alt="" style="pointer-events: none;" class="inline" title="Pipelined Data production"/></p>
<h3><a class="anchor" id="autotoc_md144"></a>
NVN</h3>
<div class="fragment"><div class="line">NVNcomamndHandle SimpleExample1_NVN(<a class="code" href="struct_n_v_ncommand_buffer.html">NVNcommandBuffer</a>* cmdBuf)</div>
<div class="line">{</div>
<div class="line">    nvnCommandBufferBeginRecord(cmdBuf, ...);</div>
<div class="line">        nvnCommandBufferPushDebugGroupDynamic(cmdBuf, 0, <span class="stringliteral">&quot;A&quot;</span>); <span class="comment">//  RA</span></div>
<div class="line">            nvnCommandBufferDrawArrays(cmdBuf, ...);           <span class="comment">//  D1</span></div>
<div class="line">            nvnCommandBufferDrawArrays(cmdBuf, ...);           <span class="comment">//  D2</span></div>
<div class="line">        nvnCommandBufferPopDebugGroupId(cmdBuf, 0);            <span class="comment">// /RA</span></div>
<div class="line">        nvnCommandBufferPushDebugGroupDynamic(cmdBuf, 0, <span class="stringliteral">&quot;B&quot;</span>); <span class="comment">//  RB</span></div>
<div class="line">            nvnCommandBufferDrawArrays(cmdBuf, ...);           <span class="comment">//  D3</span></div>
<div class="line">        nvnCommandBufferPopDebugGroupId(cmdBuf, 0);            <span class="comment">// /RB</span></div>
<div class="line">    <a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a> example = nvnCommandBufferEndRecording(cmdBuf,...);</div>
<div class="line">    <span class="keywordflow">return</span> example;</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md145"></a>
Global Initialization</h1>
<p>The following PerfWorks functions must be called before the first call into the OpenGL driver:</p>
<div class="fragment"><div class="line"><span class="comment">// Host Init</span></div>
<div class="line">{</div>
<div class="line">    <a class="code" href="nvperf___host_8h.html#a66e9388f35038d766a829de0070f9491">NVPA_InitializeHost</a>();</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Target init</span></div>
<div class="line">{</div>
<div class="line">    <a class="code" href="nvperf___target_8h.html#a4d63805db011c18976945569e08b9033">NVPA_InitializeTarget</a>();</div>
<div class="line">    NVPA_NVNC_LoadDriver();</div>
<div class="line">}</div>
<div class="ttc" id="anvperf___host_8h_html_a66e9388f35038d766a829de0070f9491"><div class="ttname"><a href="nvperf___host_8h.html#a66e9388f35038d766a829de0070f9491">NVPA_InitializeHost</a></div><div class="ttdeci">NVPA_Status NVPA_InitializeHost(void)</div><div class="ttdoc">Load the host library.</div></div>
<div class="ttc" id="anvperf___target_8h_html_a4d63805db011c18976945569e08b9033"><div class="ttname"><a href="nvperf___target_8h.html#a4d63805db011c18976945569e08b9033">NVPA_InitializeTarget</a></div><div class="ttdeci">NVPA_Status NVPA_InitializeTarget(void)</div><div class="ttdoc">Load the target.</div></div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md146"></a>
Queue Usage</h1>
<div class="fragment"><div class="line"><a class="code" href="struct_n_v_nqueue.html">NVNqueue</a>* queue = ...;</div>
<div class="line">nvnQueueInitialize(queue, ...);</div>
<div class="line"> </div>
<div class="line">    nvnQueueSubmitCommands(queue, ...);</div>
<div class="line"> </div>
<div class="line">    NVPA_NVNC_QueuePushDebugGroupDynamic(queue, ...);</div>
<div class="line">        nvnQueueSubmitCommands(queue, ...);</div>
<div class="line">        nvnQueueSubmitCommands(queue, ...);</div>
<div class="line">    NVPA_NVNC_QueuePopDebugGroupId(queue);</div>
<div class="line"> </div>
<div class="line">    nvnQueueSubmitCommands(queue, ...);</div>
<div class="line"> </div>
<div class="line">    NVPA_NVNC_QueuePushDebugGroupDynamic(queue, ...);</div>
<div class="line">        nvnQueueSubmitCommands(queue, ...);</div>
<div class="line">        nvnQueueSubmitCommands(queue, ...);</div>
<div class="line">        nvnQueueSubmitCommands(queue, ...);</div>
<div class="line">    NVPA_NVNC_QueuePopDebugGroupId(queue);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// ...</span></div>
<div class="line"> </div>
<div class="line">nvnQueueFinalize(queue);</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md147"></a>
CommandBuffer Ranges</h3>
<div class="fragment"><div class="line"><a class="code" href="struct_n_v_ncommand_buffer.html">NVNcommandBuffer</a>* cmdBuf = ...;</div>
<div class="line">nvnCommandBufferInitialize(cmdBuf, ...);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// PushRange &amp; PopRange empty range is OK</span></div>
<div class="line">    nvnCommandBufferPushDebugGroupDynamic(cmdBuf, ...);</div>
<div class="line">    nvnCommandBufferPopDebugGroupId(cmdBuf, ...);</div>
<div class="line"> </div>
<div class="line">    nvnCommandBufferBeginRecording(cmdBuf, ...);</div>
<div class="line">        nvnCommandBufferPushDebugGroupDynamic(cmdBuf, ...);</div>
<div class="line">        drawStuff();</div>
<div class="line">            nvnCommandBufferPushDebugGroupDynamic(cmdBuf, ...);</div>
<div class="line">            drawMoreStuff();</div>
<div class="line">    <a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a> commandHandle1 = nvnCommandBufferEndRecording(cmdBuf, ...);</div>
<div class="line">    <span class="comment">// commandHandle1 contains all PushRange &amp; PopRange commands recorded above</span></div>
<div class="line"> </div>
<div class="line">    nvnCommandBufferBeginRecording(cmdBuf, ...);</div>
<div class="line">        <span class="comment">// PushRange &amp; PopRange OK here</span></div>
<div class="line">        nvnCommandBufferPopDebugGroupId(cmdBuf, ...);</div>
<div class="line">    <a class="code" href="group__nvn__c__handle.html#gab7f10945ffe1f6161c87238c75ae411d">NVNcommandHandle</a> commandHandle2 = nvnCommandBufferEndRecording(cmdBuf, ...);</div>
<div class="line">    <span class="comment">// commandHandle2 contains all PushRange &amp; PopRange commands recorded above</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">// ...</span></div>
<div class="line"> </div>
<div class="line">nvnCommandBufferFinalize(cmdBuf);</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md148"></a>
Queue &amp; CommandBuffer Range Interaction</h3>
<p><code>NVNqueues</code> under PerfWorks contain an actual <a href="#RangeStack">range-stack</a>. <code>NVNcommandBuffers</code> under PerfWorks only contain <em>deferred</em> Push and Pop commands, which are executed on a queue during <code>nvnQueueSubmitCommands</code>. This means you can write <code>NVNcommandBuffers</code> containing only Push operations, only Pop operations, or imbalanced combinations.</p>
<p>This feature is useful when creating new ranges on state-changes. For example, if you want a range per program-bind, you can replace each call to <code>nvnCommandBufferBindProgram</code> with:</p>
<div class="fragment"><div class="line"><span class="keywordtype">char</span> programStr[32];</div>
<div class="line">sprintf(<span class="stringliteral">&quot;%u&quot;</span>, program);</div>
<div class="line"> </div>
<div class="line">nvnCommandBufferPopDebugGroupId(cmdBuf, domainId);</div>
<div class="line">nvnCommandBufferPushDebugGroupDynamic(cmdBuf, domainId, programStr);</div>
<div class="line">nvnCommandBufferBindProgram(cmdBuf, program);   <span class="comment">// original bind call</span></div>
</div><!-- fragment --><p>Then replace your main render function (<code>RenderFrame</code>) with:</p>
<div class="fragment"><div class="line">NVPA_NVNC_BeginPass(queue);</div>
<div class="line">    NVPA_NVNC_QueuePushDebugGroupStatic(queue, 0, <span class="stringliteral">&quot;Init&quot;</span>);  <span class="comment">// initial range, before any bind occurred</span></div>
<div class="line">    RenderFrame(queue);</div>
<div class="line">    NVPA_NVNC_QueuePopDebugGroupId(queue, 0);               <span class="comment">// pop the final range, whatever it may be</span></div>
<div class="line">NVPA_NVNC_EndPass(queue);</div>
</div><!-- fragment --><p><a class="anchor" id="Vulkan"></a></p>
<h1><a class="anchor" id="autotoc_md149"></a>
Vulkan Profiling</h1>
<p>The Vulkan profiling workflow matches the <a href="#Workflow">NVN Workflow</a> and <a href="#Range_Based_Profiling">NVN Range-Based Profiling</a>. The sample <code>NvPerfVkSimple.cpp</code> demonstrates all the steps of a profiling session on a VkQueue.</p>
<p>Outline of a profiling session:</p>
<div class="fragment"><div class="line">// prebaked CommandBuffers for per-frame operations, as circular buffers</div>
<div class="line">VkCommandBuffer beginPassCmdBuffers[MAX_FRAMES_IN_FLIGHT];</div>
<div class="line">VkCommandBuffer endPassCmdBuffers[MAX_FRAMES_IN_FLIGHT];</div>
<div class="line">VkCommandBuffer renderCmdBuffers[MAX_FRAMES_IN_FLIGHT];</div>
<div class="line"> </div>
<div class="line">void PrebakePerFrameCommands()</div>
<div class="line">{</div>
<div class="line">    for (int frameIndex = 0; frameIndex &lt; MAX_FRAMES_IN_FLIGHT; ++frameIndex)</div>
<div class="line">    {</div>
<div class="line">        VkCommandBuffer beginPassCmdBuf = beginPassCmdBuffers[frameIndex];</div>
<div class="line">        {</div>
<div class="line">            vkBeginCommandBuffer(beginPassCmdBuf, VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT);</div>
<div class="line">            NVPW_VK_Profiler_CommandBuffer_BeginPass_Params beginPassParams = { NVPW_VK_Profiler_CommandBuffer_BeginPass_Params_STRUCT_SIZE };</div>
<div class="line">            beginPassParams.commandBuffer = beginPassCmdBuf;</div>
<div class="line">            NVPW_VK_Profiler_CommandBuffer_BeginPass(&amp;beginPassParams);</div>
<div class="line">            vkEndCommandBuffer(beginPassCmdBuf);</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        VkCommandBuffer endPassCmdBuf = endPassCmdBuffers[frameIndex];</div>
<div class="line">        {</div>
<div class="line">            vkBeginCommandBuffer(endPassCmdBuf);</div>
<div class="line">            NVPW_VK_Profiler_CommandBuffer_EndPass_Params endPassParams = { NVPW_VK_Profiler_CommandBuffer_EndPass_Params_STRUCT_SIZE };</div>
<div class="line">            endPassParams.commandBuffer = endPassCmdBuf;</div>
<div class="line">            NVPW_VK_Profiler_CommandBuffer_EndPass(&amp;endPassParams);</div>
<div class="line">            vkEndCommandBuffer(endPassCmdBuf);</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        VkCommandBuffer renderCmdBuf = renderCmdBuffers[frameIndex];</div>
<div class="line">        Render(renderCmdBuf);</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">void Render(VkCommandBuffer commandBuffer)</div>
<div class="line">{</div>
<div class="line">    vkBeginCommandBuffer(commandBuffer);</div>
<div class="line">    vkCmdBeginRenderPass(commandBuffer);</div>
<div class="line"> </div>
<div class="line">    NVPW_VK_Profiler_CommandBuffer_PushRange_Params pushRangeParams = { NVPW_VK_Profiler_CommandBuffer_PushRange_Params_STRUCT_SIZE };</div>
<div class="line">    pushRangeParams.commandBuffer = commandBuffer;</div>
<div class="line">    pushRangeParams.pRangeName = &quot;My Rendering Technique&quot;;</div>
<div class="line">    pushRangeParams.rangeNameLength = strlen(pushRangeParams.pRangeName) + 1;</div>
<div class="line">    NVPW_VK_Profiler_CommandBuffer_PushRange(&amp;pushRangeParams);</div>
<div class="line"> </div>
<div class="line">    vkCmdDraw( ... );</div>
<div class="line"> </div>
<div class="line">    NVPW_VK_Profiler_CommandBuffer_PopRange popRangeParams = { NVPW_VK_Profiler_CommandBuffer_PopRange_Params_STRUCT_SIZE };</div>
<div class="line">    popRangeParams.commandBuffer = g_AppData.m_CommandBuffer;</div>
<div class="line">    NVPW_VK_Profiler_CommandBuffer_PopRange(&amp;popRangeParams);</div>
<div class="line"> </div>
<div class="line">    vkCmdEndRenderPass(commandBuffer);</div>
<div class="line">    vkEndCommandBuffer(commandBuffer);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">void ProfilerSession(VkQueue queue)</div>
<div class="line">{</div>
<div class="line">    // Set up the gpu for collection.</div>
<div class="line">    NVPW_VK_Profiler_Queue_BeginSession_Params beginSessionParams = ...;</div>
<div class="line">    beginSessionParams.queue = queue;</div>
<div class="line">    ... // see sample code for other parameters</div>
<div class="line">    NVPW_VK_Profiler_Queue_BeginSession(&amp;beginSessionParams);</div>
<div class="line"> </div>
<div class="line">    // Specify the counters to collect</div>
<div class="line">    NVPW_VK_Profiler_Queue_SetConfig_Params setConfigParams = { NVPW_VK_Profiler_Queue_SetConfig_Params_STRUCT_SIZE };</div>
<div class="line">    setConfigParams.pConfig = ...;      // see sample code</div>
<div class="line">    ... // see sample code for other parameters</div>
<div class="line">    NVPW_VK_Profiler_Queue_SetConfig(&amp;setConfigParams);</div>
<div class="line"> </div>
<div class="line">    for (int frameNumber = 0; frameNumber &lt; 100; ++frameNumber)</div>
<div class="line">    {</div>
<div class="line">        int frameIndex = frameNumber % MAX_FRAMES_IN_FLIGHT;</div>
<div class="line">        VkCommandBuffer beginPassCmdBuf = beginPassCmdBuffers[frameIndex];</div>
<div class="line">        VkCommandBuffer endPassCmdBuf = endPassCmdBuffers[frameIndex];</div>
<div class="line">        VkCommandBuffer renderCmdBuf = renderCmdBuffers[frameIndex];</div>
<div class="line"> </div>
<div class="line">        // Submit the frame</div>
<div class="line">        VkCommandBuffer* commandBuffersForFrame[] = { beginPassCmdBuf, renderCmdBuf, endPassCmdBuf };</div>
<div class="line"> </div>
<div class="line">        VkSubmitInfo info = {};</div>
<div class="line">        info.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO;</div>
<div class="line">        info.pNext = NULL;</div>
<div class="line">        info.commandBufferCount = 3;</div>
<div class="line">        info.pCommandBuffers = commandBuffersForFrame;</div>
<div class="line">        info.signalSemaphoreCount = 0;</div>
<div class="line">        info.waitSemaphoreCount = 0;</div>
<div class="line">        VkQueueSubmit(queue, &amp;info, fence);</div>
<div class="line"> </div>
<div class="line">        Present(queue, ...);  // vkQueuePresentKHR, vkAcquireNextImageKHR</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    NVPW_VK_Profiler_Queue_EndSession_Params endSessionParams = { NVPW_VK_Profiler_Queue_EndSession_Params_STRUCT_SIZE };</div>
<div class="line">    endSessionParams.queue = g_profiler.queue;</div>
<div class="line">    NVPW_VK_Profiler_Queue_EndSession(&amp;endSessionParams);</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md150"></a>
Differences from NVN</h2>
<ul>
<li>BeginPass and EndPass operate on VkCommandBuffer, whereas the NVN equivalents operate on <a class="el" href="struct_n_v_nqueue.html" title="API class used to send commands to the GPU.">NVNqueue</a>. This provides flexibility, but requires you to carefully sequence the calls per frame.</li>
<li>Range delimiters (PushRange and PopRange) are only available on VkCommandBuffer. There are no convenience functions at the VkQueue level.</li>
<li>Performance: each Vulkan PushRange and PopRange command requires some CPU processing at <code>vkQueueSubmit</code>, even when inert or outside of a profiling session. Avoid inserting many of these in performance-critical environments, like realtime HUD counter collection.</li>
<li>Error reporting: errors detected while processing CommandBuffer commands at <code>vkQueueSubmit</code>-time must be queried from a subsequent call to <code>VK_Profiler_Queue_GetLastError_Core</code>.<ul>
<li>The recommended pattern is to call GetLastError once per frame, to detect any error that previously occurred.</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md151"></a>
Limitations</h2>
<ul>
<li>Only one VkQueue may be profiled at a time, on the system.</li>
<li>BeginPass, EndPass, PushRange, and PopRange must not be recorded into a VkCommandBuffer where the <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VkCommandBufferUsageFlagBits.html">VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT</a> was set at <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VkCommandBufferBeginInfo.html"><code>vkBeginCommandBuffer</code></a> .<ul>
<li>BeginPass, EndPass, PushRange, and PopRange can be recorded into VkCommandBuffers where flags = 0. The usual <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/chap6.html#commandbuffers-lifecycle">CommandBuffer lifecycle</a> rules apply (only one submission in flight at a time).</li>
</ul>
</li>
<li>Range delimiters - <code>NVPW_VK_Profiler_CommandBuffer_PushRange</code> and <code>NVPW_VK_Profiler_CommandBuffer_PopRange</code> - cannot be inserted into <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/chap6.html#commandbuffers-secondary">Secondary Command Buffers</a>.<ul>
<li>To measure all workloads within a secondary command buffer, record into a primary command buffer in the pattern <code>PushRange, vkCmdExecuteCommands, PopRange</code>.</li>
<li>Measurements of individual workloads within a Secondary Command Buffer would require recording into a primary Command Buffer instead.</li>
</ul>
</li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/1.0-VK_EXT_debug_marker/doc/specs/vulkan/appendices/VK_EXT_debug_marker.txt">Vulkan Debug Marker</a> extension functions are not automatically treated as range delimiters.<ul>
<li>The recommended approach is to search for <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/vkCmdDebugMarkerBeginEXT.html"><code>vkCmdDebugMarkerBeginEXT</code></a> and <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/vkCmdDebugMarkerEndEXT.html"><code>vkCmdDebugMarkerEndEXT</code></a> , and nest the equivalent <code>NVPW_VK_Profiler_CommandBuffer_PushRange</code> / <code>NVPW_VK_Profiler_CommandBuffer_PopRange</code> commands within them.</li>
</ul>
</li>
<li>Error recovery is similar to NVN.<ul>
<li>Errors are not recoverable within a session. After an error occurs, CounterData contents are not lost, but additional values will not be collected and stored.</li>
<li>Error recovery requires creating a new session. EndSession must be called to terminate the current session [that is in an error state], before calling BeginSession to start again.</li>
</ul>
</li>
</ul>
<p><a class="anchor" id="MetricsChapter"></a></p>
<h1><a class="anchor" id="autotoc_md152"></a>
Metrics</h1>
<p>Metrics are high-level values derived from <a href="#Counter">counter</a> values.</p>
<p>The PerfWorks API comes with an advanced metrics calculation system, designed to help you determine what happened (counters &amp; metrics), and how close the program reached to peak GPU performance (throughputs).</p>
<p>Every counter has associated peak rates in the database, to allow computing its throughput as a percentage.</p>
<p>Two types of peak rates are available for every counter: burst and sustained. Burst rate is the maximum rate achievable in a single clock cycle. Sustained rate is the maximum rate achievable over an infinitely long measurement period, for "typical" operations. For many counters, burst == sustained. Since the burst rate cannot be exceeded, percentages against burst rate will always be less than 100%. Percentages against sustained rate can occasionally exceed 100% in edge cases.</p>
<p><a class="anchor" id="MetricEntities"></a></p>
<h2><a class="anchor" id="autotoc_md153"></a>
Metric Entities</h2>
<p>The Metrics layer has 3 major types of entities:</p>
<ul>
<li>Metrics : these are calculated quantities, with the following static properties:<ul>
<li>Description string.</li>
<li>Dimensional Units : a list of ('name', exponent) in the style of <a href="https://en.wikipedia.org/wiki/Dimensional_analysis">dimensional analysis</a>. Example string representation: <code>pixels / gpc_clk</code>.</li>
<li>Raw Metric dependencies : the list of raw metrics that must be collected, in order to evaluate the metric.</li>
<li>Every metric has the following sub-metrics built in.<ul>
<li><code>.peak_burst</code> : the peak burst rate</li>
<li><code>.peak_sustained</code> : the peak sustained rate</li>
<li><code>.per_active_cycle</code> : the number of operations per unit active cycle</li>
<li><code>.per_elapsed_cycle</code> : the number of operations per unit elapsed cycle</li>
<li><code>.per_region_cycle</code> : the number of operations per user-specified "range" cycle</li>
<li><code>.per_frame_cycle</code> : the number of operations per user-specified "frame" cycle</li>
<li><code>.pct_of_peak_burst_active</code> : % of peak burst rate achieved during unit active cycles</li>
<li><code>.pct_of_peak_burst_elapsed</code> : % of peak burst rate achieved during unit elapsed cycles</li>
<li><code>.pct_of_peak_burst_region</code> : % of peak burst rate achieved over a user-specified "range" time</li>
<li><code>.pct_of_peak_burst_frame</code> : % of peak burst rate achieved over a user-specified "frame" time</li>
<li><code>.pct_of_peak_sustained_active</code> : % of peak sustained rate achieved during unit active cycles</li>
<li><code>.pct_of_peak_sustained_elapsed</code> : % of peak sustained rate achieved during unit elapsed cycles</li>
<li><code>.pct_of_peak_sustained_region</code> : % of peak sustained rate achieved over a user-specified "range" time</li>
<li><code>.pct_of_peak_sustained_frame</code> : % of peak sustained rate achieved over a user-specified "frame" time</li>
</ul>
</li>
</ul>
</li>
<li>Counters : may be either a raw counter from the GPU, or a calculated counter value. Every counter has 4 sub-metrics under it:<ul>
<li><code>.sum</code> : The sum of counter values across all unit instances.</li>
<li><code>.avg</code> : The average counter value across all unit instances.</li>
<li><code>.min</code> : The minimum counter value across all unit instances.</li>
<li><code>.max</code> : The maximum counter value across all unit instances.</li>
</ul>
</li>
<li>Throughputs : a family of percentage metrics that indicate how close a portion of the GPU reached to peak rate. Every throughput has the following sub-metrics:<ul>
<li><code>.pct_of_peak_burst_active</code> : % of peak burst rate achieved during unit active cycles</li>
<li><code>.pct_of_peak_burst_elapsed</code> : % of peak burst rate achieved during unit elapsed cycles</li>
<li><code>.pct_of_peak_burst_region</code> : % of peak burst rate achieved over a user-specified "range" time</li>
<li><code>.pct_of_peak_burst_frame</code> : % of peak burst rate achieved over a user-specified "frame" time</li>
<li><code>.pct_of_peak_sustained_active</code> : % of peak sustained rate achieved during unit active cycles</li>
<li><code>.pct_of_peak_sustained_elapsed</code> : % of peak sustained rate achieved during unit elapsed cycles</li>
<li><code>.pct_of_peak_sustained_region</code> : % of peak sustained rate achieved over a user-specified "range" time</li>
<li><code>.pct_of_peak_sustained_frame</code> : % of peak sustained rate achieved over a user-specified "frame" time</li>
</ul>
</li>
</ul>
<p>At the configuration step, you must specify metric names. Counters and throughputs are not directly schedulable.</p>
<p>The sum,avg,min,max sub-metrics for counters are also called "rollups".</p>
<p>Examples: </p><div class="fragment"><div class="line">vpc__input_prims            # counter</div>
<div class="line">vpc__input_prims.sum        # metric</div>
<div class="line">vpc__input_prims.avg        # metric</div>
<div class="line">vpc__input_prims.min        # metric</div>
<div class="line">vpc__input_prims.max        # metric</div>
<div class="line"> </div>
<div class="line">## all names below are metrics</div>
<div class="line">vpc__input_prims.sum</div>
<div class="line">vpc__input_prims.sum.peak_burst</div>
<div class="line">vpc__input_prims.sum.peak_sustained</div>
<div class="line">vpc__input_prims.sum.per_active_cycle</div>
<div class="line">vpc__input_prims.sum.per_elapsed_cycle</div>
<div class="line">vpc__input_prims.sum.per_region_cycle</div>
<div class="line">vpc__input_prims.sum.per_frame_cycle</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_burst_active</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_burst_elapsed</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_burst_region</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_burst_frame</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_sustained_active</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_sustained_elapsed</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_sustained_region</div>
<div class="line">vpc__input_prims.sum.pct_of_peak_sustained_frame</div>
<div class="line"> </div>
<div class="line">## custom counter definition</div>
<div class="line">vpc__input_prims_not_line = vpc__input_prims - vpc__input_prims_line</div>
<div class="line">## derived counters have all rollups available</div>
<div class="line">vpc__input_prims_not_line.sum</div>
<div class="line">vpc__input_prims_not_line.avg</div>
<div class="line">vpc__input_prims_not_line.min</div>
<div class="line">vpc__input_prims_not_line.max</div>
<div class="line"> </div>
<div class="line">## custom metric definitions</div>
<div class="line">vpc__output_prims_pct_of_input = vpc__output_prims.avg / vpc__input_prims.avg</div>
<div class="line">gpu__pct_of_prims_rasterized = raster__setup_output_prims.avg / pda__input_prims.avg</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md154"></a>
Metric Naming Conventions</h2>
<p>Counters and metrics <em>generally</em> obey the naming scheme:</p>
<ul>
<li>Unit-Level Counter: <code>unit__&lt;subunit&gt;_&lt;pipestage&gt;_quantity_&lt;qualifiers&gt;</code></li>
<li>Interface Counter: <code>unit__&lt;subunit&gt;_&lt;interface&gt;_&lt;pipestage&gt;_quantity_&lt;qualifiers&gt;</code></li>
<li>Unit Metric: <code>&lt;counter_name&gt;.&lt;rollup_metric&gt;</code></li>
<li>Sub-Metric: <code>&lt;counter_name&gt;.&lt;rollup_metric&gt;.&lt;submetric&gt;</code></li>
</ul>
<p>where</p>
<ul>
<li>unit: A logical of physical unit of the GPU. See the section on <a href="#HardwareUnits">Hardware Units</a>.</li>
<li>subunit: The subunit within the unit where the counter was measured. Sometimes this is a pipeline mode instead.</li>
<li>pipestage: The pipeline stage within the subunit where the counter was measured.</li>
<li>quantity: What is being measured. Generally matches the "dimensional units".</li>
<li>qualifiers: Any additional predicates or filters applied to the counter. Often, an unqualified counter can be broken down into several qualified sub-components.</li>
<li>interface: Of the form <code>&lt;unitA&gt;2&lt;unitB&gt;</code>, where <code>unitA</code> is the source-unit (sender) and <code>unitB</code> is the destination-unit (receiver).</li>
<li>rollup_metric: One of sum,avg,min,max.</li>
<li>submetric: see section <a href="#MetricEntities">Metric Entities</a> for the full list.</li>
</ul>
<p>Components are not always present. Most top-level counters have no qualifiers. Subunit and pipestage may be absent where irrelevant, or there may be many subunit specifiers for detailed counters.</p>
<p>Examples:</p>
<div class="fragment"><div class="line">vpc__input_prims                                        # Counter</div>
<div class="line">*   unit        : [vpc](#VPC)</div>
<div class="line">*   subunit     : _none_</div>
<div class="line">*   pipestage   : input</div>
<div class="line">*   quantity    : prims</div>
<div class="line">*   qualifiers  : _none_</div>
<div class="line"> </div>
<div class="line">vpc__input_prims_line                                   # Counter</div>
<div class="line">*   unit        : [vpc](#VPC)</div>
<div class="line">*   subunit     : _none_</div>
<div class="line">*   pipestage   : input</div>
<div class="line">*   quantity    : prims</div>
<div class="line">*   qualifiers  : line</div>
<div class="line"> </div>
<div class="line">vpc__input_prims.sum                                    # Metric</div>
<div class="line">*   counter         : vpc__input_prims</div>
<div class="line">*   rollup_metric   : sum</div>
<div class="line">vpc__input_prims_line.sum                               # Metric</div>
<div class="line">*   counter         : vpc__input_prims_line</div>
<div class="line">*   rollup_metric   : sum</div>
<div class="line">vpc__input_prims_line.sum.pct_of_peak_burst_active      # Metric</div>
<div class="line">*   counter         : vpc__input_prims_line</div>
<div class="line">*   rollup_metric   : sum</div>
<div class="line">*   submetric       : pct_of_peak_burst_active</div>
<div class="line"> </div>
<div class="line">## In many cases, qualified metrics sum up to the unqualified metric.  For example:</div>
<div class="line">    vpc__input_prims_line</div>
<div class="line">    vpc__input_prims_patch</div>
<div class="line">    vpc__input_prims_point</div>
<div class="line">    vpc__input_prims_triangle</div>
<div class="line"> </div>
<div class="line">raster__setup_output_prims                              # Counter</div>
<div class="line">*   unit        : [raster](#RASTER)</div>
<div class="line">*   subunit     : [setup](#SETUP)</div>
<div class="line">*   pipestage   : output</div>
<div class="line">*   quantity    : prims</div>
<div class="line">*   qualifiers  : _none_</div>
<div class="line"> </div>
<div class="line">raster__setup_output_prims_triangle                     # Counter</div>
<div class="line">*   unit        : [raster](#RASTER)</div>
<div class="line">*   subunit     : [setup](#SETUP)</div>
<div class="line">*   pipestage   : output</div>
<div class="line">*   quantity    : prims</div>
<div class="line">*   qualifiers  : triangle</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md155"></a>
Cycle Metrics</h2>
<p>Metrics using the term <code>cycles</code> in the name report the number of cycles in the unit's clock domain. Unit-level cycle metrics include:</p>
<ul>
<li><code>unit__cycles_elapsed</code>: The number of cycles within a range. The cycles' <code>DimUnits</code> are specific to the unit's clock domain.</li>
<li><code>unit__cycles_active</code>: The number of cycles where the unit was processing data.</li>
<li><code>unit__cycles_stalled</code>: The number of cycles where the unit was unable to process new data because its output interface was blocked.</li>
<li><code>unit__cycles_busy</code>: The number of cycles where the unit was not idle.</li>
<li><code>unit__cycles_idle</code>: The number of cycles where the unit was idle.</li>
</ul>
<p>Interface-level cycle metrics are often (not always) available in the following variations:</p>
<ul>
<li><code>unit__&lt;interface&gt;_active</code>: Cycles where data was transferred from source-unit to destination-unit.</li>
<li><code>unit__&lt;interface&gt;_stalled</code>: Cycles where the source-unit had data, but the destination-unit was unable to accept data.</li>
<li><code>unit__&lt;interface&gt;_backpressured</code>: Cycles where the destination-unit was unable to accept data. Includes both <code>stalled</code> cycles, and cycles where the source-unit had no data available.</li>
<li><code>unit__&lt;interface&gt;_busy</code>: All non-idle cycles; equivalent to the sum of <code>active</code> and <code>backpressured</code> cycles.</li>
</ul>
<h2><a class="anchor" id="autotoc_md156"></a>
Time Metrics</h2>
<ul>
<li><code>gpu__time_start</code>: gpu timestamp in nanoseconds, relative to the start of the pass, when the range is first submitted to the gpu</li>
<li><code>gpu__time_end</code>: gpu timestamp in nanoseconds, relative to the start of the pass, when the last submittal of the range finishes gpu processing</li>
<li><code>gpu__time_duration</code>: total gpu time in nanoseconds, in pipelined mode, this is the incremental time duration. See "Isolated vs Pipelined Passes" above for more info.</li>
<li><code>gpu__time_active</code>: total gpu time in nanoseconds, in pipelined mode, this is the total range duration. This is equivalent to <code>gpu__time_duration</code> in isolated mode.</li>
</ul>
<p>The <code>gpu__time_duration</code> or <code>gpu__time_active</code> is not simply:</p>
<p><code>gpu__time_end - gpu__time_start</code></p>
<p>A range id may cover several ranges within a pass, therefore <code>gpu__time_duration</code> and <code>gpu__time_active</code> is the sum of each of the range's durations with the same id.</p>
<p><em>NOTE:</em> <code>gpu__time_duration</code> nor <code>gpu__time_active</code> does not currently take into account duration not in context due to context switches. This can result in a higher duration than expected.</p>
<ul>
<li><code>cpu__time_duration</code>: this is the cpu only duration in nanoseconds for a range. This includes any time spent in the driver handing off the gpu command to the driver.</li>
</ul>
<p>This time has no correlation to gpu__time_duration due to the asynchronous nature of the gpu.</p>
<ul>
<li><code>system__time_duration</code> : this is simply <code>cpu__time_duration</code> + <code>gpu__time_duration</code></li>
</ul>
<p>This is not the duration between when the first command is executed on the cpu to the time the last command is finished executing on the gpu.</p>
<p>This diagram demonstrates 2 ranges collected in pipelined mode. Times for range 2 are shown. <img src="time_metrics_pipelined.svg" alt="" style="pointer-events: none;" class="inline" title="Time Metrics Pipelined"/> Since range 2 begins while the first part of range 1 is on the gpu, the <code>gpu__time_duration</code> is the incremental cost of range 2. <code>gpu__time_active</code> is the full time for range 2.</p>
<p>This diagram demonstrates the same 2 ranges collected in isolated mode. Times for range 1 are shown. <img src="time_metrics_isolated.svg" alt="" style="pointer-events: none;" class="inline" title="Time Metrics Isolated"/> For range 1, notice how <code>gpu__time_duration != gpu__time_end - gpu__time_start</code> due to the split range.</p>
<h1><a class="anchor" id="autotoc_md157"></a>
Recommended Metrics for Realtime</h1>
<p>Familiarity with <a href="#RealtimeMetricsEvaluation">Realtime Metrics Evaluation</a> is useful for the following section.</p>
<p>These recommendations are provided per scenario, and per Perfmon type (HUB, FBP, GPC, TPC). Counters for each Perfmon type are scheduled independently, and thus form interchangeable groupings. For example, the FBP perfmon can be configured to measure <code>(crop__cycles_active, zrop__cycles_active)</code> or <code>(rdm__cycles_active, lts__cycles_active)</code> without affecting counters measured from {HUB, GPC, TPC}.</p>
<h2><a class="anchor" id="autotoc_md158"></a>
Realtime Counter Constraints</h2>
<p>"True" realtime observation must occur in a <em>single pass configuration</em>, meaning all counters are collected simultaneously, so that a free-running program (with no replay loops) has all its counters collected. With a single pass configuration, PerfWorks introduces less than 1% overhead on both CPU and GPU.</p>
<p>Selecting counters that fit in a single pass is not always easy due to the following constraints:</p>
<ul>
<li>Each <a href="#HardwareUnits">hardware unit</a> has a configuration register for selecting signals to observe. Only a small number of signals may be observed at once for a given hardware unit, and these are hard-wired in the GPU.</li>
<li>There are only 4 Perfmon types on NX (GM20B): HUB, FBP, GPC, TPC. (<code>NUM_PERFMON_TYPES = 4</code>)</li>
<li>Each Perfmon only has 4 counter registers. (<code>NUM_COUNTERS_PER_PERFMON = 4</code>)</li>
<li>Some Perfmons must measure 2 instances of a hardware unit, requiring 2x the number of counter registers per Perfmon.<ul>
<li>Examples of 2 instances per Perfmon: CDP, CROP, LTCX, LTS, MCCIF, PIXOUT, SMP, ZROP</li>
</ul>
</li>
<li>There are 4 SMSP instances per TPC Perfmon, so only one SMSP counter can be measured per pass.</li>
<li>Some counter definitions are wider or more complex, requiring multiple counter registers.</li>
</ul>
<p>The absolute maximum number of counters in a single pass is <code>NUM_PERFMON_TYPES * NUM_COUNTERS_PER_PERFMON == 16</code>, but in practice we typically can collect fewer than 16 counters per pass.</p>
<p>Some high-level metrics like cache-hit-rates, input/output ratios, or breakdowns of operations by type, require multiple passes to collect. Observing activity over the full pipeline also requires multiple passes. For these reasons, we sometimes will recommend a two-pass configuration. Counters will be collected across two frames, but typically the rendered content will not change much between adjacent frames, so it's a reasonable compromise. Alternatively, an engine could replay each frame twice, halving the wallclock FPS in exchange for more accurate counters. Note that multi-pass configurations cannot achieve less than 1% overhead; it is closer to ~3% of GPU overhead due to the extra cost of register programming per pass.</p>
<p>Approximate throughput metrics are provided for convenience, but most require more than 2 passes by themselves. Collecting all throughput metrics requires a much larger number of passes than is suitable for realtime observation.</p>
<h2><a class="anchor" id="autotoc_md159"></a>
Basic 3D Activity</h2>
<p>The following metrics are good for high-level performance triage. You can also detect the presence of compute. Particularly good for shader pipelines containing only {VS, PS} or {VS, FGS, PS}.</p>
<div class="fragment"><div class="line">gr__cycles_active</div>
<div class="line">pda__cycles_active</div>
<div class="line">mmu__cycles_active</div>
<div class="line">scc__cycles_active</div>
<div class="line">crop__cycles_active</div>
<div class="line">zrop__cycles_active</div>
<div class="line">vpc__cycles_active</div>
<div class="line">raster__zcull_input_tiles</div>
<div class="line">raster__frstr_output_cycles</div>
<div class="line">prop__zrop_output_active</div>
<div class="line">vaf__alpha_cycles_active</div>
<div class="line">sm__cycles_active</div>
<div class="line">sm__cycles_active_3d</div>
<div class="line">sm__cycles_active_3d_ps</div>
</div><!-- fragment --><p>General triage method:</p>
<ul>
<li>Is <code>gr__cycles_active</code> low? If yes, fix that first.</li>
<li>Is <code>mmu__cycles_active</code> high? If yes, there may be pathological memory access patterns.</li>
<li>Is the range 3D or Compute shader dominated? Compare <code>sm__cycles_active_compute</code> and <code>sm__cycles_active_3d</code>.</li>
<li>If the range is dominated by 3D, look for 3D bottlenecks, starting from the back of the pipe:<ul>
<li><code>crop__cycles_active</code> : CROP blend</li>
<li><code>sm__cycles_active_3d_ps</code> : pixel shading</li>
<li><code>zrop__cycles_active</code> : depth/stencil test</li>
<li><code>prop__zrop_output_active</code> : depth/stencil samples sent from rasterizer or PS-output to ZROP; includes EarlyZ, LateZ, and ShaderZ modes</li>
<li><code>raster__frstr_output_cycles</code> : rasterizer generates depth samples and fragments for shading</li>
<li><code>raster__zcull_input_tiles</code> : zcull over coarse raster tiles</li>
<li><code>vpc__cycles_active</code> : primitive assembly including Clip/Cull</li>
<li><code>sm__cycles_active_3d_vtg_only</code> : VTG shading during startup transients when PS hasn't been started</li>
<li><code>vaf__alpha_cycles_active</code> : vertex buffer fetch, for vertex shader</li>
<li><code>pda__cycles_active</code> : index buffer fetch</li>
<li><code>scc__cycles_active</code> : draw call shader bindings and uniform buffer updates</li>
</ul>
</li>
</ul>
<p>Counter descriptions and pass placement:</p>
<ul>
<li>HUB (pass #1)<ul>
<li><code>gr__cycles_active</code> : if low, the GPU is under-utilized.</li>
<li><code>pda__cycles_active</code> : measures vertex fetch from index buffer.</li>
<li><code>mmu__cycles_active</code> : if high, memory accesses may be scattered.</li>
<li><code>scc__cycles_active</code> : if high, there may be many state changes (including uniform buffer updates) that limit draw call concurrency.</li>
</ul>
</li>
<li>FBP (pass #1)<ul>
<li><code>crop__cycles_active</code> : if high, then <a href="#CROP">CROP</a>-bound.</li>
<li><code>zrop__cycles_active</code> : if high, and <code>prop__zrop_output_active</code> is not high, there may be poor depth compression caused by high overdraw or many small triangles.</li>
</ul>
</li>
<li>GPC (pass #1)<ul>
<li><code>vpc__cycles_active</code> : if high, Clip/Cull may be the bottleneck.</li>
<li><code>raster__zcull_input_tiles</code> : if high, then may be depth-test bound at ZCULL.</li>
<li><code>raster__frstr_output_cycles</code> : if high, rasterization may be the bottleneck.</li>
<li><code>prop__zrop_output_active</code> : if high, then may be depth-test bound sending samples from <a href="#PROP">PROP</a> to <a href="#ZROP">ZROP</a>.</li>
</ul>
</li>
<li>TPC (pass #1)<ul>
<li><code>vaf__alpha_cycles_active</code> : measures attribute fetch from vertex buffer</li>
<li><code>sm__cycles_active</code> : % of time when any shader warp was resident.</li>
<li><code>sm__cycles_active_3d</code> : % of time when any 3D shader warp was resident.</li>
<li><code>sm__cycles_active_3d_ps</code> : % of time when PS warps were resident; expect high.</li>
</ul>
</li>
<li>Calculated:<ul>
<li><code>sm__cycles_active_compute</code> : % of time compute warps were resident; compute and 3d do not run concurrently on NX.</li>
<li><code>sm__cycles_active_3d_vtg_only</code> ; % of time when VTG warps were not running concurrently with PS; expect low.</li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md160"></a>
Alternate 3D Activity</h3>
<p>If CROP isn't your bottleneck (e.g. focused on depth-only render passes) then consider using this:</p>
<div class="fragment"><div class="line">fe__cycles_active</div>
<div class="line">pda__cycles_active</div>
<div class="line">mmu__cycles_active</div>
<div class="line">scc__cycles_active</div>
<div class="line">zrop__cycles_active</div>
<div class="line">lts__cycles_active</div>
<div class="line">vpc__cycles_active</div>
<div class="line">raster__zcull_input_tiles</div>
<div class="line">raster__frstr_output_cycles</div>
<div class="line">prop__zrop_output_active</div>
<div class="line">vaf__alpha_cycles_active</div>
<div class="line">sm__cycles_active</div>
<div class="line">l1tex__m_read_request_active</div>
</div><!-- fragment --><p>General triage method:</p>
<ul>
<li>Is <code>sm__cycles_active</code> high? If yes, then shader bound. (could be ALU or TEX though)</li>
<li>Is <code>lts__cycles_active</code> high? If yes, then memory bound.</li>
<li>Is <code>l1tex__m_read_request_active</code> high? If yes, then memory bound at TEX.</li>
<li>Is <code>mmu__cycles_active</code> high? If yes, there may be pathological memory access patterns.</li>
<li>Look for bottlenecks, starting from the back of the pipe:<ul>
<li><code>sm__cycles_active</code> : assuming shader time dominated by PS, this is the last observable stage in this configuration</li>
<li><code>zrop__cycles_active</code> : depth/stencil test</li>
<li><code>prop__zrop_output_active</code> : depth/stencil samples sent from rasterizer or PS-output to ZROP; includes EarlyZ, LateZ, and ShaderZ modes</li>
<li><code>raster__frstr_output_cycles</code> : rasterizer generates depth samples and fragments for shading</li>
<li><code>raster__zcull_input_tiles</code> : zcull over coarse raster tiles</li>
<li><code>vpc__cycles_active</code> : primitive assembly including Clip/Cull</li>
<li><code>vaf__alpha_cycles_active</code> : vertex buffer fetch, for vertex shader</li>
<li><code>pda__cycles_active</code> : index buffer fetch</li>
<li><code>scc__cycles_active</code> : draw call shader bindings and uniform buffer updates</li>
<li><code>fe__cycles_active</code> : GPU command processing</li>
</ul>
</li>
</ul>
<p>Counter descriptions and pass placement:</p>
<ul>
<li>HUB (pass #1)<ul>
<li><code>fe__cycles_active</code> : if high, <a href="#FE">FE</a> is either performing large DMA copies, or is processing too many large command buffers.</li>
<li><code>pda__cycles_active</code> : measures vertex fetch from index buffer.</li>
<li><code>mmu__cycles_active</code> : if high, memory accesses may be scattered.</li>
<li><code>scc__cycles_active</code> : if high, there may be many state changes (including uniform buffer updates) that limit draw call concurrency.</li>
</ul>
</li>
<li>FBP (pass #1)<ul>
<li><code>zrop__cycles_active</code> : if high, and <code>prop__zrop_output_active</code> is not high, there may be poor depth compression caused by high overdraw or many small triangles.</li>
<li><code>lts__cycles_active</code> : if high, then L2 Cache is a limiter. There's also a chance that DRAM is a limiter; check <a href="#MCCIF">MCCIF</a> stats in a separate configuration.</li>
</ul>
</li>
<li>GPC (pass #1)<ul>
<li><code>vpc__cycles_active</code> : if high, Clip/Cull may be the bottleneck.</li>
<li><code>raster__zcull_input_tiles</code> : if high, then may be depth-test bound at ZCULL.</li>
<li><code>raster__frstr_output_cycles</code> : if high, rasterization may be the bottleneck.</li>
<li><code>prop__zrop_output_active</code> : if high, then may be depth-test bound sending samples from <a href="#PROP">PROP</a> to <a href="#ZROP">ZROP</a>.</li>
</ul>
</li>
<li>TPC (pass #1)<ul>
<li><code>vaf__alpha_cycles_active</code> : measures attribute fetch from vertex buffer</li>
<li><code>sm__cycles_active</code> : % of time when any shader warp was resident.</li>
<li><code>l1tex__m_read_request_active</code> : % of time when an L1 miss generated an L2 request.</li>
</ul>
</li>
</ul>
<p>Possible substitutions:</p>
<ul>
<li>In place of <code>l1tex__m_read_request_active</code>:<ul>
<li><code>l1tex__texin_sm2tex_active</code> : see <a href="#RealtimeCacheHitRates">Memory section</a>.</li>
<li><code>l1tex__f_output_tex2sm_active</code> : if high, then range is TEX <em>return data</em> bound. Typically a compute-only problem from 64-bit or 128-bit global load instructions.</li>
<li><code>l1tex__d_output_wavefronts</code> : see <a href="#RealtimeCacheHitRates">Memory section</a>.</li>
</ul>
</li>
<li>In place of <code>vaf__alpha_cycles_active</code>:<ul>
<li><code>pel__out_l2_requests</code> : if high, then attribute transfer is consuming high L2 bandwidth. (ISBEs being written to CBEs at the end of World Alpha and Beta phases)</li>
<li><code>stri__attrs</code> : if high, then preparing PS attributes in TRAM is a bottleneck.</li>
</ul>
</li>
<li>TPC : detecting killed PS threads (GLSL <code>discard</code> command in fragment shaders)<ul>
<li><code>vaf__alpha_cycles_active</code> : measures attribute fetch from vertex buffer</li>
<li><code>sm__cycles_active</code> : % of time when any shader warp was resident.</li>
<li><code>sm__ps_quads_launched</code> : # of 2x2 PS quads launched. A launched quad has at least one thread with sample coverage.<ul>
<li><code>sm__threads_launched_ps</code> can be evaluated at no extra cost. It = <code>sm__ps_quads_launched * 4</code>.</li>
</ul>
</li>
<li><code>sm__ps_quads_sent_to_pixout</code> : # of 2x2 PS quads where at least one thread was not killed (discarded) by PS program.</li>
<li><code>sm__ps_quads_sent_to_pixout_pct</code> : % of PS quads surviving the PS program.</li>
</ul>
</li>
</ul>
<p><a class="anchor" id="RealtimeCacheHitRates"></a></p>
<h2><a class="anchor" id="autotoc_md161"></a>
Cache Hit Rates</h2>
<p>It's possible to get cache hit rates from all major caches in a single pass.</p>
<div class="fragment"><div class="line">mmu__hubtlb_requests_hit_rate_pct</div>
<div class="line">gr__cycles_active</div>
<div class="line">host__pushbuffer_dwords</div>
<div class="line">lts__t_tag_requests_hit_rate_pct</div>
<div class="line">gcc__l15_requests_hit_rate_pct</div>
<div class="line">gcc__tsl2_requests_hit_rate_pct</div>
<div class="line">vpc__write_sectors</div>
<div class="line">l1tex__t_sectors_hit_rate_pct</div>
</div><!-- fragment --><p>Which allows the following additional metrics to be evaluated at no additional cost:</p>
<div class="fragment"><div class="line">mmu__hubtlb_requests_hit_rate_pct</div>
<div class="line">    mmu__hubtlb_requests</div>
<div class="line">    mmu__hubtlb_requests_hit</div>
<div class="line">    mmu__hubtlb_requests_miss</div>
<div class="line">gr__cycles_active</div>
<div class="line">lts__t_tag_requests_hit_rate_pct</div>
<div class="line">    lts__t_tag_requests</div>
<div class="line">    lts__t_tag_requests_hit</div>
<div class="line">    lts__t_tag_requests_miss</div>
<div class="line">gcc__l15_requests_hit_rate_pct</div>
<div class="line">    gcc__l15_requests</div>
<div class="line">    gcc__l15_requests_hit</div>
<div class="line">    gcc__l15_requests_miss</div>
<div class="line">gcc__tsl2_requests_hit_rate_pct</div>
<div class="line">    gcc__tsl2_requests</div>
<div class="line">    gcc__tsl2_requests_hit</div>
<div class="line">vpc__write_sectors</div>
<div class="line">l1tex__t_sectors_hit_rate_pct</div>
<div class="line">    l1tex__t_sectors</div>
<div class="line">    l1tex__t_sectors_hit</div>
<div class="line">    l1tex__t_sectors_miss</div>
</div><!-- fragment --><p>Counter descriptions and pass placement:</p>
<ul>
<li>HUB (pass #1)<ul>
<li><code>mmu__hubtlb_requests_hit_rate_pct</code> : % of PTE requests that hit in HUB TLB (the "L2 TLB").</li>
<li><code>mmu__hubtlb_requests</code> : high # of requests here implies L1TLBs and uTLBs experienced high miss rates.</li>
<li><code>host__pushbuffer_dwords</code> : indicates command memory bandwidth into <a href="#FE">FE</a>.</li>
</ul>
</li>
<li>FBP (pass #1)<ul>
<li><code>lts__t_tag_requests_hit_rate_pct</code> : % of L2 <b>tag</b> accesses that hit.<ul>
<li>This metric was chosen because it can be collected in a single pass, as opposed to <code>lts__t_sectors_hit_rate_pct</code>.</li>
<li>Caveat: Not a true indicator of bandwidth since sectors may be sparsely loaded into cache-lines depending on requested addresses. (4 sectors per cache-line, 1 tag per cache-line)</li>
</ul>
</li>
</ul>
</li>
<li>GPC (pass #1)<ul>
<li><code>gcc__l15_requests_hit_rate_pct</code> : % of shader constant and instruction requests that hit in L1.5 cache. Incoming requests include shader I$ misses, IMC misses (non-indexed constant lookup), and IDC misses (indexed constant lookup via <code>LDC</code> instruction).</li>
<li><code>gcc__tsl2_requests_hit_rate_pct</code> : % of texture or sampler header requests that hit in TSL2 cache. If low, then shaders may be thrashing over a large number of texture/sampler combos (threshold is ~64-84 on NX).</li>
</ul>
</li>
<li>TPC (pass #1)<ul>
<li><code>l1tex__t_sectors_hit_rate_pct</code> : % of L1TEX <b>sector</b> accesses that hit.<ul>
<li>This includes texture, surface, and global load/store acccesses by shaders.</li>
</ul>
</li>
<li><code>l1tex__t_sectors_miss</code> : implies the # of 32B sectors requested from L2.<ul>
<li>True indicator of L1&lt;-&gt;L2 bandwidth.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Possible substitutions:</p>
<ul>
<li>In place of <code>gcc__tsl2_requests_hit_rate_pct</code>:<ul>
<li><code>vpc__write_sectors</code> : write bandwidth to CBEs in L2 from VPC.</li>
</ul>
</li>
</ul>
<p>Additional configurations:</p>
<ul>
<li>FBP (pass #2 + pass #3)<ul>
<li><code>lts__t_sectors</code></li>
<li><code>lts__t_sectors_hit</code></li>
<li>(calculated) <code>lts__t_sectors_hit_rate_pct</code> : % of sector requests that hit in L1TEX cache.<ul>
<li>Unfortunately cannot be collected in single pass.</li>
</ul>
</li>
<li><code>(lts__t_sectors - lts__t_sectors_hit)</code> is equivalent to <code>lts__t_sectors_miss</code> which is a true indicator of bandwidth.</li>
</ul>
</li>
<li>FBP (pass #4)<ul>
<li><code>crop__read_subpackets</code> : # of 32B L2 sector reads. Unfortunately, cannot gather <code>crop__write_subpackets</code> in the same pass.</li>
<li><code>zrop__read_subpackets</code> : # of 32B L2 sector reads. Unfortunately, cannot gather <code>zrop__write_subpackets</code> in the same pass.</li>
</ul>
</li>
<li>FBP (pass #5)<ul>
<li><code>crop__write_subpackets</code> : # of 32B L2 sector writes.</li>
<li><code>zrop__write_subpackets</code> : # of 32B L2 sector writes.</li>
</ul>
</li>
<li>TPC (pass #2)<ul>
<li><code>l1tex__texin_sm2tex_active</code> : if high, then range is TEX or LG <em>request</em> bound.</li>
<li><code>l1tex__d_output_wavefronts</code> : if high and <code>l1tex__texin_sm2tex_active</code> is low, then range is TEX filtering bound. Consider reducing the # of aniso or trilinear filtered texture accesses.</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md162"></a>
GPU DRAM Read/Write</h2>
<p>DRAM traffic generated from the GPU cannot be collected in a single pass due to hardware limitations. However, the following two-pass configuration provides a reasonable approximation of bandwidth.</p>
<div class="fragment"><div class="line">lts__mccif_read_bytes</div>
<div class="line">lts__mccif_write_bytes_appx</div>
</div><!-- fragment --><p>Which allows the following additional metrics to be evaluated at no additional cost:</p>
<div class="fragment"><div class="line">lts__mccif_read_bytes</div>
<div class="line">    lts__mccif_read_cycles_32</div>
<div class="line">    lts__mccif_read_cycles_64</div>
<div class="line">    lts__mccif_read_sectors</div>
<div class="line">lts__mccif_write_bytes_appx</div>
<div class="line">    lts__mccif_write_sectors_excluding_16</div>
</div><!-- fragment --><p>Counter descriptions and pass placement:</p>
<ul>
<li>FBP (pass #1) : read traffic<ul>
<li><code>lts__mccif_read_bytes</code> : # of bytes read from the SoC DRAM controller to the GPU.<ul>
<li>Note that in a single pass, it's possible to get all read traffic. <code>lts__mccif_read_bytes</code> can be combined with any other {HUB, GPC, TPC} counters.</li>
</ul>
</li>
</ul>
</li>
<li>FBP (pass #2) : write traffic<ul>
<li><code>lts__mccif_write_bytes_appx</code> : # of bytes written from the GPU to the SoC DRAM controller.<ul>
<li>This counter is approximate because it ignores <code>lts__mccif_write_cycles_16</code> which counts 16 byte write operations. 16 byte writes are rare because GPU cacheable memory is always read and written by L2 in units of 32 bytes (L2 sectors). Only uncacheable writes should generate 16 byte write operations to the memory controller.</li>
<li>Note that in a single pass, it's possible to get approximate write traffic. <code>lts__mccif_write_bytes_appx</code> can be combined with any other {HUB, GPC, TPC} counters.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md163"></a>
Primitive Flow</h2>
<div class="fragment"><div class="line">pda__input_prims</div>
<div class="line">pdb__input_batches</div>
<div class="line">wwdx__input_prims</div>
<div class="line">vpc__input_prims</div>
<div class="line">raster__setup_input_prims</div>
<div class="line">raster__crstr_input_prims</div>
<div class="line">vaf__alpha_fetched_attr_scalar</div>
<div class="line">sm__cycles_active_3d_vtg</div>
</div><!-- fragment --><ul>
<li>HUB (pass #1)<ul>
<li><code>pda__input_prims</code> : input primitives to draw calls.</li>
<li><code>pdb__input_batches</code> : batches sent from VS or Tesselation.</li>
</ul>
</li>
<li>GPC (pass #1)<ul>
<li><code>wwdx__input_prims</code> : primitives redistributed between VTG stages.</li>
<li><code>vpc__input_prims</code> : primitives that reached Primitive Assembly stage.</li>
<li><code>raster__setup_input_prims</code> : primitives that reached <a href="#SETUP">SETUP</a>.</li>
<li><code>raster__crstr_input_prims</code> : primitives that reached <a href="#CRSTR">CRSTR</a>.</li>
</ul>
</li>
<li>TPC (pass #1)<ul>
<li><code>vaf__alpha_fetched_attr_scalar</code> : scalar attributes fetched from vertex buffer for VS.</li>
<li><code>sm__cycles_active_3d_vtg</code> : time when VTG warps were resident.</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md164"></a>
Stalls and Limiters</h2>
<p>The following (incomplete) list of counters have not been optimized into single pass configurations, but may be useful for diagnosing stalls in key areas of the pipe.</p>
<div class="fragment"><div class="line">FBP:</div>
<div class="line">    rdm__crop_output_stalled</div>
<div class="line">    rdm__zrop_output_stalled</div>
<div class="line">TPC:</div>
<div class="line">    l1tex__texin_stalled_on_tsl2_miss</div>
<div class="line">    pel__out_l2_requests</div>
<div class="line">    pel__out_read_stalled_stri</div>
<div class="line">    pel__out_read_stalled_vaf_alpha</div>
<div class="line">    pel__out_read_stalled_vaf_beta</div>
<div class="line">    mpc__isbe_allocation_stalled</div>
<div class="line">    mpc__isbe_allocation_stalled_alpha_on_vsc</div>
<div class="line">    mpc__isbe_allocation_stalled_beta_on_vsc</div>
<div class="line">    mpc__tram_allocation_stalled</div>
<div class="line">    mpc__tram_fill_fifo_stalled</div>
<div class="line">    mpc__tram_startxy_fifo_stalled</div>
<div class="line">    mpc__warp_launch_stalled_ps</div>
<div class="line">    mpc__warp_launch_stalled_vtg</div>
<div class="line">GPC:</div>
<div class="line">    cbmgr__alpha_cbe_allocation_stalled</div>
<div class="line">    cbmgr__beta_cbe_allocation_stalled</div>
<div class="line">    prop__csb_output_stalled</div>
<div class="line">    swdx__output_stalled</div>
<div class="line">    wwdx__output_stalled</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md165"></a>
Advanced Concepts</h1>
<h2><a class="anchor" id="autotoc_md166"></a>
Pass-Groups</h2>
<p>The <a href="#ConfigurationSection">Configuration section</a> presents simplified recipes for configuring counters, including through <code>nvperf</code>. In the simplified workflow, PerfWorks will decide how to schedule counters into passes. PerfWorks attempts to schedule the maximum number of counters per pass to reduce the number of required replays, but hardware constraints may force the creation of additional passes. There is no guarantee that any given metric will be collected on a particular pass.</p>
<p>In special cases, <a href="#You">you</a> may want to schedule two counters in the same pass, to get a precise sum or ratio. For example, <code>sm__cycles_active_3d + sm__cycles_active_compute == sm__cycles_active</code>, but the equality strictly holds only when measured in the same pass. Splitting measurement across passes will result in a less precise value, influenced by work distribution and other non-deterministic processes. It's possible to encourage these two counters into the same pass by creating a new PassGroup at configuration time, via <code>NVPA_RawMetricsConfig_BeginPassGroup</code>. Caveats:</p>
<ul>
<li>Over-using PassGroups may result in sub-optimal scheduling, resulting in additional replay passes needed to collect all counters.</li>
<li>It's possible to scheduled the same counter multiple times in a single Configuration; up to once per PassGroup. This will cause the value to be statistically averaged. If this is not the desired effect, then you must avoid passing the same name into AddCounter on multiple PassGroups.</li>
</ul>
<p>In practice, PassGroups tend to be interesting only in realtime configurations involving 1-2 passes. For replay-based profiling, <a href="#StatisticalSampling">statistical sampling</a> is the preferred method for eliminating multi-pass variance.</p>
<p><a class="anchor" id="StatisticalSampling"></a></p>
<h2><a class="anchor" id="autotoc_md167"></a>
Statistical Sampling</h2>
<p>During <b>DecodeCounters</b>, PerfWorks increments each counter value with logic similar to:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span>&amp; counterValue = counterData.range[debugGroupDescription].counter[offset];</div>
<div class="line">counterValue.sum += currentSample;</div>
<div class="line">counterValue.numSamples += 1;</div>
</div><!-- fragment --><p>If you collect repeated <a href="#Iteration">iterations</a> of the same counter, the <code>sum</code> will accumulate and <code>numSamples</code> will increment. At evaluation time, the metric systems calculate the mean value as <code>sum / numSamples</code>. This allows the values to naturally converge to its statistical average, the longer you sample it.</p>
<p>If there are specific stats you wish to statistically sample, you can create a separate configuration containing only those counters and re-run additional passes on just that configuration.</p>
<p><a class="anchor" id="TraceBufferDynamicResizing"></a></p>
<h2><a class="anchor" id="autotoc_md168"></a>
Dynamically resizing the TraceBuffer and ComputeBuffer</h2>
<p>General formulae were provided to accurately size the <b>TraceBuffer</b> and <b>ComputeBuffer</b>. These formulae are based on having a priori knowledge of the number of ranges and number of dispatches being profiled in the application. With larger complex applications with dynamic branching, these might be unknown. So either some upper bound must be chosen potentially waisting gpu memory, or the buffers can be dynamically sized at runtime.</p>
<p>This approach requires starting a session with fewer buffers than necessary, and allow PerfWorks to report how many records in bytes were dropped due to not having enough space. <a href="#You">You</a> can then restart the session with the updated buffer sizes. This way, you allow the buffers to grow over several passes. The one downside to this approach is that it could take several iterations of growth before hitting the upper bound.</p>
<p>The dropped byte count is reported during <code>NVPA_NVNC_DecodeCounters</code> through the out parameters of the <code>NVPA_NVNC_DecodeCountersStats</code> object.</p>
<div class="fragment"><div class="line">NVPA_NVNC_DecodeCountersOptions decodeOptions = {};</div>
<div class="line"><span class="comment">// set up decodeOptions</span></div>
<div class="line">...</div>
<div class="line"> </div>
<div class="line">NVPA_NVNC_DecodeCountersStats decodeStats = {};</div>
<div class="line">decodeStats.structSize = NVPA_NVNC_DECODE_COUNTERS_STATE_STRUCT_SIZE;</div>
<div class="line"> </div>
<div class="line">NVPA_NVNC_DecodeCounters(&amp;decodeOptions, &amp;decodeStats);</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span>(decodeStats.numTraceBytesDropped || decodeStats.numComputeBytesDropped)</div>
<div class="line">{</div>
<div class="line">    UpdateSessionOptions(decodeStats.numTraceBytesDropped, decodeStats.numComputeBytesDropped);</div>
<div class="line">    restartSession();</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md169"></a>
Definitions</h1>
<h2><a class="anchor" id="autotoc_md170"></a>
Glossary</h2>
<ul>
<li><a class="anchor" id="Counter"></a>Counter : the number of occurences of a specific event<ul>
<li>always a <a href="https://en.wikipedia.org/wiki/Count_data">"count value"</a> &ndash; a non-negative integer value</li>
<li>if the counter originates from an instanced hardware unit, the term "counter" may imply an array of count values</li>
</ul>
</li>
<li><a class="anchor" id="Device"></a>Device : a physical NVIDIA GPU</li>
<li><a class="anchor" id="Graphics_API"></a>Graphics API : in this document, any API that sends work to a GPU<ul>
<li>here, the term "graphics API" includes compute-only APIs like CUDA</li>
</ul>
</li>
<li><a class="anchor" id="Iteration"></a>Iteration : a set of passes needed to collect a set of metrics.</li>
<li><a class="anchor" id="Metric"></a>Metric : a high-level value derived from <a href="#Counter">counter</a> values</li>
<li><a class="anchor" id="Pass"></a>Pass : a repeatable set of operations, with consistently labeled <a href="#Range">ranges</a><ul>
<li>In most graphics programs, a <a href="#Pass">pass</a> equates to a rendered frame.</li>
</ul>
</li>
<li><a class="anchor" id="Range"></a>Range : a labeled region of execution<ul>
<li>Each Range covers a set of API calls. The label provides a means of attribution.</li>
<li>Ranges can be nested. Each <a class="el" href="struct_n_v_nqueue.html" title="API class used to send commands to the GPU.">NVNqueue</a> maintains its own <a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack</a> of RangeIds as part of its state. The stack is reset to empty at <code>BeginPass</code>.</li>
<li>Ranges can be pushed/popped on NVNcommandBuffers. These operations will be performed on the <a class="el" href="struct_n_v_nqueue.html" title="API class used to send commands to the GPU.">NVNqueue</a> when submitted.</li>
<li>The label is a string.</li>
</ul>
</li>
<li><a class="anchor" id="RangeStack"></a>Range-Stack : a <a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack</a> of <a href="#Range">RangeIds</a><ul>
<li><a href="#Counter">Counter</a> data is collected per unique range-stack.</li>
<li>Identified by a list of string labels when reading back <a href="#Metric">metrics</a>.</li>
</ul>
</li>
<li><a class="anchor" id="Session"></a>Session : a set of <a href="#Pass">passes</a> collecting metrics for a single configuration<ul>
<li>GPU resources needed for profiling are allocated at Session boundaries.</li>
<li>Power management may be disabled at Session boundaries.</li>
<li>Outside of a Session, the GPU will return to its normal operating state.</li>
</ul>
</li>
<li><a class="anchor" id="Trigger"></a>Trigger : abstractly, a GPU command that causes counters to start or stop incrementing<ul>
<li>e.g., on each measurement <a href="#Range">Range</a>, PerfWorks inserts a start and stop trigger</li>
</ul>
</li>
<li><a class="anchor" id="User"></a>User : <a href="#You">you</a></li>
<li><a class="anchor" id="Workload"></a>Workload : a draw call, compute dispatch, or DMA-copy</li>
<li><a class="anchor" id="You"></a>You : the application or engine developer; aka the <a href="#User">user</a></li>
</ul>
<p><a class="anchor" id="HardwareUnits"></a></p>
<h2><a class="anchor" id="autotoc_md171"></a>
Hardware Units</h2>
<ul>
<li><a class="anchor" id="CBMGR"></a>CBMGR: The Circular Buffer Manager communicates attributes from Alpha phase to Beta phase, and from Beta phase to Raster.</li>
<li><a class="anchor" id="CDP"></a>CDP: The Color Data Path performs Alpha Test and Alpha-to-Coverage.</li>
<li><a class="anchor" id="CROP"></a>CROP: The Color Raster Operation unit is the portion of the Raster Operation unit that performs blending and color write.</li>
<li><a class="anchor" id="CRSTR"></a>CRSTR: The Coarse Raster unit determines primitive coverage over 16x16 tiles.</li>
<li><a class="anchor" id="CSB"></a>CSB: The Color Sync Barrier unit is a subunit of <a href="#PROP">PROP</a>, responsible for reordering shaded fragments. The CSB sends color data to <a href="#CROP">CROP</a>.</li>
<li><a class="anchor" id="CWD"></a>CWD: The Compute Work Distributor rasterizes compute dispatches, and distributes compute work to <a href="#SM">SMs</a>.</li>
<li><a class="anchor" id="DRAM"></a>DRAM: The logical unit for the external memory controller. On discrete GPUs, this is called the Frame Buffer (FB); for integrated GPUs, this refers to the SoC memory controller.</li>
<li><a class="anchor" id="FBP"></a>FBP: The Frame Buffer Partition (FBP) includes the <a href="#LTS">L2 cache</a>, <a href="#CROP">CROP</a>, and <a href="#ZROP">ZROP</a> unit. On discrete GPUs, the <a href="#FBP">FBP</a> contains the memory controller for the <a href="#DRAM">DRAM</a> interface.</li>
<li><a class="anchor" id="FE"></a>FE: The Front End unit is the portion of <a href="#HOST">HOST</a> that decodes GPU commands and sends them to engines.</li>
<li><a class="anchor" id="FRSTR"></a>FRSTR: The Fine Raster unit determines which samples of subtile (8x8 or 16x4) are covered by a primitive.</li>
<li><a class="anchor" id="GCC"></a>GCC: The GPC Cache Controller has a "level 1.5" cache to hold instructions and constant data.</li>
<li><a class="anchor" id="GPC"></a>GPC: The Graphics Processor Cluster (GPC) contains most of the graphics and compute processing units. The GPC contains Texture Processor Clusters <a href="#TPC">(TPC)</a> and fixed function graphics units, which perform vertex fetch and processing, primitive processing, rasterization, and communicating with <a href="#SM">SM</a> and <a href="#FBP">FBP</a> units. Low-end GPUs contain 1 GPC while higher end GPUs contain multiple GPCs.</li>
<li><a class="anchor" id="GPMPD"></a>GPMPD: The Graphics Program Manager Primitive Distributor sends geometry to <a href="#MPC">MPCs</a>.</li>
<li><a class="anchor" id="GPMSD"></a>GPMSD: The Graphics Program Manager Screen Distributor sends fragment work to <a href="#MPC">MPCs</a>.</li>
<li><a class="anchor" id="GPU"></a>GPU: GPU is the top level logical unit. Metrics that use counters from multiple units may specify this unit.</li>
<li><a class="anchor" id="GR"></a>GR: GR is the graphics or compute engine. The <a href="#HOST">HOST</a> schedules work on the graphics and compute engine.</li>
<li><a class="anchor" id="HOST"></a>HOST: The HOST is the interface to the CPU. The HOST fetches GPU commands from memory, and schedules work on the engines.</li>
<li><a class="anchor" id="L1TEX"></a>L1TEX: The L1 Texture Unit (L1TEX also referred to as TEX) receives coordinates from the <a href="#SM">SMs</a>, fetches texel data, and performs bilinear/trilinear/aniso filtering. Texture contains an L1 cache to improve locality. On Maxwell and Pascal GPUs, the TEX unit also is responsible for global, local, and surface loads and stores.</li>
<li><a class="anchor" id="LTC"></a>LTC: The L2 Cache unit contains <a href="#LTS">LTS</a> and Raster Operation units (<a href="#CROP">CROP</a>, <a href="#ZROP">ZROP</a>, <a href="#RDM">RDM</a>).</li>
<li><a class="anchor" id="LTCX"></a>LTCX: On mobile GPUs, each <a href="#LTS">LTS</a> connects to the <a href="#MCCIF">MCCIF</a> via an LTCX. Contains queueing and coalescing logic.</li>
<li><a class="anchor" id="LTS"></a>LTS: The L2 data cache slice is the basic building block of the L2 data cache.</li>
<li><a class="anchor" id="MCCIF"></a>MCCIF: On mobile GPUs, the Memory Controller Interface sends read &amp; write requests from <a href="#LTCX">LTCX</a> to the <a href="#MSS">MSS</a>.</li>
<li><a class="anchor" id="MME"></a>MME: The Macro Method Expander is a subunit of <a href="#FE">FE</a>.</li>
<li><a class="anchor" id="MPC"></a>MPC: The Module Pipe Controller coordinates shader launches and related resource management.</li>
<li><a class="anchor" id="MSS"></a>MSS: On mobile SoCs, the Memory SubSystem contains the DRAM controller. Resides outside of the GPU, and handles CPU traffic as well.</li>
<li><a class="anchor" id="PDA"></a>PDA: Primitive Distributor Alpha sub-unit of PD which assembles primitives from memory buffers and sends them to the GPCs.</li>
<li><a class="anchor" id="PDB"></a>PDB: Primitive Distributor Beta sub-unit of PD which distributes geometry and/or tessellation shading to GPCs.</li>
<li><a class="anchor" id="PEL"></a>PEL: Primitive Engine Local. A per-TPC unit that contains the VAF and STRI units.</li>
<li><a class="anchor" id="PES"></a>PES: Primitive Engine Shared. A GPC unit shared by TPCs, that contains the VSC and TG units.</li>
<li><a class="anchor" id="PIXOUT"></a>PIXOUT: PIXOUT is an interface that transfers shaded fragment output from <a href="#SM">SM</a> to the <a href="#CDP">Color Data Path</a>, which eventually leads to <a href="#CROP">CROP</a>.</li>
<li><a class="anchor" id="PPC"></a>PPC: The Primitive Processing Cluster.</li>
<li><a class="anchor" id="PROP"></a>PROP: The Pre-ROP unit does address calculation and sends pixel work to TPCs and ROPs. PROP is responsible for managing EarlyZ and LateZ, and sends depth samples to ZROP for Z-Test. PROP also sends final computed color samples to CROP.</li>
<li><a class="anchor" id="RASTER"></a>RASTER: Raster is a pipeline that translates primitives into pixel work. Contains <a href="#SETUP">SETUP</a>, <a href="#CRSTR">CRSTR</a>, <a href="#ZCULL">ZCULL</a>, <a href="#FRSTR">FRSTR</a>, <a href="#TC">TC</a>.</li>
<li><a class="anchor" id="RDM"></a>RDM: The Raster Operation Data Manager resides in the <a href="#LTC">LTC</a>. RDM receives CROP and ZROP commands from GPCs, and distributes them to the appropriate destination.</li>
<li><a class="anchor" id="SCC"></a>SCC: The State Cache Controller handles state and constant versioning for the graphics pipeline.</li>
<li><a class="anchor" id="SETUP"></a>SETUP: The Raster Setup unit fetches coordinate attributes from circular buffers, and calculates edge equations for triangles.</li>
<li><a class="anchor" id="SKED"></a>SKED: The SKED unit maintains the list of outstanding compute tasks, and sends them to the <a href="#CWD">Compute Work Distributor</a>.</li>
<li><a class="anchor" id="SM"></a>SM: The Streaming Multiprocessor (SM) is the core processing unit in the GPU, running all shader programs.</li>
<li><a class="anchor" id="SMP"></a>SMP: The Stream Multiprocessor Partition (SMP) is a physical partition of the shared resources in the <a href="#SM">SM</a>.</li>
<li><a class="anchor" id="SMSP"></a>SMSP: The Streaming Multiprocessor Sub-Partition (SMSP) contains a warp scheduler, register file, and dedicated execution units.</li>
<li><a class="anchor" id="STREAM"></a>STREAM: The Stream unit can write primitive data to memory before clip/cull. Stream is known as "transform feedback" on some APIs.</li>
<li><a class="anchor" id="STRI"></a>STRI: The Setup Triangle unit calculates plane equations for attributes for the pixel shader, and sends them to be stored in TRAM.</li>
<li><a class="anchor" id="SWDX"></a>SWDX: The Screen Work Distributor Crossbar receives work from the crossbar bus, and sends primitives to <a href="#RASTER">rasterizers</a>. SWDX performs the binning and tiling steps for Tiled Caching.</li>
<li><a class="anchor" id="TC"></a>TC: The Tile Coalescer sits at the end of the <a href="#RASTER">Raster</a> pipe.</li>
<li><a class="anchor" id="TGA"></a>TGA: Task Generator Alpha.</li>
<li><a class="anchor" id="TGB"></a>TGB: Topology Generator Beta.</li>
<li><a class="anchor" id="TPC"></a>TPC: The Texture Processor Cluster (TPC) is the core unit of graphics functionality, including graphics and compute shader functions, texture and primitive engine functions, including attribute fetch and plane equation calculations. The TPC includes Streaming Multiprocessors <a href="#SM">SM</a>, Texture Units <a href="#L1TEX">L1TEX</a>, and a primitive engine.</li>
<li><a class="anchor" id="VAF"></a>VAF: The Vertex Attribute Fetch unit reads attributes from memory for Vertex Shaders and the Beta phase shaders.</li>
<li><a class="anchor" id="VPC"></a>VPC: The Viewport Clip Cull unit.</li>
<li><a class="anchor" id="WWDX"></a>WWDX: The World Work Distributor Crossbar sends primitives at the end of the world pipe to the crossbar bus, destined to SWDX and rasterization.</li>
<li><a class="anchor" id="ZCULL"></a>ZCULL: The ZCULL unit is a low resolution on-chip Z-buffer to trivially accept or reject tiles based on conservative depth comparison. ZCULL sits in the <a href="#RASTER">RASTER</a> pipe.</li>
<li><a class="anchor" id="ZROP"></a>ZROP: The Z Raster Operation unit is the portion of the Raster Operation unit that performs the Depth (Z) and Stencil read, compare, and conditional write.</li>
</ul>
<p><a class="anchor" id="UnitTree"></a></p>
<h2><a class="anchor" id="autotoc_md172"></a>
Hardware Unit Tree</h2>
<ul>
<li><a href="#GPU">GPU</a><ul>
<li><a href="#FBP">FBP</a><ul>
<li><a href="#LTC">LTC</a><ul>
<li><a href="#CROP">CROP</a></li>
<li><a href="#LTS">LTS</a><ul>
<li><a href="#LTCX">LTCX</a></li>
<li><a href="#MCCIF">MCCIF</a></li>
</ul>
</li>
<li><a href="#RDM">RDM</a></li>
<li><a href="#ZROP">ZROP</a></li>
</ul>
</li>
<li><a href="#DRAM">DRAM</a></li>
</ul>
</li>
<li><a href="#FE">FE</a><ul>
<li><a href="#MME">MME</a></li>
</ul>
</li>
<li><a href="#GR">GR</a><ul>
<li><a href="#CWD">CWD</a></li>
<li><a href="#PDA">PDA</a></li>
<li><a href="#PDB">PDB</a></li>
<li><a href="#SCC">SCC</a></li>
<li><a href="#SKED">SKED</a></li>
<li><a href="#GPC">GPC</a><ul>
<li><a href="#GCC">GCC</a></li>
<li><a href="#GPMPD">GPMPD</a></li>
<li><a href="#GPMSD">GPMSD</a></li>
<li><a href="#PIXOUT">PIXOUT</a></li>
<li><a href="#PPC">PPC</a><ul>
<li><a href="#CBMGR">CBMGR</a></li>
<li><a href="#PES">PES</a><ul>
<li><a href="#TGA">TGA</a></li>
<li><a href="#TGB">TGB</a></li>
<li><a href="#VPC">VPC</a></li>
</ul>
</li>
<li><a href="#STREAM">STREAM</a></li>
<li><a href="#WWDX">WWDX</a></li>
</ul>
</li>
<li><a href="#PROP">PROP</a><ul>
<li><a href="#CDP">CDP</a></li>
<li><a href="#CSB">CSB</a></li>
</ul>
</li>
<li><a href="#RASTER">RASTER</a><ul>
<li><a href="#CRSTR">CRSTR</a></li>
<li><a href="#FRSTR">FRSTR</a></li>
<li><a href="#SETUP">SETUP</a></li>
<li><a href="#TC">TC</a></li>
<li><a href="#ZCULL">ZCULL</a></li>
</ul>
</li>
<li><a href="#SWDX">SWDX</a></li>
<li><a href="#TPC">TPC</a><ul>
<li><a href="#L1TEX">L1TEX</a></li>
<li><a href="#MPC">MPC</a></li>
<li><a href="#PEL">PEL</a><ul>
<li><a href="#VAF">VAF</a></li>
<li><a href="#STRI">STRI</a></li>
</ul>
</li>
<li><a href="#SM">SM</a><ul>
<li><a href="#SMP">SMP</a><ul>
<li><a href="#SMSP">SMSP</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#HOST">HOST</a></li>
</ul>
</li>
<li><a href="#MSS">MSS</a> : this is not part of the GPU</li>
</ul>
<h1><a class="anchor" id="autotoc_md173"></a>
Notices</h1>
<h2><a class="anchor" id="autotoc_md174"></a>
Notice</h2>
<p>ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, "MATERIALS") ARE BEING PROVIDED "AS IS." NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.</p>
<p>Information furnished is believed to be accurate and reliable. However, NVIDIA Corporation assumes no responsibility for the consequences of use of such information or for any infringement of patents or other rights of third parties that may result from its use. No license is granted by implication of otherwise under any patent rights of NVIDIA Corporation. Specifications mentioned in this publication are subject to change without notice. This publication supersedes and replaces all other information previously supplied. NVIDIA Corporation products are not authorized as critical components in life support devices or systems without express written approval of NVIDIA Corporation.</p>
<h2><a class="anchor" id="autotoc_md175"></a>
Trademarks</h2>
<p>NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.</p>
<h2><a class="anchor" id="autotoc_md176"></a>
Copyright</h2>
<p>NVIDIA(R) PerfWorks SDK Documentation (c) 2015-2021. NVIDIA Corporation. All Rights Reserved. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- HTML footer for doxygen 1.9.1-->
<!-- start footer part -->
</body>
</html>
